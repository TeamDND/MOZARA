
"""
MOZARA Python Backend í†µí•© ì• í”Œë¦¬ì¼€ì´ì…˜
"""
from fastapi import FastAPI, File, UploadFile, Form, HTTPException, Query
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
from pydantic import BaseModel
from typing import Optional, List
import json
from typing import Annotated
import threading
from dotenv import load_dotenv
from datetime import datetime
import os
import urllib.parse
import hashlib
import json
from datetime import datetime, timedelta

# .env íŒŒì¼ ë¡œë“œ (Docker í™˜ê²½ì—ì„œëŠ” í™˜ê²½ë³€ìˆ˜ ì§ì ‘ ì‚¬ìš©)
try:
    load_dotenv("../../.env")
    # load_dotenv(".env")
except:
    pass  # Docker í™˜ê²½ì—ì„œëŠ” í™˜ê²½ë³€ìˆ˜ë¥¼ ì§ì ‘ ì‚¬ìš©

# ì´ë¯¸ì§€ ìºì‹œ ì €ì¥ì†Œ (ë©”ëª¨ë¦¬ ê¸°ë°˜)
image_cache = {}

def get_cache_key(place_name: str, address: str = None) -> str:
    """ìºì‹œ í‚¤ ìƒì„±"""
    key_string = f"{place_name}_{address or ''}"
    return hashlib.md5(key_string.encode()).hexdigest()

def get_cached_image(place_name: str, address: str = None) -> str:
    """ìºì‹œëœ ì´ë¯¸ì§€ URL ê°€ì ¸ì˜¤ê¸°"""
    cache_key = get_cache_key(place_name, address)
    
    if cache_key in image_cache:
        cached_data = image_cache[cache_key]
        # ìºì‹œ ë§Œë£Œ ì‹œê°„ í™•ì¸ (24ì‹œê°„)
        if datetime.now() - cached_data['timestamp'] < timedelta(hours=24):
            return cached_data['image_url']
        else:
            # ë§Œë£Œëœ ìºì‹œ ì‚­ì œ
            del image_cache[cache_key]
    
    return None

def cache_image(place_name: str, address: str, image_url: str):
    """ì´ë¯¸ì§€ URL ìºì‹œ ì €ì¥"""
    cache_key = get_cache_key(place_name, address)
    image_cache[cache_key] = {
        'image_url': image_url,
        'timestamp': datetime.now()
    }

def generate_default_image_url(category: str, name: str) -> str:
    """ì¹´í…Œê³ ë¦¬ì™€ ì´ë¦„ì„ ê¸°ë°˜ìœ¼ë¡œ ê¸°ë³¸ ì´ë¯¸ì§€ URL ìƒì„± (ê°œì„ ëœ ëœë¤ ì‹œìŠ¤í…œ)"""
    # ì¹´í…Œê³ ë¦¬ë³„ ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ì¿¼ë¦¬ ë§¤í•‘
    category_mapping = {
        'íƒˆëª¨ë³‘ì›': {
            'color': 'blue', 
            'icon': 'hospital', 
            'queries': [
                'hospital+medical', 'clinic+medical', 'doctor+office', 'medical+center',
                'healthcare+facility', 'hospital+building', 'medical+clinic', 'health+center'
            ]
        },
        'íƒˆëª¨ë¯¸ìš©ì‹¤': {
            'color': 'purple', 
            'icon': 'scissors', 
            'queries': [
                'hair+salon', 'barbershop', 'hair+stylist', 'beauty+salon',
                'hair+cutting', 'salon+interior', 'hair+care', 'styling+chair'
            ]
        },
        'ê°€ë°œì „ë¬¸ì ': {
            'color': 'green', 
            'icon': 'wig', 
            'queries': [
                'wig+hair', 'hair+piece', 'hair+extension', 'hair+replacement',
                'synthetic+hair', 'human+hair', 'hair+accessories', 'hair+styling'
            ]
        },
        'ë‘í”¼ë¬¸ì‹ ': {
            'color': 'orange', 
            'icon': 'tattoo', 
            'queries': [
                'tattoo+studio', 'scalp+micropigmentation', 'hair+tattoo', 'tattoo+artist',
                'tattoo+parlor', 'body+art', 'tattoo+equipment', 'tattoo+design'
            ]
        },
    }
    
    # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    category_lower = category.lower()
    name_lower = name.lower()
    
    if 'ë¬¸ì‹ ' in category_lower or 'ë¬¸ì‹ ' in name_lower or 'smp' in name_lower:
        selected_category = 'ë‘í”¼ë¬¸ì‹ '
    elif 'ê°€ë°œ' in category_lower or 'ê°€ë°œ' in name_lower or 'ì¦ëª¨ìˆ ' in name_lower:
        selected_category = 'ê°€ë°œì „ë¬¸ì '
    elif 'ë¯¸ìš©' in category_lower or 'ë¯¸ìš©' in name_lower or 'í—¤ì–´' in name_lower or 'ì‚´ë¡±' in name_lower:
        selected_category = 'íƒˆëª¨ë¯¸ìš©ì‹¤'
    else:
        selected_category = 'íƒˆëª¨ë³‘ì›'
    
    config = category_mapping.get(selected_category, category_mapping['íƒˆëª¨ë³‘ì›'])
    
    # ì²« ê¸€ì ì¶”ì¶œ
    first_letter = name[0].upper() if name else 'H'
    
    # ì´ë¦„ ê¸°ë°˜ ì‹œë“œë¡œ ëœë¤ ì¿¼ë¦¬ ì„ íƒ (ì¼ê´€ì„± ìˆëŠ” ëœë¤)
    import hashlib
    name_hash = int(hashlib.md5(name.encode()).hexdigest()[:8], 16)
    query_index = name_hash % len(config['queries'])
    selected_query = config['queries'][query_index]
    
    # Unsplash APIë¥¼ ì‚¬ìš©í•œ ì‹¤ì œ ì´ë¯¸ì§€ URL ìƒì„±
    # ëœë¤ ì‹œë“œ ì¶”ê°€ë¡œ ë” ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ì œê³µ
    random_seed = name_hash % 1000
    unsplash_url = f"https://source.unsplash.com/400x200/?{selected_query}&sig={random_seed}"
    
    # fallbackìœ¼ë¡œ placeholder ì‚¬ìš©
    placeholder_url = f"https://via.placeholder.com/400x200/{config['color']}/ffffff?text={urllib.parse.quote(first_letter)}"
    
    return unsplash_url

def get_unsplash_collection_images(category: str, name: str) -> str:
    """Unsplash ì»¬ë ‰ì…˜ì—ì„œ íŠ¹ì • ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°"""
    # ì¹´í…Œê³ ë¦¬ë³„ Unsplash ì»¬ë ‰ì…˜ ID
    collection_mapping = {
        'íƒˆëª¨ë³‘ì›': ['medical', 'healthcare', 'hospital', 'clinic'],
        'íƒˆëª¨ë¯¸ìš©ì‹¤': ['hair-salon', 'barbershop', 'beauty', 'styling'],
        'ê°€ë°œì „ë¬¸ì ': ['hair', 'wig', 'hairpiece', 'haircare'],
        'ë‘í”¼ë¬¸ì‹ ': ['tattoo', 'body-art', 'tattoo-studio', 'ink']
    }
    
    # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    category_lower = category.lower()
    name_lower = name.lower()
    
    if 'ë¬¸ì‹ ' in category_lower or 'ë¬¸ì‹ ' in name_lower or 'smp' in name_lower:
        selected_category = 'ë‘í”¼ë¬¸ì‹ '
    elif 'ê°€ë°œ' in category_lower or 'ê°€ë°œ' in name_lower or 'ì¦ëª¨ìˆ ' in name_lower:
        selected_category = 'ê°€ë°œì „ë¬¸ì '
    elif 'ë¯¸ìš©' in category_lower or 'ë¯¸ìš©' in name_lower or 'í—¤ì–´' in name_lower or 'ì‚´ë¡±' in name_lower:
        selected_category = 'íƒˆëª¨ë¯¸ìš©ì‹¤'
    else:
        selected_category = 'íƒˆëª¨ë³‘ì›'
    
    collections = collection_mapping.get(selected_category, collection_mapping['íƒˆëª¨ë³‘ì›'])
    
    # ì´ë¦„ ê¸°ë°˜ìœ¼ë¡œ ì»¬ë ‰ì…˜ ì„ íƒ
    import hashlib
    name_hash = int(hashlib.md5(name.encode()).hexdigest()[:8], 16)
    collection_index = name_hash % len(collections)
    selected_collection = collections[collection_index]
    
    # Unsplash ì»¬ë ‰ì…˜ URL
    return f"https://source.unsplash.com/collection/{selected_collection}/400x200"

def get_unsplash_user_images(category: str, name: str) -> str:
    """Unsplash íŠ¹ì • ì‚¬ìš©ìì˜ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°"""
    # ì¹´í…Œê³ ë¦¬ë³„ ì „ë¬¸ ì‚¬ì§„ì‘ê°€ ì‚¬ìš©ìëª…
    photographer_mapping = {
        'íƒˆëª¨ë³‘ì›': ['cdc', 'nci', 'pixabay', 'pexels'],
        'íƒˆëª¨ë¯¸ìš©ì‹¤': ['pexels', 'pixabay', 'unsplash', 'freepik'],
        'ê°€ë°œì „ë¬¸ì ': ['pexels', 'pixabay', 'unsplash', 'freepik'],
        'ë‘í”¼ë¬¸ì‹ ': ['pexels', 'pixabay', 'unsplash', 'freepik']
    }
    
    # ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
    category_lower = category.lower()
    name_lower = name.lower()
    
    if 'ë¬¸ì‹ ' in category_lower or 'ë¬¸ì‹ ' in name_lower or 'smp' in name_lower:
        selected_category = 'ë‘í”¼ë¬¸ì‹ '
    elif 'ê°€ë°œ' in category_lower or 'ê°€ë°œ' in name_lower or 'ì¦ëª¨ìˆ ' in name_lower:
        selected_category = 'ê°€ë°œì „ë¬¸ì '
    elif 'ë¯¸ìš©' in category_lower or 'ë¯¸ìš©' in name_lower or 'í—¤ì–´' in name_lower or 'ì‚´ë¡±' in name_lower:
        selected_category = 'íƒˆëª¨ë¯¸ìš©ì‹¤'
    else:
        selected_category = 'íƒˆëª¨ë³‘ì›'
    
    photographers = photographer_mapping.get(selected_category, photographer_mapping['íƒˆëª¨ë³‘ì›'])
    
    # ì´ë¦„ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ì§„ì‘ê°€ ì„ íƒ
    import hashlib
    name_hash = int(hashlib.md5(name.encode()).hexdigest()[:8], 16)
    photographer_index = name_hash % len(photographers)
    selected_photographer = photographers[photographer_index]
    
    # Unsplash ì‚¬ìš©ì ì´ë¯¸ì§€ URL
    return f"https://source.unsplash.com/user/{selected_photographer}/400x200"

def get_best_image_url(place_name: str, address: str = None, category: str = '') -> str:
    """ìµœì ì˜ ì´ë¯¸ì§€ URLì„ ì„ íƒí•˜ëŠ” ë‹¤ë‹¨ê³„ ì‹œìŠ¤í…œ (ì‹¤ìš©ì  ê°œì„ )"""
    # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
    cached_image = get_cached_image(place_name, address)
    if cached_image:
        return cached_image
    
    # ì´ë¯¸ì§€ ì†ŒìŠ¤ ìš°ì„ ìˆœìœ„ (ì‹¤ìš©ì„±ê³¼ ì•ˆì •ì„±ì„ ê³ ë ¤í•œ ìˆœì„œ)
    image_sources = [
        # 1ìˆœìœ„: Google Places API (ì‹¤ì œ ë³‘ì› ì‚¬ì§„)
        lambda: get_google_places_image_sync(place_name, address),
        
        # 2ìˆœìœ„: ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ API (ì‹¤ì œ ë³‘ì› ì‚¬ì§„)
        lambda: get_naver_place_image_sync(place_name, address),
        
        # 3ìˆœìœ„: ì¹´ì¹´ì˜¤ë§µ API (ì‹¤ì œ ë³‘ì› ì‚¬ì§„)
        lambda: get_kakao_place_image_sync(place_name, address),
        
        # 4ìˆœìœ„: Google Custom Search API (ê´€ë ¨ ì´ë¯¸ì§€)
        lambda: get_google_search_image_sync(place_name, address),
        
        # 5ìˆœìœ„: Unsplash ì»¬ë ‰ì…˜ (ê³ í’ˆì§ˆ ê´€ë ¨ ì´ë¯¸ì§€)
        lambda: get_unsplash_collection_images(category, place_name),
        
        # 6ìˆœìœ„: Unsplash ì‚¬ìš©ì (ì „ë¬¸ ì‚¬ì§„ì‘ê°€)
        lambda: get_unsplash_user_images(category, place_name),
        
        # 7ìˆœìœ„: ê¸°ë³¸ Unsplash (ëœë¤ ê´€ë ¨ ì´ë¯¸ì§€)
        lambda: generate_default_image_url(category, place_name)
    ]
    
    # ê° ì†ŒìŠ¤ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„ (íƒ€ì„ì•„ì›ƒ ì„¤ì •)
    for i, source_func in enumerate(image_sources):
        try:
            # ê° ì†ŒìŠ¤ë³„ë¡œ íƒ€ì„ì•„ì›ƒ ì„¤ì •
            timeout = 5 if i < 3 else 3  # API í˜¸ì¶œì€ 5ì´ˆ, UnsplashëŠ” 3ì´ˆ
            
            import signal
            
            def timeout_handler(signum, frame):
                raise TimeoutError("ì´ë¯¸ì§€ ì†ŒìŠ¤ íƒ€ì„ì•„ì›ƒ")
            
            signal.signal(signal.SIGALRM, timeout_handler)
            signal.alarm(timeout)
            
            try:
                image_url = source_func()
                if image_url and is_valid_image_url(image_url):
                    # ì´ë¯¸ì§€ URL ê²€ì¦
                    if verify_image_accessibility(image_url):
                        # ìºì‹œì— ì €ì¥
                        cache_image(place_name, address, image_url)
                        return image_url
            finally:
                signal.alarm(0)  # íƒ€ì„ì•„ì›ƒ í•´ì œ
                
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ì†ŒìŠ¤ {i+1} ì˜¤ë¥˜: {e}")
            continue
    
    # ëª¨ë“  ì†ŒìŠ¤ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì´ë¯¸ì§€ ë°˜í™˜
    default_image = generate_default_image_url(category, place_name)
    cache_image(place_name, address, default_image)
    return default_image

def get_naver_place_image_sync(place_name: str, address: str = None) -> str:
    """ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ API ë™ê¸° ë²„ì „"""
    try:
        import asyncio
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        result = loop.run_until_complete(scrape_naver_place_images(place_name, address))
        loop.close()
        return result
    except:
        return None

def get_kakao_place_image_sync(place_name: str, address: str = None) -> str:
    """ì¹´ì¹´ì˜¤ë§µ API ë™ê¸° ë²„ì „"""
    try:
        import asyncio
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        result = loop.run_until_complete(scrape_kakao_place_images(place_name, address))
        loop.close()
        return result
    except:
        return None

def get_google_search_image_sync(place_name: str, address: str = None) -> str:
    """Google Custom Search API ë™ê¸° ë²„ì „"""
    try:
        import asyncio
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        result = loop.run_until_complete(scrape_google_images(place_name, address))
        loop.close()
        return result
    except:
        return None

def verify_image_accessibility(image_url: str) -> bool:
    """ì´ë¯¸ì§€ URL ì ‘ê·¼ ê°€ëŠ¥ì„± ê²€ì¦"""
    try:
        import requests
        
        # HEAD ìš”ì²­ìœ¼ë¡œ ì´ë¯¸ì§€ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        response = requests.head(image_url, timeout=5, allow_redirects=True)
        
        # 200 OKì´ê³  Content-Typeì´ ì´ë¯¸ì§€ì¸ì§€ í™•ì¸
        if response.status_code == 200:
            content_type = response.headers.get('content-type', '').lower()
            return any(img_type in content_type for img_type in ['image/', 'jpeg', 'jpg', 'png', 'gif', 'webp'])
        
        return False
        
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ì ‘ê·¼ì„± ê²€ì¦ ì˜¤ë¥˜: {e}")
        return False

def get_google_places_image_sync(place_name: str, address: str = None) -> str:
    """Google Places API ë™ê¸° ë²„ì „"""
    try:
        import asyncio
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        result = loop.run_until_complete(get_google_places_image(place_name, address))
        loop.close()
        return result
    except:
        return None

def get_scraped_image_sync(place_name: str, address: str = None) -> str:
    """ì›¹ ìŠ¤í¬ë˜í•‘ ë™ê¸° ë²„ì „"""
    try:
        import asyncio
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        result = loop.run_until_complete(scrape_hospital_images(place_name, address))
        loop.close()
        return result
    except:
        return None

async def get_google_places_image(place_name: str, address: str = None) -> str:
    """Google Places APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ë³‘ì› ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°"""
    # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
    cached_image = get_cached_image(place_name, address)
    if cached_image:
        return cached_image
    
    google_api_key = os.getenv("GOOGLE_PLACES_API_KEY")
    
    if not google_api_key:
        default_image = generate_default_image_url("", place_name)
        cache_image(place_name, address, default_image)
        return default_image
    
    try:
        import requests
        
        # Google Places Text Search APIë¡œ ì¥ì†Œ ê²€ìƒ‰
        search_url = "https://maps.googleapis.com/maps/api/place/textsearch/json"
        search_params = {
            "query": f"{place_name} {address or ''}",
            "key": google_api_key,
            "type": "hospital|beauty_salon|hair_care"
        }
        
        search_response = requests.get(search_url, params=search_params)
        search_data = search_response.json()
        
        if search_data.get("status") == "OK" and search_data.get("results"):
            place_id = search_data["results"][0]["place_id"]
            
            # Place Details APIë¡œ ìƒì„¸ ì •ë³´ ë° ì‚¬ì§„ ì°¸ì¡° ê°€ì ¸ì˜¤ê¸°
            details_url = "https://maps.googleapis.com/maps/api/place/details/json"
            details_params = {
                "place_id": place_id,
                "fields": "photos",
                "key": google_api_key
            }
            
            details_response = requests.get(details_url, params=details_params)
            details_data = details_response.json()
            
            if details_data.get("status") == "OK" and details_data.get("result", {}).get("photos"):
                # ì²« ë²ˆì§¸ ì‚¬ì§„ ì‚¬ìš©
                photo_reference = details_data["result"]["photos"][0]["photo_reference"]
                photo_url = f"https://maps.googleapis.com/maps/api/place/photo?maxwidth=400&photoreference={photo_reference}&key={google_api_key}"
                # ìºì‹œì— ì €ì¥
                cache_image(place_name, address, photo_url)
                return photo_url
        
        # Google Placesì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ê¸°ë³¸ ì´ë¯¸ì§€ ë°˜í™˜
        default_image = generate_default_image_url("", place_name)
        cache_image(place_name, address, default_image)
        return default_image
        
    except Exception as e:
        print(f"Google Places API ì˜¤ë¥˜: {e}")
        return generate_default_image_url("", place_name)

async def scrape_hospital_images(place_name: str, address: str = None) -> str:
    """ì›¹ ìŠ¤í¬ë˜í•‘ì„ í†µí•œ ë³‘ì› ì´ë¯¸ì§€ ìˆ˜ì§‘ (ê°œì„ ëœ ë²„ì „)"""
    try:
        import requests
        from bs4 import BeautifulSoup
        import re
        
        # ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
        cached_image = get_cached_image(f"scraped_{place_name}", address)
        if cached_image:
            return cached_image
        
        # ì—¬ëŸ¬ ì†ŒìŠ¤ì—ì„œ ì´ë¯¸ì§€ ìˆ˜ì§‘ ì‹œë„
        image_sources = [
            scrape_naver_place_images(place_name, address),
            scrape_kakao_place_images(place_name, address),
            scrape_google_images(place_name, address)
        ]
        
        for source_func in image_sources:
            try:
                image_url = await source_func
                if image_url and image_url != generate_default_image_url("", place_name):
                    cache_image(f"scraped_{place_name}", address, image_url)
                    return image_url
            except Exception as e:
                print(f"ìŠ¤í¬ë˜í•‘ ì†ŒìŠ¤ ì˜¤ë¥˜: {e}")
                continue
        
        # ëª¨ë“  ì†ŒìŠ¤ì—ì„œ ì‹¤íŒ¨í•œ ê²½ìš° ê¸°ë³¸ ì´ë¯¸ì§€ ë°˜í™˜
        default_image = generate_default_image_url("", place_name)
        cache_image(f"scraped_{place_name}", address, default_image)
        return default_image
        
    except Exception as e:
        print(f"ì›¹ ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {e}")
        return generate_default_image_url("", place_name)

async def scrape_naver_place_images(place_name: str, address: str = None) -> str:
    """ë„¤ì´ë²„ ì§€ì—­ê²€ìƒ‰ APIë¥¼ ì‚¬ìš©í•œ ë³‘ì› ì´ë¯¸ì§€ ìˆ˜ì§‘ (ì‹¤ì œ ì—°ë™)"""
    try:
        import requests
        import json
        
        # ë„¤ì´ë²„ ì§€ì—­ê²€ìƒ‰ API ì‚¬ìš© (ì‹¤ì œ API í‚¤ í™œìš©)
        naver_client_id = os.getenv("NAVER_CLIENT_ID")
        naver_client_secret = os.getenv("NAVER_CLIENT_SECRET")
        
        if not naver_client_id or not naver_client_secret:
            print("ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        # ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
        search_query = f"{place_name} {address or ''}"
        
        # ë„¤ì´ë²„ ì§€ì—­ê²€ìƒ‰ API ì—”ë“œí¬ì¸íŠ¸
        naver_api_url = "https://openapi.naver.com/v1/search/local.json"
        
        headers = {
            'X-Naver-Client-Id': naver_client_id,
            'X-Naver-Client-Secret': naver_client_secret,
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        params = {
            'query': search_query,
            'display': 10,
            'start': 1,
            'sort': 'comment'  # ë¦¬ë·° ë§ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        }
        
        response = requests.get(naver_api_url, params=params, headers=headers, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            
            # ë„¤ì´ë²„ ì§€ì—­ê²€ìƒ‰ API ì‘ë‹µì—ì„œ ë³‘ì› ì •ë³´ ì¶”ì¶œ
            if 'items' in data:
                for item in data['items']:
                    # ë³‘ì›/ì˜ë£Œ ê´€ë ¨ ì¥ì†Œë§Œ í•„í„°ë§
                    if is_medical_place(item.get('category', ''), item.get('title', '')):
                        # ë„¤ì´ë²„ì—ì„œ ì¶”ê°€ ì´ë¯¸ì§€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                        image_url = await get_naver_place_detail_image(item)
                        if image_url:
                            return image_url
        
        return None
        
    except Exception as e:
        print(f"ë„¤ì´ë²„ ì§€ì—­ê²€ìƒ‰ API ì˜¤ë¥˜: {e}")
        return None

async def get_naver_place_detail_image(place_item: dict) -> str:
    """ë„¤ì´ë²„ ì¥ì†Œ ìƒì„¸ ì •ë³´ì—ì„œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°"""
    try:
        import requests
        import re
        
        # ë„¤ì´ë²„ ì§€ë„ì—ì„œ ì¥ì†Œ ìƒì„¸ ì •ë³´ í˜ì´ì§€ ìŠ¤í¬ë˜í•‘
        place_name = place_item.get('title', '').replace('<b>', '').replace('</b>', '')
        place_address = place_item.get('address', '')
        
        # ë„¤ì´ë²„ ì§€ë„ ê²€ìƒ‰ URL
        search_query = f"{place_name} {place_address}"
        naver_map_url = f"https://map.naver.com/v5/search/{urllib.parse.quote(search_query)}"
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Referer': 'https://map.naver.com/'
        }
        
        response = requests.get(naver_map_url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            # HTMLì—ì„œ ì´ë¯¸ì§€ URL ì¶”ì¶œ
            content = response.text
            
            # ë„¤ì´ë²„ ì§€ë„ì—ì„œ ì´ë¯¸ì§€ URL íŒ¨í„´ ì°¾ê¸°
            image_patterns = [
                r'https://[^"\']*\.naver\.com[^"\']*\.(?:jpg|jpeg|png|gif|webp)',
                r'https://[^"\']*\.navercdn\.com[^"\']*\.(?:jpg|jpeg|png|gif|webp)',
                r'https://[^"\']*\.naver\.com[^"\']*photo[^"\']*',
                r'https://[^"\']*\.naver\.com[^"\']*image[^"\']*'
            ]
            
            for pattern in image_patterns:
                matches = re.findall(pattern, content, re.IGNORECASE)
                for match in matches:
                    if is_valid_image_url(match):
                        return normalize_image_url(match, 'naver.com')
        
        return None
        
    except Exception as e:
        print(f"ë„¤ì´ë²„ ì¥ì†Œ ìƒì„¸ ì •ë³´ ì˜¤ë¥˜: {e}")
        return None

def is_medical_place(category: str, name: str) -> bool:
    """ì˜ë£Œ ê´€ë ¨ ì¥ì†Œì¸ì§€ í™•ì¸"""
    medical_keywords = [
        'ë³‘ì›', 'ì˜ì›', 'í´ë¦¬ë‹‰', 'ì„¼í„°', 'í”¼ë¶€ê³¼', 'ì„±í˜•ì™¸ê³¼', 'í•œì˜ì›',
        'ì¹˜ê³¼', 'ë‚´ê³¼', 'ì™¸ê³¼', 'ì†Œì•„ê³¼', 'ì‚°ë¶€ì¸ê³¼', 'ì •í˜•ì™¸ê³¼',
        'ë¯¸ìš©ì‹¤', 'í—¤ì–´ì‚´ë¡±', 'ë‘í”¼', 'íƒˆëª¨', 'ê°€ë°œ', 'ë¬¸ì‹ ', 'SMP'
    ]
    
    category_lower = category.lower()
    name_lower = name.lower()
    
    return any(keyword in category_lower or keyword in name_lower for keyword in medical_keywords)

def extract_naver_image_url(place_data: dict) -> str:
    """ë„¤ì´ë²„ ì¥ì†Œ ë°ì´í„°ì—ì„œ ì´ë¯¸ì§€ URL ì¶”ì¶œ"""
    # ë‹¤ì–‘í•œ ì´ë¯¸ì§€ í•„ë“œ í™•ì¸
    image_fields = [
        'thumUrl', 'photoUrl', 'imageUrl', 'mainPhotoUrl',
        'representPhotoUrl', 'photo', 'image', 'thumbnail'
    ]
    
    for field in image_fields:
        if field in place_data and place_data[field]:
            image_url = place_data[field]
            if is_valid_image_url(image_url):
                return normalize_image_url(image_url, 'naver.com')
    
    return None

async def scrape_kakao_place_images(place_name: str, address: str = None) -> str:
    """ì¹´ì¹´ì˜¤ë§µì—ì„œ ë³‘ì› ì´ë¯¸ì§€ ìˆ˜ì§‘ (ì‹¤ìš©ì  ë°©ë²•)"""
    try:
        import requests
        import json
        
        # ì¹´ì¹´ì˜¤ë§µ ê²€ìƒ‰ API ì‚¬ìš© (ë” ì•ˆì •ì )
        search_query = f"{place_name} {address or ''}"
        
        # ì¹´ì¹´ì˜¤ë§µ ê²€ìƒ‰ API ì—”ë“œí¬ì¸íŠ¸
        kakao_api_url = "https://dapi.kakao.com/v2/local/search/keyword.json"
        
        # ì¹´ì¹´ì˜¤ API í‚¤ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        kakao_api_key = os.getenv("KAKAO_REST_API_KEY")
        
        if not kakao_api_key:
            print("ì¹´ì¹´ì˜¤ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        headers = {
            'Authorization': f'KakaoAK {kakao_api_key}',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        params = {
            'query': search_query,
            'category_group_code': 'HP8,MT1,CS2',  # ë³‘ì›, ì•½êµ­, ë¯¸ìš©ì‹¤
            'size': 15,
            'page': 1
        }
        
        response = requests.get(kakao_api_url, params=params, headers=headers, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            
            # ì¹´ì¹´ì˜¤ API ì‘ë‹µì—ì„œ ì´ë¯¸ì§€ URL ì¶”ì¶œ
            if 'documents' in data:
                for place in data['documents']:
                    # ë³‘ì›/ì˜ë£Œ ê´€ë ¨ ì¥ì†Œë§Œ í•„í„°ë§
                    if is_medical_place(place.get('category_name', ''), place.get('place_name', '')):
                        # ì¹´ì¹´ì˜¤ë§µì—ì„œ ì¶”ê°€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                        image_url = await get_kakao_place_detail_image(place.get('id'))
                        if image_url:
                            return image_url
        
        return None
        
    except Exception as e:
        print(f"ì¹´ì¹´ì˜¤ë§µ API ì˜¤ë¥˜: {e}")
        return None

async def get_kakao_place_detail_image(place_id: str) -> str:
    """ì¹´ì¹´ì˜¤ ì¥ì†Œ ìƒì„¸ ì •ë³´ì—ì„œ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°"""
    try:
        import requests
        
        kakao_api_key = os.getenv("KAKAO_REST_API_KEY")
        if not kakao_api_key:
            return None
        
        # ì¹´ì¹´ì˜¤ ì¥ì†Œ ìƒì„¸ ì •ë³´ API
        detail_url = f"https://dapi.kakao.com/v2/local/place/detail.json"
        
        headers = {
            'Authorization': f'KakaoAK {kakao_api_key}'
        }
        
        params = {
            'id': place_id
        }
        
        response = requests.get(detail_url, params=params, headers=headers, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            
            if 'result' in data and 'place' in data['result']:
                place_detail = data['result']['place']
                
                # ì´ë¯¸ì§€ URL ì¶”ì¶œ
                image_fields = ['photo', 'image', 'thumbnail', 'main_photo']
                
                for field in image_fields:
                    if field in place_detail and place_detail[field]:
                        image_url = place_detail[field]
                        if is_valid_image_url(image_url):
                            return normalize_image_url(image_url, 'kakao.com')
        
        return None
        
    except Exception as e:
        print(f"ì¹´ì¹´ì˜¤ ì¥ì†Œ ìƒì„¸ ì •ë³´ ì˜¤ë¥˜: {e}")
        return None

async def scrape_google_images(place_name: str, address: str = None) -> str:
    """Google Custom Search APIë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ìˆ˜ì§‘ (ì‹¤ìš©ì  ë°©ë²•)"""
    try:
        import requests
        
        # Google Custom Search API ì‚¬ìš© (ë” ì•ˆì •ì )
        google_api_key = os.getenv("GOOGLE_CUSTOM_SEARCH_API_KEY")
        google_cse_id = os.getenv("GOOGLE_CUSTOM_SEARCH_ENGINE_ID")
        
        if not google_api_key or not google_cse_id:
            print("Google Custom Search API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        # ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬ì„±
        search_query = f"{place_name} {address or ''} ë³‘ì› í´ë¦¬ë‹‰"
        
        # Google Custom Search API ì—”ë“œí¬ì¸íŠ¸
        google_api_url = "https://www.googleapis.com/customsearch/v1"
        
        params = {
            'key': google_api_key,
            'cx': google_cse_id,
            'q': search_query,
            'searchType': 'image',
            'num': 5,
            'imgSize': 'medium',
            'imgType': 'photo',
            'safe': 'medium'
        }
        
        response = requests.get(google_api_url, params=params, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            
            # Google API ì‘ë‹µì—ì„œ ì´ë¯¸ì§€ URL ì¶”ì¶œ
            if 'items' in data:
                for item in data['items']:
                    image_url = item.get('link')
                    if image_url and is_valid_image_url(image_url):
                        # ì´ë¯¸ì§€ í¬ê¸° ìµœì í™”
                        return optimize_google_image_url(image_url)
        
        return None
        
    except Exception as e:
        print(f"Google Custom Search API ì˜¤ë¥˜: {e}")
        return None

def optimize_google_image_url(image_url: str) -> str:
    """Google ì´ë¯¸ì§€ URL ìµœì í™”"""
    if not image_url:
        return image_url
    
    # Google ì´ë¯¸ì§€ URLì—ì„œ í¬ê¸° íŒŒë¼ë¯¸í„° ì¶”ê°€
    if 'googleusercontent.com' in image_url:
        # Google ì´ë¯¸ì§€ í¬ê¸° ìµœì í™”
        if '=w' not in image_url:
            image_url += '=w400-h200'
        else:
            # ê¸°ì¡´ í¬ê¸° íŒŒë¼ë¯¸í„°ë¥¼ 400x200ìœ¼ë¡œ ë³€ê²½
            import re
            image_url = re.sub(r'=w\d+-h\d+', '=w400-h200', image_url)
    
    return image_url

def is_valid_image_url(url: str) -> bool:
    """ìœ íš¨í•œ ì´ë¯¸ì§€ URLì¸ì§€ í™•ì¸"""
    if not url:
        return False
    
    # ì´ë¯¸ì§€ í™•ì¥ì í™•ì¸
    image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.webp']
    url_lower = url.lower()
    
    # URLì´ ì´ë¯¸ì§€ í™•ì¥ìë¡œ ëë‚˜ê±°ë‚˜ ì´ë¯¸ì§€ ê´€ë ¨ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê²½ìš°
    return (any(ext in url_lower for ext in image_extensions) or 
            any(keyword in url_lower for keyword in ['photo', 'image', 'thumb', 'place']))

def normalize_image_url(url: str, domain: str) -> str:
    """ì´ë¯¸ì§€ URL ì •ê·œí™”"""
    if not url:
        return url
    
    # ìƒëŒ€ URLì„ ì ˆëŒ€ URLë¡œ ë³€í™˜
    if url.startswith('//'):
        return 'https:' + url
    elif url.startswith('/'):
        return f'https://{domain}' + url
    elif not url.startswith('http'):
        return f'https://{domain}/{url}'
    
    return url

# MOZARA Hair Change ëª¨ë“ˆ
try:
    from services.hair_change.hair_change import generate_wig_style_service, get_wig_styles_service
    HAIR_CHANGE_AVAILABLE = True
    print("Hair Change ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"Hair Change ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    HAIR_CHANGE_AVAILABLE = False

# Hair Loss Daily ëª¨ë“ˆ - services í´ë” ë‚´ì— ìˆë‹¤ê³  ê°€ì •í•˜ê³  ê²½ë¡œ ìˆ˜ì •
try:
    # app ê°ì²´ë¥¼ ê°€ì ¸ì™€ ë§ˆìš´íŠ¸í•˜ê¸° ë•Œë¬¸ì—, ì´ íŒŒì¼ì— uvicorn ì‹¤í–‰ ì½”ë“œëŠ” ì—†ì–´ì•¼ í•©ë‹ˆë‹¤.
    from services.hair_loss_daily.api.hair_analysis_api import app as hair_analysis_app
    HAIR_ANALYSIS_AVAILABLE = True
    print("Hair Loss Daily ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"Hair Loss Daily ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    HAIR_ANALYSIS_AVAILABLE = False
    hair_analysis_app = None



# Pydantic ëª¨ë¸ ì •ì˜
class HairstyleResponse(BaseModel):
    result: str
    images: list
    message: str

class ErrorResponse(BaseModel):
    error: str

# ë©”ì¸ ì•± ìƒì„±
app = FastAPI(title="MOZARA Python Backend í†µí•©", version="1.0.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=False,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ëª¨ë“  ì‘ë‹µì— CORS í—¤ë”ë¥¼ ë³´ê°• (ì¼ë¶€ í™˜ê²½ì—ì„œ ëˆ„ë½ë˜ëŠ” ê²½ìš° ëŒ€ë¹„)
@app.middleware("http")
async def add_cors_headers(request, call_next):
    # ê°„ë‹¨í•œ ìš”ì²­ ë¡œê¹…
    try:
        print(f"[REQ] {request.method} {request.url.path}")
    except Exception:
        pass
    response = await call_next(request)
    response.headers["Access-Control-Allow-Origin"] = request.headers.get("origin", "*") or "*"
    response.headers["Vary"] = "Origin"
    response.headers["Access-Control-Allow-Headers"] = request.headers.get("access-control-request-headers", "*") or "*"
    response.headers["Access-Control-Allow-Methods"] = request.headers.get("access-control-request-method", "GET,POST,PUT,PATCH,DELETE,OPTIONS") or "GET,POST,PUT,PATCH,DELETE,OPTIONS"
    return response

# ë¼ìš°í„° ë§ˆìš´íŠ¸ (ì¡°ê±´ë¶€)
if HAIR_ANALYSIS_AVAILABLE and hair_analysis_app:
    # Hair Loss Daily APIë¥¼ /hair-loss-daily ê²½ë¡œì— ë§ˆìš´íŠ¸
    app.mount("/hair-loss-daily", hair_analysis_app)
    print("Hair Loss Daily ë¼ìš°í„° ë§ˆìš´íŠ¸ ì™„ë£Œ (/hair-loss-daily)")
else:
    index = None
    print("Hair Loss Daily ë¼ìš°í„° ë§ˆìš´íŠ¸ ê±´ë„ˆëœ€")

# OpenAI setup
openai_api_key = os.getenv("OPENAI_API_KEY")
if openai_api_key:
    from openai import OpenAI
    openai_client = OpenAI(api_key=openai_api_key)
    print("OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
else:
    openai_client = None
    print("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# Google Gemini setup
gemini_api_key = os.getenv("GEMINI_API_KEY")
google_api_key = os.getenv("GOOGLE_API_KEY")

if gemini_api_key:
    import google.generativeai as genai
    genai.configure(api_key=gemini_api_key)
    print("Google Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (GEMINI_API_KEY ì‚¬ìš©)")
elif google_api_key:
    import google.generativeai as genai
    genai.configure(api_key=google_api_key)
    print("Google Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (GOOGLE_API_KEY ì‚¬ìš©)")
else:
    genai = None
    print("GEMINI_API_KEY ë˜ëŠ” GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Gemini ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# Hair Encyclopedia ë¼ìš°í„° ë§ˆìš´íŠ¸
try:
    from services.hair_encyclopedia.paper_api import router as paper_router
    app.include_router(paper_router)
    print("Hair Encyclopedia Paper API ë¼ìš°í„° ë§ˆìš´íŠ¸ ì™„ë£Œ")
except ImportError as e:
    print(f"Hair Encyclopedia Paper API ë¼ìš°í„° ë§ˆìš´íŠ¸ ì‹¤íŒ¨: {e}")

# Gemini Hair Check ëª¨ë“ˆ
try:
    from services.hair_gemini_check import analyze_hair_with_gemini
    GEMINI_HAIR_CHECK_AVAILABLE = True
    print("Gemini Hair Check ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"Gemini Hair Check ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    GEMINI_HAIR_CHECK_AVAILABLE = False

# Swin Hair Classification ëª¨ë“ˆ
try:
    from services.swin_hair_classification.hair_swin_check import analyze_hair_with_swin
    SWIN_HAIR_CHECK_AVAILABLE = True
    print("Swin Hair Check ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"Swin Hair Check ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}")
    SWIN_HAIR_CHECK_AVAILABLE = False

# Gemini Hair Analysis Models
class HairAnalysisRequest(BaseModel):
    image_base64: str

class HairAnalysisResponse(BaseModel):
    stage: int
    title: str
    description: str
    advice: List[str]

# Gemini Hair Quiz Models
class QuizQuestion(BaseModel):
    question: str
    answer: str

class PaperDetail(BaseModel):
    id: str
    title: str
    source: str
    full_summary: str

class PaperAnalysis(BaseModel):
    id: str
    title: str
    source: str
    main_topics: List[str]
    key_conclusions: str
    section_summaries: List[dict]

class QuizGenerateResponse(BaseModel):
    items: List[QuizQuestion]

@app.get("/")

def read_root():
    """ë£¨íŠ¸ ê²½ë¡œ - ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "message": "MOZARA Python Backend í†µí•© ì„œë²„",
        "status": "running",
        "modules": {
            "hair_loss_daily": "/hair-loss-daily" if HAIR_ANALYSIS_AVAILABLE else "unavailable",
            "hair_change": "/generate_hairstyle" if HAIR_CHANGE_AVAILABLE else "unavailable",
            "basp_diagnosis": "/api/basp/evaluate" if BASP_AVAILABLE else "unavailable",
            "hair_gemini_check": "/hair_gemini_check" if GEMINI_HAIR_CHECK_AVAILABLE else "unavailable",
            "hair_swin_check": "/hair_swin_check" if SWIN_HAIR_CHECK_AVAILABLE else "unavailable"
        }
    }

@app.get("/health")

def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {"status": "healthy", "service": "python-backend-integrated"}

# --- Gemini íƒˆëª¨ ì‚¬ì§„ ë¶„ì„ ì „ìš© ì—”ë“œí¬ì¸íŠ¸ ---
@app.post("/hair_gemini_check")
async def api_hair_gemini_check(file: Annotated[UploadFile, File(...)]):
    """
    multipart/form-dataë¡œ ì „ì†¡ëœ ì´ë¯¸ì§€ë¥¼ Geminië¡œ ë¶„ì„í•˜ì—¬ í‘œì¤€ ê²°ê³¼ë¥¼ ë°˜í™˜
    """
    if not GEMINI_HAIR_CHECK_AVAILABLE:
        raise HTTPException(status_code=503, detail="Gemini ë¶„ì„ ëª¨ë“ˆì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    try:
        image_bytes = await file.read()
        print(f"--- [DEBUG] File received. Size: {len(image_bytes)} bytes ---")

        # bytes ë°ì´í„°ë¥¼ ì§ì ‘ ì „ë‹¬
        result = analyze_hair_with_gemini(image_bytes)

        return result
    except Exception as e:
        print(f"--- [DEBUG] Main Error: {str(e)} ---")
        raise HTTPException(status_code=500, detail=str(e))

# í”„ë¦¬í”Œë¼ì´íŠ¸ ìš”ì²­ ì²˜ë¦¬ (íŠ¹ì • ë¸Œë¼ìš°ì €/í”„ë¡ì‹œ í™˜ê²½ ëŒ€ì‘)
# @app.options("/api/hair_gemini_check")
# def options_hair_gemini_check():
#     return {"ok": True}

# @app.get("/api/hair_gemini_check/ping")
# def get_hair_gemini_check_ping():
#     return {"status": "ok"}

# --- Swin íƒˆëª¨ ì‚¬ì§„ ë¶„ì„ ì „ìš© ì—”ë“œí¬ì¸íŠ¸ ---
@app.post("/hair_swin_check")
async def api_hair_swin_check(
    top_image: Annotated[UploadFile, File(...)],
    side_image: Optional[UploadFile] = File(None),
    gender: Optional[str] = Form(None),
    age: Optional[str] = Form(None),
    familyHistory: Optional[str] = Form(None),
    recentHairLoss: Optional[str] = Form(None),
    stress: Optional[str] = Form(None)
):
    """
    multipart/form-dataë¡œ ì „ì†¡ëœ Top/Side ì´ë¯¸ì§€ë¥¼ Swinìœ¼ë¡œ ë¶„ì„í•˜ì—¬ í‘œì¤€ ê²°ê³¼ë¥¼ ë°˜í™˜
    Side ì´ë¯¸ì§€ëŠ” optional (ì—¬ì„±ì˜ ê²½ìš° ì—†ì„ ìˆ˜ ìˆìŒ)
    ì„¤ë¬¸ ë°ì´í„°ë„ í•¨ê»˜ ë°›ì•„ì„œ ë™ì  ê°€ì¤‘ì¹˜ ê³„ì‚°ì— ì‚¬ìš©
    """
    if not SWIN_HAIR_CHECK_AVAILABLE:
        raise HTTPException(status_code=503, detail="Swin ë¶„ì„ ëª¨ë“ˆì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    try:
        top_image_bytes = await top_image.read()
        side_image_bytes = None

        if side_image:
            side_image_bytes = await side_image.read()
            print(f"--- [DEBUG] Files received. Top: {len(top_image_bytes)} bytes, Side: {len(side_image_bytes)} bytes ---")
        else:
            print(f"--- [DEBUG] Files received. Top: {len(top_image_bytes)} bytes, Side: None (ì—¬ì„±) ---")

        # ì„¤ë¬¸ ë°ì´í„° êµ¬ì„±
        survey_data = None
        if age and familyHistory:
            survey_data = {
                'gender': gender,
                'age': age,
                'familyHistory': familyHistory,
                'recentHairLoss': recentHairLoss,
                'stress': stress
            }
            print(f"--- [DEBUG] Survey data: {survey_data} ---")

        # bytes ë°ì´í„°ì™€ ì„¤ë¬¸ ë°ì´í„°ë¥¼ í•¨ê»˜ ì „ë‹¬
        result = analyze_hair_with_swin(top_image_bytes, side_image_bytes, survey_data)

        return result
    except Exception as e:
        print(f"--- [DEBUG] Swin Error: {str(e)} ---")
        raise HTTPException(status_code=500, detail=str(e))
        
# --- ë„¤ì´ë²„ ì§€ì—­ ê²€ìƒ‰ API í”„ë¡ì‹œ ---
@app.get("/api/naver/local/search")
async def search_naver_local(query: str):
    """ë„¤ì´ë²„ ì§€ì—­ ê²€ìƒ‰ API í”„ë¡ì‹œ"""
    naver_client_id = os.getenv("NAVER_CLIENT_ID") or os.getenv("REACT_APP_NAVER_CLIENT_ID")
    naver_client_secret = os.getenv("NAVER_CLIENT_SECRET") or os.getenv("REACT_APP_NAVER_CLIENT_SECRET")

    if not naver_client_id or not naver_client_secret:
        raise HTTPException(status_code=503, detail="ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    try:
        import requests
        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë‹¤ë¥¸ ê²€ìƒ‰ì–´ ì „ëµ ì‚¬ìš©
        if "ë¯¸ìš©ì‹¤" in query or "í—¤ì–´ì‚´ë¡±" in query or "íƒˆëª¨ì „ìš©" in query:
            # íƒˆëª¨ë¯¸ìš©ì‹¤ ê²€ìƒ‰ ì‹œ ë” ê´‘ë²”ìœ„í•œ ë¯¸ìš©ì‹¤ ê²€ìƒ‰
            search_query = "íƒˆëª¨ ë¯¸ìš©ì‹¤ í—¤ì–´ì‚´ë¡±"
        elif "ê°€ë°œ" in query or "ì¦ëª¨ìˆ " in query:
            search_query = f"{query}"
        elif "ë¬¸ì‹ " in query or "smp" in query.lower():
            search_query = f"ë‘í”¼ë¬¸ì‹  SMP"
        elif "ì•½êµ­" in query:
            # íƒˆëª¨ì•½êµ­ ê²€ìƒ‰
            search_query = "ì•½êµ­"
        else:
            # íƒˆëª¨ë³‘ì› ê²€ìƒ‰ ì‹œ íƒˆëª¨ ê´€ë ¨ ì˜ë£Œê¸°ê´€ ê²€ìƒ‰
            if "íƒˆëª¨" in query or "ë³‘ì›" in query or "ì˜ì›" in query:
                search_query = "íƒˆëª¨ ë³‘ì› ì˜ì› í´ë¦¬ë‹‰ í”¼ë¶€ê³¼ ëª¨ë°œ"
            else:
                search_query = f"{query} ë³‘ì›"

        api_url = f"https://openapi.naver.com/v1/search/local.json"
        params = {
            "query": search_query,
            "display": 20,
            "sort": "comment"
        }

        headers = {
            "X-Naver-Client-Id": naver_client_id,
            "X-Naver-Client-Secret": naver_client_secret
        }

        response = requests.get(api_url, params=params, headers=headers)
        response.raise_for_status()

        data = response.json()
        
        # ê° í•­ëª©ì— ì´ë¯¸ì§€ URL ì¶”ê°€ (ë„¤ì´ë²„ API ìš°ì„  í™œìš©)
        if 'items' in data:
            for item in data['items']:
                # ë„¤ì´ë²„ ì§€ì—­ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì´ë¯¸ì§€ ì •ë³´ ì¶”ì¶œ ì‹œë„ (ë™ê¸° ë²„ì „)
                try:
                    import asyncio
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    image_url = loop.run_until_complete(get_naver_place_detail_image(item))
                    loop.close()
                    
                    if not image_url:
                        # ë„¤ì´ë²„ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ë‹¤ë¥¸ ì†ŒìŠ¤ ì‹œë„
                        image_url = get_best_image_url(
                            item.get('title', ''), 
                            item.get('address', ''), 
                            item.get('category', '')
                        )
                    item['imageUrl'] = image_url
                except Exception as e:
                    print(f"ë„¤ì´ë²„ ì´ë¯¸ì§€ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
                    # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©
                    item['imageUrl'] = get_best_image_url(
                        item.get('title', ''), 
                        item.get('address', ''), 
                        item.get('category', '')
                    )
        
        return data

    except Exception as e:
        print(f"ë„¤ì´ë²„ ì§€ì—­ ê²€ìƒ‰ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ë„¤ì´ë²„ API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")

# --- ì¹´ì¹´ì˜¤ ì¢Œí‘œ-ì£¼ì†Œ ë³€í™˜ API í”„ë¡ì‹œ (ì •ì‹/í˜¸í™˜ ì—”ë“œí¬ì¸íŠ¸ ì œê³µ) ---
@app.get("/api/kakao/local/geo/coord2address")
@app.get("/api/kakao/geo/coord2address")
async def get_address_from_coordinates(x: float, y: float):
    """ì¹´ì¹´ì˜¤ ì¢Œí‘œ-ì£¼ì†Œ ë³€í™˜ API í”„ë¡ì‹œ"""
    kakao_api_key = os.getenv("KAKAO_REST_API_KEY") or os.getenv("REACT_APP_KAKAO_REST_API_KEY")

    if not kakao_api_key:
        raise HTTPException(status_code=503, detail="ì¹´ì¹´ì˜¤ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    try:
        import requests

        api_url = "https://dapi.kakao.com/v2/local/geo/coord2address.json"
        params = {
            "x": x,
            "y": y
        }

        headers = {
            "Authorization": f"KakaoAK {kakao_api_key}"
        }

        response = requests.get(api_url, params=params, headers=headers, timeout=10)
        response.raise_for_status()

        return response.json()

    except Exception as e:
        print(f"ì¹´ì¹´ì˜¤ ì¢Œí‘œ-ì£¼ì†Œ ë³€í™˜ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì¹´ì¹´ì˜¤ ì¢Œí‘œ-ì£¼ì†Œ ë³€í™˜ ì‹¤íŒ¨: {str(e)}")

# ëŒ€ì•ˆ: ì¢Œí‘œ-í–‰ì •êµ¬ì—­ ì½”ë“œ ë³€í™˜ í”„ë¡ì‹œ
@app.get("/api/kakao/local/geo/coord2regioncode")
async def get_region_from_coordinates(x: float, y: float):
    kakao_api_key = os.getenv("KAKAO_REST_API_KEY") or os.getenv("REACT_APP_KAKAO_REST_API_KEY")
    if not kakao_api_key:
        raise HTTPException(status_code=503, detail="ì¹´ì¹´ì˜¤ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    try:
        import requests
        api_url = "https://dapi.kakao.com/v2/local/geo/coord2regioncode.json"
        params = {"x": x, "y": y}
        headers = {"Authorization": f"KakaoAK {kakao_api_key}"}
        response = requests.get(api_url, params=params, headers=headers, timeout=10)
        response.raise_for_status()
        return response.json()
    except Exception as e:
        print(f"ì¹´ì¹´ì˜¤ ì¢Œí‘œ-í–‰ì •êµ¬ì—­ ë³€í™˜ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì¹´ì¹´ì˜¤ ì¢Œí‘œ-í–‰ì •êµ¬ì—­ ë³€í™˜ ì‹¤íŒ¨: {str(e)}")

# --- ì¹´ì¹´ì˜¤ ì§€ì—­ ê²€ìƒ‰ API í”„ë¡ì‹œ ---
@app.get("/api/kakao/local/search")
async def search_kakao_local(
    query: str,
    x: Optional[float] = None,
    y: Optional[float] = None,
    radius: Optional[int] = 5000
):
    """ì¹´ì¹´ì˜¤ ì§€ì—­ ê²€ìƒ‰ API í”„ë¡ì‹œ"""
    kakao_api_key = os.getenv("KAKAO_REST_API_KEY") or os.getenv("REACT_APP_KAKAO_REST_API_KEY")

    if not kakao_api_key:
        raise HTTPException(status_code=503, detail="ì¹´ì¹´ì˜¤ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    try:
        import requests
        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë‹¤ë¥¸ ê²€ìƒ‰ì–´ ì „ëµ ì‚¬ìš©
        if "ë¯¸ìš©ì‹¤" in query or "í—¤ì–´ì‚´ë¡±" in query or "íƒˆëª¨ì „ìš©" in query:
            # íƒˆëª¨ë¯¸ìš©ì‹¤ ê²€ìƒ‰ ì‹œ ë” ê´‘ë²”ìœ„í•œ ë¯¸ìš©ì‹¤ ê²€ìƒ‰
            search_query = "íƒˆëª¨ ë¯¸ìš©ì‹¤ í—¤ì–´ì‚´ë¡±"
        elif "ê°€ë°œ" in query or "ì¦ëª¨ìˆ " in query:
            search_query = f"{query}"
        elif "ë¬¸ì‹ " in query or "smp" in query.lower():
            search_query = f"ë‘í”¼ë¬¸ì‹  SMP"
        elif "ì•½êµ­" in query:
            # íƒˆëª¨ì•½êµ­ ê²€ìƒ‰
            search_query = "ì•½êµ­"
        else:
            # íƒˆëª¨ë³‘ì› ê²€ìƒ‰ ì‹œ íƒˆëª¨ ê´€ë ¨ ì˜ë£Œê¸°ê´€ ê²€ìƒ‰
            if "íƒˆëª¨" in query or "ë³‘ì›" in query or "ì˜ì›" in query:
                search_query = "íƒˆëª¨ ë³‘ì› ì˜ì› í´ë¦¬ë‹‰ í”¼ë¶€ê³¼ ëª¨ë°œ"
            else:
                search_query = f"{query} ë³‘ì›"

        api_url = f"https://dapi.kakao.com/v2/local/search/keyword.json"
        params = {
            "query": search_query,
            "size": 15
        }

        if x is not None and y is not None:
            params["x"] = x
            params["y"] = y
            params["radius"] = radius

        headers = {
            "Authorization": f"KakaoAK {kakao_api_key}"
        }

        response = requests.get(api_url, params=params, headers=headers)
        response.raise_for_status()

        data = response.json()
        
        # ê° í•­ëª©ì— ì´ë¯¸ì§€ URL ì¶”ê°€ (ì¹´ì¹´ì˜¤ API ìš°ì„  í™œìš©)
        if 'documents' in data:
            for doc in data['documents']:
                # ì¹´ì¹´ì˜¤ ì¥ì†Œ ìƒì„¸ ì •ë³´ì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ ì‹œë„
                try:
                    import asyncio
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    image_url = loop.run_until_complete(get_kakao_place_detail_image(doc.get('id')))
                    loop.close()
                    
                    if not image_url:
                        # ì¹´ì¹´ì˜¤ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì§€ ëª»í•œ ê²½ìš° ë‹¤ë¥¸ ì†ŒìŠ¤ ì‹œë„
                        image_url = get_best_image_url(
                            doc.get('place_name', ''), 
                            doc.get('address_name', ''), 
                            doc.get('category_name', '')
                        )
                    doc['imageUrl'] = image_url
                except Exception as e:
                    print(f"ì¹´ì¹´ì˜¤ ì´ë¯¸ì§€ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
                    # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©
                    doc['imageUrl'] = get_best_image_url(
                        doc.get('place_name', ''), 
                        doc.get('address_name', ''), 
                        doc.get('category_name', '')
                    )
        
        return data

    except Exception as e:
        print(f"ì¹´ì¹´ì˜¤ ì§€ì—­ ê²€ìƒ‰ API ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì¹´ì¹´ì˜¤ API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")

# --- YouTube API í”„ë¡ì‹œ (ì¡°ê±´ë¶€) ---
@app.get("/youtube/search")
async def search_youtube_videos(q: str, order: str = "viewCount", max_results: int = 12):
    """YouTube API í”„ë¡ì‹œ - API í‚¤ë¥¼ ë°±ì—”ë“œì—ì„œ ê´€ë¦¬"""
    # URL ë””ì½”ë”© ì²˜ë¦¬
    import urllib.parse
    original_q = q
    q = urllib.parse.unquote(q)
    print(f"ğŸ” YouTube ê²€ìƒ‰ ìš”ì²­ - ì›ë³¸: {original_q}, ë””ì½”ë”©: {q}, ì •ë ¬: {order}, ìµœëŒ€ê²°ê³¼: {max_results}")
    
    try:
        import requests
        print("âœ… requests ëª¨ë“ˆ ë¡œë“œ ì„±ê³µ")
    except ImportError:
        print("âŒ requests ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨")
        raise HTTPException(status_code=500, detail="requests ëª¨ë“ˆì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install requestsë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    
    youtube_api_key = os.getenv("YOUTUBE_API_KEY")
    print(f"ğŸ”‘ YouTube API í‚¤ ìƒíƒœ: {'ì„¤ì •ë¨' if youtube_api_key and youtube_api_key != 'your_youtube_api_key_here' else 'ì„¤ì •ë˜ì§€ ì•ŠìŒ'}")
    
    try:
        api_url = f"https://www.googleapis.com/youtube/v3/search"
        params = {
            "part": "snippet",
            "q": q,
            "order": order,
            "type": "video",
            "maxResults": max_results,
            "key": youtube_api_key
        }
        
        print(f"ğŸŒ YouTube API í˜¸ì¶œ: {api_url}")
        print(f"ğŸ“‹ íŒŒë¼ë¯¸í„°: {params}")
        
        response = requests.get(api_url, params=params)
        print(f"ğŸ“¡ ì‘ë‹µ ìƒíƒœ: {response.status_code}")
        
        response.raise_for_status()
        
        result = response.json()
        print(f"âœ… YouTube API ì‘ë‹µ ì„±ê³µ: {len(result.get('items', []))}ê°œ ì˜ìƒ")
        return result
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ YouTube API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
        raise HTTPException(status_code=500, detail=f"YouTube API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")


    


# --- Hair Change API (ì¡°ê±´ë¶€) ---
if HAIR_CHANGE_AVAILABLE:
    @app.post('/generate_hairstyle', response_model=HairstyleResponse)
    async def generate_hairstyle(
        image: UploadFile = File(...),
        hairstyle: str = Form(...),
        custom_prompt: Optional[str] = Form(None)
    ):
        """ê°€ë°œ ìŠ¤íƒ€ì¼ ë³€ê²½ API"""
        image_data = await image.read()
        result = await generate_wig_style_service(image_data, hairstyle, custom_prompt)
        return HairstyleResponse(**result)

    @app.get('/hairstyles')
    async def get_hairstyles():
        """ì‚¬ìš© ê°€ëŠ¥í•œ ê°€ë°œ ìŠ¤íƒ€ì¼ ëª©ë¡ ë°˜í™˜"""
        return get_wig_styles_service()

# Hair Loss Products Service Import
from services.hair_loss_products import build_stage_response, search_11st_products

@app.get("/products")
async def get_hair_loss_products(
    stage: int = Query(..., description="íƒˆëª¨ ë‹¨ê³„ (0-3)", ge=0, le=3)
):
    """íƒˆëª¨ ë‹¨ê³„ë³„ ì œí’ˆ ì¶”ì²œ API"""
    try:
        print(f"íƒˆëª¨ ë‹¨ê³„ë³„ ì œí’ˆ ìš”ì²­: stage={stage}")
        
        # ì„œë¹„ìŠ¤ ê³„ì¸µì—ì„œ ê²°ê³¼ êµ¬ì„±
        result = build_stage_response(stage)
        
        print(f"ì„±ê³µ: {stage}ë‹¨ê³„ ì œí’ˆ {result.get('totalCount', 0)}ê°œ ë°˜í™˜")
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"íƒˆëª¨ ë‹¨ê³„ë³„ ì œí’ˆ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ì œí’ˆ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.get("/products/health")
async def products_health_check():
    """ì œí’ˆ ì¶”ì²œ ì„œë¹„ìŠ¤ í—¬ìŠ¤ì²´í¬"""
    return {
        "status": "healthy",
        "service": "hair-products-recommendation",
        "timestamp": datetime.now().isoformat()
    }


from services.hair_quiz.hair_quiz import (
    generate_hair_quiz_service,
)


@app.get("/11st/products")
async def get_11st_products(
    keyword: str = Query(..., description="ê²€ìƒ‰ í‚¤ì›Œë“œ"),
    page: int = Query(1, description="í˜ì´ì§€ ë²ˆí˜¸", ge=1),
    pageSize: int = Query(20, description="í˜ì´ì§€ í¬ê¸°", ge=1, le=100)
):
    """11ë²ˆê°€ ì œí’ˆ ê²€ìƒ‰ API"""
    try:
        print(f"11ë²ˆê°€ ì œí’ˆ ê²€ìƒ‰ ìš”ì²­: keyword={keyword}, page={page}, pageSize={pageSize}")
        
        # ì„œë¹„ìŠ¤ ê³„ì¸µì—ì„œ 11ë²ˆê°€ ì œí’ˆ ê²€ìƒ‰ (ì´ë¯¸ ìœ„ì—ì„œ importë¨)
        result = search_11st_products(keyword, page, pageSize)
        
        print(f"ì„±ê³µ: 11ë²ˆê°€ì—ì„œ {len(result['products'])}ê°œ ì œí’ˆ ì¡°íšŒ")
        return result
        
    except Exception as e:
        print(f"11ë²ˆê°€ ì œí’ˆ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(
            status_code=500,
            detail="ì œí’ˆ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )

@app.post("/refresh")
async def refresh_token():
    """í† í° ê°±ì‹  API (ì„ì‹œ êµ¬í˜„)"""
    try:
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” JWT í† í° ê°±ì‹  ë¡œì§ì´ í•„ìš”
        # í˜„ì¬ëŠ” ì„ì‹œë¡œ ì„±ê³µ ì‘ë‹µ ë°˜í™˜
        return {
            "message": "í† í° ê°±ì‹  ì™„ë£Œ",
            "status": "success"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/paper/{paper_id}", response_model=PaperDetail)
async def get_paper_detail(paper_id: str):
    if not index:
        raise HTTPException(status_code=503, detail="Thesis search service is not available")
    
    try:
        results = index.fetch(ids=[paper_id])
        vectors = results.vectors
        if not vectors:
            raise HTTPException(status_code=404, detail="Paper not found")
        
        vector_obj = vectors.get(paper_id)
        if vector_obj is None:
            raise HTTPException(status_code=404, detail="Paper not found")
        
        metadata = getattr(vector_obj, 'metadata', None)
        if metadata is None and isinstance(vector_obj, dict):
            metadata = vector_obj.get('metadata', {})
        if metadata is None:
            metadata = {}
        
        full_summary = (
            metadata.get('summary') or
            metadata.get('full_summary') or
            metadata.get('text', '')
        )
        
        title_safe = str(metadata.get('title', 'Unknown')).encode('utf-8', errors='ignore').decode('utf-8')
        source_safe = str(metadata.get('source', 'Unknown')).encode('utf-8', errors='ignore').decode('utf-8')
        summary_safe = str(full_summary).encode('utf-8', errors='ignore').decode('utf-8')
        
        return PaperDetail(
            id=paper_id,
            title=title_safe,
            source=source_safe,
            full_summary=summary_safe
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/papers/count")
async def get_papers_count():
    if not index:
        return {"count": 0, "system": "service_disabled"}
    
    try:
        results = index.query(
            vector=[0.0] * 1536,
            top_k=10000,
            include_metadata=True
        )
        
        unique_papers = set()
        for match in results['matches']:
            metadata = match.get('metadata', {})
            file_path = metadata.get('file_path')
            if file_path:
                unique_papers.add(file_path)
        
        return {"count": len(unique_papers), "system": "pinecone_deduped"}
    except Exception as e:
        return {"count": 0, "system": "error", "error": str(e)}

@app.get("/paper/{paper_id}/analysis", response_model=PaperAnalysis)
async def get_paper_analysis(paper_id: str):
    if not index:
        raise HTTPException(status_code=503, detail="Thesis search service is not available")
    
    try:
        results = index.fetch(ids=[paper_id])
        vectors = results.vectors
        if not vectors:
            raise HTTPException(status_code=404, detail="Chunk not found")

        clicked_chunk_metadata = vectors[paper_id].metadata if paper_id in vectors else {}
        original_file_path = clicked_chunk_metadata.get('file_path')
        original_title = clicked_chunk_metadata.get('title')

        if not original_file_path:
            raise HTTPException(status_code=404, detail="Original paper path not found for this chunk.")

        analysis_results = index.query(
            vector=[0.0] * 1536,
            top_k=1,
            include_metadata=True,
            filter={
                "file_path": original_file_path,
                "chunk_index": 0
            }
        )

        if not analysis_results['matches']:
            raise HTTPException(status_code=404, detail="Structured analysis for paper not found.")

        paper_analysis_metadata = analysis_results['matches'][0].metadata

        main_topics_parsed = []
        raw_main_topics = paper_analysis_metadata.get('main_topics')
        if isinstance(raw_main_topics, list):
            main_topics_parsed = [str(t).encode('utf-8', errors='ignore').decode('utf-8') for t in raw_main_topics if isinstance(t, str)]
        elif isinstance(raw_main_topics, str):
            safe_topics = raw_main_topics.encode('utf-8', errors='ignore').decode('utf-8')
            main_topics_parsed = [safe_topics]

        raw_conclusions = paper_analysis_metadata.get('key_conclusions', '')
        key_conclusions_parsed = str(raw_conclusions).encode('utf-8', errors='ignore').decode('utf-8')

        section_summaries_parsed = []
        raw_section_summaries = paper_analysis_metadata.get('section_summaries')
        
        if isinstance(raw_section_summaries, str):
            try:
                safe_json_string = raw_section_summaries.encode('utf-8', errors='ignore').decode('utf-8')
                temp_parsed = json.loads(safe_json_string)
                if isinstance(temp_parsed, list):
                    section_summaries_parsed = []
                    for s in temp_parsed:
                        if isinstance(s, dict):
                            safe_section = {}
                            for key, value in s.items():
                                safe_key = str(key).encode('utf-8', errors='ignore').decode('utf-8')
                                safe_value = str(value).encode('utf-8', errors='ignore').decode('utf-8')
                                safe_section[safe_key] = safe_value
                            section_summaries_parsed.append(safe_section)
            except json.JSONDecodeError:
                pass
        elif isinstance(raw_section_summaries, list):
            section_summaries_parsed = []
            for s in raw_section_summaries:
                if isinstance(s, dict):
                    safe_section = {}
                    for key, value in s.items():
                        safe_key = str(key).encode('utf-8', errors='ignore').decode('utf-8')
                        safe_value = str(value).encode('utf-8', errors='ignore').decode('utf-8')
                        safe_section[safe_key] = safe_value
                    section_summaries_parsed.append(safe_section)
        
        if not section_summaries_parsed:
            section_summaries_parsed = []

        title_raw = paper_analysis_metadata.get('title', original_title or 'Unknown')
        title_safe = str(title_raw).encode('utf-8', errors='ignore').decode('utf-8')
        
        source_raw = paper_analysis_metadata.get('source', 'Unknown')
        source_safe = str(source_raw).encode('utf-8', errors='ignore').decode('utf-8')

        return PaperAnalysis(
            id=paper_id,
            title=title_safe,
            source=source_safe,
            main_topics=main_topics_parsed,
            key_conclusions=key_conclusions_parsed,
            section_summaries=section_summaries_parsed
        )

    except Exception as e:
        print(f"ì„¤ì • ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=500,
            detail="ì„¤ì • ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )

@app.get("/api/location/status")
async def get_location_status():
    """ìœ„ì¹˜ ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ API"""
    naver_client_id = os.getenv("NAVER_CLIENT_ID") or os.getenv("REACT_APP_NAVER_CLIENT_ID")
    naver_client_secret = os.getenv("NAVER_CLIENT_SECRET") or os.getenv("REACT_APP_NAVER_CLIENT_SECRET")
    kakao_api_key = os.getenv("KAKAO_REST_API_KEY") or os.getenv("REACT_APP_KAKAO_REST_API_KEY")

    return {
        "status": "ok",
        "message": "Location API ì„œë²„ê°€ ì •ìƒì ìœ¼ë¡œ ë™ì‘ ì¤‘ì…ë‹ˆë‹¤.",
        "naverApiConfigured": bool(naver_client_id and naver_client_secret),
        "kakaoApiConfigured": bool(kakao_api_key),
    }



# --- Gemini Hair Quiz API ---
@app.post("/hair-quiz/generate", response_model=QuizGenerateResponse)
async def generate_hair_quiz():
    """Geminië¡œ O/X íƒˆëª¨ í€´ì¦ˆ 20ë¬¸í•­ ìƒì„± (ì„œë¹„ìŠ¤ë¡œ ìœ„ì„)"""
    try:
        items = generate_hair_quiz_service()
        return {"items": items}
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except RuntimeError as e:
        raise HTTPException(status_code=503, detail=str(e))
    except Exception as e:
        print(f"Gemini í€´ì¦ˆ ìƒì„± ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"í€´ì¦ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.get("/hair-quiz/health")
async def hair_quiz_health_check():
    """í€´ì¦ˆ ìƒì„± ì„œë¹„ìŠ¤ í—¬ìŠ¤ì²´í¬"""
    return {
        "status": "healthy" if genai else "unavailable",
        "service": "gemini-hair-quiz",
        "timestamp": datetime.now().isoformat()
    }


# --- Location Services API ---
@app.get("/location/naver/search")
async def search_naver_local(query: str):
    """ë„¤ì´ë²„ ë¡œì»¬ ê²€ìƒ‰ API í”„ë¡ì‹œ"""
    try:
        naver_client_id = os.getenv("NAVER_CLIENT_ID")
        naver_client_secret = os.getenv("NAVER_CLIENT_SECRET")

        if not naver_client_id or not naver_client_secret:
            return {
                "error": "ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "items": []
            }

        import requests

        url = "https://openapi.naver.com/v1/search/local.json"
        headers = {
            'X-Naver-Client-Id': naver_client_id,
            'X-Naver-Client-Secret': naver_client_secret,
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

        params = {
            'query': query,
            'display': 20,
            'sort': 'comment'
        }

        response = requests.get(url, params=params, headers=headers, timeout=10)

        if response.status_code == 200:
            data = response.json()
            return data
        else:
            return {
                "error": f"ë„¤ì´ë²„ API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}",
                "items": []
            }

    except Exception as e:
        print(f"ë„¤ì´ë²„ ë¡œì»¬ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return {
            "error": f"ë„¤ì´ë²„ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "items": []
        }

@app.get("/location/kakao/search")
async def search_kakao_local(
    query: str,
    x: Optional[float] = None,
    y: Optional[float] = None,
    radius: Optional[int] = 5000
):
    """ì¹´ì¹´ì˜¤ ë¡œì»¬ ê²€ìƒ‰ API í”„ë¡ì‹œ"""
    try:
        kakao_api_key = os.getenv("KAKAO_REST_API_KEY")

        if not kakao_api_key:
            return {
                "error": "ì¹´ì¹´ì˜¤ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.",
                "documents": []
            }

        import requests

        url = "https://dapi.kakao.com/v2/local/search/keyword.json"
        headers = {
            'Authorization': f'KakaoAK {kakao_api_key}',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }

        params = {
            'query': query,
            'size': 15
        }

        # ì¢Œí‘œ ê¸°ë°˜ ê²€ìƒ‰ì´ ìš”ì²­ëœ ê²½ìš°
        if x is not None and y is not None:
            params['x'] = x
            params['y'] = y
            params['radius'] = radius

        response = requests.get(url, params=params, headers=headers, timeout=10)

        if response.status_code == 200:
            data = response.json()
            return data
        else:
            return {
                "error": f"ì¹´ì¹´ì˜¤ API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}",
                "documents": []
            }

    except Exception as e:
        print(f"ì¹´ì¹´ì˜¤ ë¡œì»¬ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return {
            "error": f"ì¹´ì¹´ì˜¤ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            "documents": []
        }

@app.get("/location/status")
async def location_service_status():
    """ìœ„ì¹˜ ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸"""
    naver_client_id = os.getenv("NAVER_CLIENT_ID")
    naver_client_secret = os.getenv("NAVER_CLIENT_SECRET")
    kakao_api_key = os.getenv("KAKAO_REST_API_KEY")

    return {
        "status": "ok",
        "message": "Python ìœ„ì¹˜ ì„œë¹„ìŠ¤ê°€ ì •ìƒì ìœ¼ë¡œ ë™ì‘ ì¤‘ì…ë‹ˆë‹¤.",
        "naverApiConfigured": bool(naver_client_id and naver_client_secret),
        "kakaoApiConfigured": bool(kakao_api_key),
        "timestamp": datetime.now().isoformat()
    }


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)