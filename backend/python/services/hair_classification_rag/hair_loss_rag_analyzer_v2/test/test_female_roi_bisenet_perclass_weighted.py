#!/usr/bin/env python3
r"""
Female Hair Loss - BiSeNet ROI-based Per-Class Weighted Ensemble (Stage 1-5)
BiSeNetìœ¼ë¡œ ë‘í”¼ ì˜ì—­ ì¶”ì¶œ í›„ ROI embedding ê¸°ë°˜ Per-Class ìµœì  ê°€ì¤‘ì¹˜ ì•™ìƒë¸” í…ŒìŠ¤íŠ¸

í…ŒìŠ¤íŠ¸ ëŒ€ìƒ: C:\Users\301\Desktop\female_classification\test\selected_test (stage_1..stage_5)
ë°©ì‹: BiSeNet ì„¸ê·¸ë©˜í…Œì´ì…˜ â†’ ROI embedding â†’ Per-Class ìµœì  ê°€ì¤‘ì¹˜ ì ìš©
í•„í„°: gender=female, embedding_type=roi
ê°€ì¤‘ì¹˜: weight(female_full+1)/ensemble_config.json ì‚¬ìš©

ë¡œê·¸ ì¶œë ¥: result_log/log/female_roi_bisenet_perclass_test{N}/
"""

import os
import re
import json
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
from PIL import Image, ImageEnhance
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report

import torch
import torchvision.transforms as T
import timm
from dotenv import load_dotenv
from pinecone import Pinecone


# ---------- ê²½ë¡œ/ì„¤ì • ----------
LOG_BASE_PATH = Path(r"C:\Users\301\Desktop\main_project\backend\python\services\hair_classification_rag\result_log\log")
TEST_ROOT = Path(r"C:\Users\301\Desktop\female_classification\test\selected_test")  # stage_1..stage_5
ENV_PATH = r"C:\Users\301\Desktop\main_project\.env"
WEIGHT_CONFIG_PATH = Path(r"C:\Users\301\Desktop\main_project\backend\python\services\hair_classification_rag\result_log\tester\weight\weight(female_full+1)\ensemble_config.json")

INDEX_CONV = "hair-loss-rag-analyzer"
INDEX_VIT = "hair-loss-vit-s16"

NUM_CLASSES = 5  # Stage 1-5 (5 classes)
CLASS_OFFSET = 1  # Start from stage 1
TOP_K = 10
T_CONV = 0.15
T_VIT = 0.20


# ---------- ìœ í‹¸/ì „ì²˜ë¦¬ ----------
def ensure_dir(p: Path):
    p.mkdir(parents=True, exist_ok=True)


def enhance_image(img: Image.Image) -> Image.Image:
    img = ImageEnhance.Sharpness(img).enhance(1.05)
    img = ImageEnhance.Contrast(img).enhance(1.05)
    img = ImageEnhance.Brightness(img).enhance(1.03)
    img = ImageEnhance.Color(img).enhance(1.03)
    return img


def simulate_bisenet_segmentation(img: Image.Image) -> Image.Image:
    """
    BiSeNet ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œë®¬ë ˆì´ì…˜
    ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” BiSeNet ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‘í”¼ ì˜ì—­ì„ ì •í™•íˆ ì¶”ì¶œ
    í˜„ì¬ëŠ” ì¤‘ì•™ 70% ì˜ì—­ì„ ROIë¡œ í¬ë¡­í•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜
    """
    width, height = img.size
    left = int(width * 0.15)
    top = int(height * 0.15)
    right = int(width * 0.85)
    bottom = int(height * 0.85)

    # ROI ì¶”ì¶œ
    roi_img = img.crop((left, top, right, bottom))

    # ì›ë³¸ í¬ê¸°ë¡œ resize (ëª¨ë¸ ì…ë ¥ í¬ê¸° ë§ì¶”ê¸°)
    roi_img = roi_img.resize((width, height), Image.Resampling.LANCZOS)

    return roi_img


def tf_vit():
    return T.Compose([
        T.Resize(224, interpolation=T.InterpolationMode.BICUBIC),
        T.CenterCrop(224),
        T.ToTensor(),
        T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
    ])


def tf_conv():
    return T.Compose([
        T.Resize(384, interpolation=T.InterpolationMode.BICUBIC),
        T.CenterCrop(384),
        T.ToTensor(),
        T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
    ])


def load_models(device: str = "cpu"):
    vit = timm.create_model("vit_small_patch16_224", pretrained=True, num_classes=0, global_pool="avg").eval().to(device)
    conv = timm.create_model("convnext_large.fb_in22k_ft_in1k_384", pretrained=True, num_classes=0, global_pool="avg").eval().to(device)
    return vit, conv


def embed(img: Image.Image, model, transform) -> np.ndarray:
    if img.mode != "RGB":
        img = img.convert("RGB")
    img = enhance_image(img)
    x = transform(img).unsqueeze(0)
    with torch.no_grad():
        z = model(x).cpu().numpy()[0]
    z = z / (np.linalg.norm(z) + 1e-12)
    return z


def knn_to_probs(matches: List[Dict], num_classes=NUM_CLASSES, T=0.20) -> np.ndarray:
    if not matches:
        return np.zeros(num_classes, dtype=float)
    sims = np.array([m["score"] for m in matches], float)
    w = np.exp(sims / T)
    w = w / (w.sum() + 1e-12)
    probs = np.zeros(num_classes, float)
    for wi, m in zip(w, matches):
        md = m.get("metadata", {})
        # stage í‚¤ ìš°ì„ , ì—†ìœ¼ë©´ level/label ì¶”ì •
        if "stage" in md:
            try:
                st = int(md["stage"])
            except (ValueError, TypeError):
                st = None
        else:
            st = None
            for k in ("level", "class", "label"):
                v = md.get(k)
                if isinstance(v, str):
                    mm = re.search(r"(\d+)", v)
                    if mm:
                        st = int(mm.group(1))
                        break
            if st is None:
                src = m.get("id") or ""
                mm = re.search(r"(\d+)", str(src))
                st = int(mm.group(1)) if mm else 0
        if 1 <= st <= 5:  # Stage 1-5
            probs[st - CLASS_OFFSET] += wi
    s = probs.sum()
    return probs / s if s > 0 else probs


def predict_with_roi(pc: Pinecone, idx_conv, idx_vit, img_path: Path, vit, conv, tf_v, tf_c) -> Tuple[Dict, Dict]:
    """
    BiSeNet ROI ê¸°ë°˜ ì˜ˆì¸¡ ë° íƒ€ì´ë° ì •ë³´ ë°˜í™˜
    Returns: (timing_dict, (p_conv, p_vit))
    """
    timings = {}

    # ì´ë¯¸ì§€ ë¡œë”©
    t0 = time.perf_counter()
    img = Image.open(img_path)
    timings['image_load'] = time.perf_counter() - t0

    # BiSeNet ì„¸ê·¸ë©˜í…Œì´ì…˜ (ë‘í”¼ ì˜ì—­ ì¶”ì¶œ)
    t0 = time.perf_counter()
    roi_img = simulate_bisenet_segmentation(img)
    timings['bisenet_segmentation'] = time.perf_counter() - t0

    # ROI ViT Embedding
    t0 = time.perf_counter()
    vq_roi = embed(roi_img, vit, tf_v)
    timings['roi_vit_embed'] = time.perf_counter() - t0

    # ROI ConvNeXt Embedding
    t0 = time.perf_counter()
    cq_roi = embed(roi_img, conv, tf_c)
    timings['roi_conv_embed'] = time.perf_counter() - t0

    # ViT ROI Search (gender=female, embedding_type=roi í•„í„°)
    t0 = time.perf_counter()
    r_v = idx_vit.query(
        vector=vq_roi.tolist(),
        top_k=TOP_K,
        include_metadata=True,
        filter={"gender": "female", "embedding_type": "roi"}
    )
    timings['roi_vit_search'] = time.perf_counter() - t0

    # ConvNeXt ROI Search (gender=female, embedding_type=roi í•„í„°)
    t0 = time.perf_counter()
    r_c = idx_conv.query(
        vector=cq_roi.tolist(),
        top_k=TOP_K,
        include_metadata=True,
        filter={"gender": "female", "embedding_type": "roi"}
    )
    timings['roi_conv_search'] = time.perf_counter() - t0

    # KNN to Probs
    t0 = time.perf_counter()
    p_v = knn_to_probs(r_v.get("matches", []), NUM_CLASSES, T=T_VIT)
    p_c = knn_to_probs(r_c.get("matches", []), NUM_CLASSES, T=T_CONV)
    timings['knn_probs'] = time.perf_counter() - t0

    return timings, (p_c, p_v)


def perclass_weighted_ensemble(p_conv: np.ndarray, p_vit: np.ndarray,
                                weights_conv: np.ndarray, weights_vit: np.ndarray,
                                strong_conv: List[int], strong_vit: List[int],
                                tau_conv: List[float], tau_vit: List[float]) -> Tuple[int, np.ndarray, Dict]:
    """
    Per-class ìµœì  ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì•™ìƒë¸” (Override ë¡œì§ í¬í•¨)

    Args:
        p_conv: ConvNeXt í™•ë¥  ë¶„í¬
        p_vit: ViT í™•ë¥  ë¶„í¬
        weights_conv: í´ë˜ìŠ¤ë³„ ConvNeXt ê°€ì¤‘ì¹˜ (5ê°œ)
        weights_vit: í´ë˜ìŠ¤ë³„ ViT ê°€ì¤‘ì¹˜ (5ê°œ)
        strong_conv: ConvNeXt strong weight í”Œë˜ê·¸ (5ê°œ)
        strong_vit: ViT strong weight í”Œë˜ê·¸ (5ê°œ)
        tau_conv: ConvNeXt override ì„ê³„ê°’ (5ê°œ)
        tau_vit: ViT override ì„ê³„ê°’ (5ê°œ)

    Returns:
        - pred: ì˜ˆì¸¡ stage (1-based)
        - P_ens: ì•™ìƒë¸” í™•ë¥  ë¶„í¬
        - weights_info: ì‚¬ìš©ëœ ê°€ì¤‘ì¹˜ ì •ë³´
    """
    # Override ë¡œì§ ì²´í¬
    override_applied = False
    override_info = None

    for c in range(NUM_CLASSES):
        if strong_conv[c] == 1 and p_conv[c] >= tau_conv[c]:
            # ConvNeXt override
            pred = c + CLASS_OFFSET
            P_ens = np.zeros(NUM_CLASSES)
            P_ens[c] = 1.0
            override_applied = True
            override_info = {
                'type': 'conv',
                'stage': pred,
                'confidence': float(p_conv[c]),
                'threshold': tau_conv[c]
            }
            break
        elif strong_vit[c] == 1 and p_vit[c] >= tau_vit[c]:
            # ViT override
            pred = c + CLASS_OFFSET
            P_ens = np.zeros(NUM_CLASSES)
            P_ens[c] = 1.0
            override_applied = True
            override_info = {
                'type': 'vit',
                'stage': pred,
                'confidence': float(p_vit[c]),
                'threshold': tau_vit[c]
            }
            break

    if not override_applied:
        # Per-class ê°€ì¤‘ì¹˜ë¡œ ì•™ìƒë¸”
        P_ens = weights_conv * p_conv + weights_vit * p_vit

        # ì •ê·œí™”
        s = P_ens.sum()
        if s > 0:
            P_ens = P_ens / s

        pred = int(np.argmax(P_ens)) + CLASS_OFFSET

    weights_info = {
        'override_applied': override_applied,
        'override_info': override_info,
        'weights_conv': weights_conv.tolist(),
        'weights_vit': weights_vit.tolist(),
        'pred_stage': pred,
    }

    return pred, P_ens, weights_info


def load_weight_config(config_path: Path) -> Dict:
    """ê°€ì¤‘ì¹˜ ì„¤ì • íŒŒì¼ ë¡œë“œ"""
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
    return config


def collect_test_set(root: Path) -> List[Tuple[Path, int]]:
    """í…ŒìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘ (stage_1 ~ stage_5)"""
    items = []
    if not root.exists():
        return items

    for stage in range(1, 6):  # stage_1 ~ stage_5
        stage_dir = root / f"stage_{stage}"
        if not stage_dir.exists():
            print(f"[WARN] {stage_dir} does not exist, skipping.")
            continue

        stage_files = []
        for fp in stage_dir.iterdir():
            if fp.is_file() and fp.suffix.lower() in ['.jpg', '.jpeg', '.png']:
                stage_files.append(fp)

        print(f"Stage {stage}: {len(stage_files)}ê°œ íŒŒì¼ ë°œê²¬")

        for fp in stage_files:
            items.append((fp, stage))

    return items


def next_test_number(base: Path, prefix: str) -> int:
    if not base.exists():
        return 1
    nums = []
    for d in base.iterdir():
        if d.is_dir() and d.name.startswith(prefix):
            s = d.name.replace(prefix, "")
            try:
                nums.append(int(s))
            except:
                pass
    return max(nums) + 1 if nums else 1


def main():
    print("="*80)
    print("Female Hair Loss - BiSeNet ROI-based Per-Class Weighted Ensemble Test (Stage 1-5)")
    print("="*80)

    # ê°€ì¤‘ì¹˜ ì„¤ì • ë¡œë“œ
    if not WEIGHT_CONFIG_PATH.exists():
        print(f"[ERROR] ê°€ì¤‘ì¹˜ ì„¤ì • íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {WEIGHT_CONFIG_PATH}")
        return

    weight_config = load_weight_config(WEIGHT_CONFIG_PATH)
    print(f"ê°€ì¤‘ì¹˜ ì„¤ì • ë¡œë“œ ì™„ë£Œ: {WEIGHT_CONFIG_PATH}")

    weights_conv = np.array(weight_config['config']['weights']['conv'])
    weights_vit = np.array(weight_config['config']['weights']['vit'])
    strong_conv = weight_config['config']['strong']['conv']
    strong_vit = weight_config['config']['strong']['vit']
    tau_conv = weight_config['config']['tau']['conv']
    tau_vit = weight_config['config']['tau']['vit']

    print("\nìµœì  ê°€ì¤‘ì¹˜ ì„¤ì •:")
    for i in range(NUM_CLASSES):
        print(f"  Stage {i+CLASS_OFFSET}: ConvNeXt={weights_conv[i]:.3f}, ViT={weights_vit[i]:.3f}")

    # ë¡œë“œ
    load_dotenv(ENV_PATH)
    pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
    idx_conv = pc.Index(INDEX_CONV)
    idx_vit = pc.Index(INDEX_VIT)

    device = "cpu"
    print("\nLoading models...")
    vit, conv = load_models(device)
    tf_v, tf_c = tf_vit(), tf_conv()

    # ë¡œê·¸ ë””ë ‰í† ë¦¬ êµ¬ì„±
    prefix = "female_roi_bisenet_perclass_test"
    test_no = next_test_number(LOG_BASE_PATH, prefix)
    folder_name = f"{prefix}{test_no}"
    log_dir = LOG_BASE_PATH / folder_name
    ensure_dir(log_dir)

    # í…ŒìŠ¤íŠ¸ì…‹ ìˆ˜ì§‘
    test_items = collect_test_set(TEST_ROOT)
    if not test_items:
        print(f"[ERROR] í…ŒìŠ¤íŠ¸ì…‹ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {TEST_ROOT}")
        return

    print(f"ì´ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {len(test_items)}ê°œ")

    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    results = []
    y_true = []
    y_pred = []

    # íƒ€ì´ë° í†µê³„
    all_timings = {
        'image_load': [],
        'bisenet_segmentation': [],
        'roi_vit_embed': [],
        'roi_conv_embed': [],
        'roi_vit_search': [],
        'roi_conv_search': [],
        'knn_probs': [],
        'ensemble': [],
    }

    # Override í†µê³„
    override_stats = {'count': 0, 'conv': 0, 'vit': 0}

    total_start = time.time()

    for fp, st in test_items:
        try:
            # ROI ê¸°ë°˜ ì˜ˆì¸¡ ë° íƒ€ì´ë°
            timings, (p_c, p_v) = predict_with_roi(pc, idx_conv, idx_vit, fp, vit, conv, tf_v, tf_c)

            # Per-class ê°€ì¤‘ì¹˜ ì•™ìƒë¸”
            t0 = time.perf_counter()
            pred, p_ens, weights_info = perclass_weighted_ensemble(
                p_c, p_v, weights_conv, weights_vit,
                strong_conv, strong_vit, tau_conv, tau_vit
            )
            timings['ensemble'] = time.perf_counter() - t0

            # Override í†µê³„
            if weights_info['override_applied']:
                override_stats['count'] += 1
                if weights_info['override_info']['type'] == 'conv':
                    override_stats['conv'] += 1
                else:
                    override_stats['vit'] += 1

            # íƒ€ì´ë° ì €ì¥
            for key in all_timings.keys():
                all_timings[key].append(timings[key])

            results.append({
                "image_path": str(fp),
                "filename": fp.name,
                "true_stage": st,
                "pred_stage": pred,
                "probs": p_ens.tolist(),
                "weights": weights_info,
                "timings": timings,
            })
            y_true.append(st - CLASS_OFFSET)  # stage 1-5 -> 0-4
            y_pred.append(pred - CLASS_OFFSET)

        except Exception as e:
            print(f"[skip test] {fp}: {e}")

    total_time = time.time() - total_start
    print(f"Test inference done on {len(y_true)} images in {total_time:.1f}s")

    if not y_true:
        print("[ERROR] No test predictions produced.")
        return

    # ë©”íŠ¸ë¦­ ê³„ì‚°
    acc = accuracy_score(y_true, y_pred)
    precision, recall, f1, support = precision_recall_fscore_support(
        y_true, y_pred, labels=list(range(NUM_CLASSES)), average='weighted', zero_division=0
    )

    # íƒ€ì´ë° í†µê³„ ê³„ì‚°
    timing_stats = {}
    for key, values in all_timings.items():
        if values:
            timing_stats[key] = {
                'mean': np.mean(values) * 1000,  # ms
                'std': np.std(values) * 1000,
                'min': np.min(values) * 1000,
                'max': np.max(values) * 1000,
            }

    # ë¦¬í¬íŠ¸ ì €ì¥
    with open(log_dir / "report.txt", "w", encoding="utf-8") as f:
        f.write("=" * 80 + "\n")
        f.write(f"Female Hair Loss - BiSeNet ROI-based Per-Class Weighted Ensemble - Test #{test_no}\n")
        f.write("=" * 80 + "\n")
        f.write(f"í…ŒìŠ¤íŠ¸ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {TEST_ROOT}\n")
        f.write(f"ëŒ€ìƒ ìŠ¤í…Œì´ì§€: Stage 1-5 (ì´ {NUM_CLASSES}ê°œ í´ë˜ìŠ¤)\n")
        f.write(f"ì¸ë±ìŠ¤: ConvNeXt='{INDEX_CONV}', ViT='{INDEX_VIT}'\n")
        f.write(f"íŒŒë¼ë¯¸í„°: top_k={TOP_K}, Tconv={T_CONV}, Tvit={T_VIT}\n")
        f.write(f"ì•™ìƒë¸” ë°©ì‹: Per-Class ìµœì  ê°€ì¤‘ì¹˜ (Full Embedding ìµœì í™”)\n")
        f.write(f"ROI ì¶”ì¶œ: BiSeNet ì„¸ê·¸ë©˜í…Œì´ì…˜\n")
        f.write(f"í•„í„°: gender=female, embedding_type=roi\n")
        f.write(f"ê°€ì¤‘ì¹˜ ì„¤ì •: {WEIGHT_CONFIG_PATH}\n\n")

        f.write("ğŸ“Š ì „ì²´ ê²°ê³¼\n")
        f.write("-" * 40 + "\n")
        f.write(f"ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {len(y_true)}\n")
        f.write(f"ì •í™•ë„ (Accuracy): {acc:.3f}\n")
        f.write(f"ì •ë°€ë„ (Precision): {precision:.3f}\n")
        f.write(f"ì¬í˜„ìœ¨ (Recall): {recall:.3f}\n")
        f.write(f"F1-Score: {f1:.3f}\n")
        f.write(f"ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ\n")
        f.write(f"ì´ë¯¸ì§€ë‹¹ í‰ê·  ì‹œê°„: {total_time/len(y_true)*1000:.1f}ms\n\n")

        f.write("ğŸ“ ìŠ¤í…Œì´ì§€ë³„ í…ŒìŠ¤íŠ¸ íŒŒì¼ ìˆ˜\n")
        f.write("-" * 40 + "\n")
        stage_counts = {}
        for _, st in test_items:
            stage_counts[st] = stage_counts.get(st, 0) + 1
        for stage in sorted(stage_counts.keys()):
            f.write(f"Stage {stage}: {stage_counts[stage]}ê°œ íŒŒì¼\n")
        f.write("\n")

        f.write("âš–ï¸ Per-Class ìµœì  ê°€ì¤‘ì¹˜\n")
        f.write("-" * 40 + "\n")
        for i in range(NUM_CLASSES):
            stage = i + CLASS_OFFSET
            f.write(f"Stage {stage}: ConvNeXt={weights_conv[i]:.3f}, ViT={weights_vit[i]:.3f}")
            if strong_conv[i] == 1:
                f.write(f" [ConvNeXt Strong, Ï„={tau_conv[i]:.2f}]")
            elif strong_vit[i] == 1:
                f.write(f" [ViT Strong, Ï„={tau_vit[i]:.2f}]")
            f.write(f" (F1={weight_config['config']['f1']['conv'][i]:.3f})\n")
        f.write("\n")

        f.write("ğŸ¯ Override í†µê³„\n")
        f.write("-" * 40 + "\n")
        f.write(f"ì´ Override ì ìš©: {override_stats['count']}íšŒ ({override_stats['count']/len(y_true)*100:.1f}%)\n")
        f.write(f"  - ConvNeXt Override: {override_stats['conv']}íšŒ\n")
        f.write(f"  - ViT Override: {override_stats['vit']}íšŒ\n\n")

        f.write("ğŸ¯ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ (Stage 1-5)\n")
        f.write("-" * 40 + "\n")
        cls_dict = classification_report(
            y_true, y_pred, labels=list(range(NUM_CLASSES)), zero_division=0, output_dict=True
        )
        for c in range(NUM_CLASSES):
            stage = c + CLASS_OFFSET
            key = str(c)
            if key in cls_dict:
                cr = cls_dict[key]
                f.write(f"Stage {stage}: ì •ë°€ë„={cr['precision']:.3f}, ì¬í˜„ìœ¨={cr['recall']:.3f}, F1={cr['f1-score']:.3f}, Support={cr['support']}\n")
        f.write("\n")

        f.write("â±ï¸ ë‹¨ê³„ë³„ ì²˜ë¦¬ ì‹œê°„ í†µê³„ (ë°€ë¦¬ì´ˆ)\n")
        f.write("-" * 40 + "\n")
        f.write(f"{'Step':<25} {'Mean':<10} {'Std':<10} {'Min':<10} {'Max':<10}\n")
        f.write("-" * 40 + "\n")

        step_names = {
            'image_load': 'Image Loading',
            'bisenet_segmentation': 'BiSeNet Segmentation',
            'roi_vit_embed': 'ROI ViT Embedding',
            'roi_conv_embed': 'ROI ConvNeXt Embedding',
            'roi_vit_search': 'ROI ViT Search',
            'roi_conv_search': 'ROI ConvNeXt Search',
            'knn_probs': 'KNN Probability',
            'ensemble': 'Ensemble',
        }

        for key, name in step_names.items():
            if key in timing_stats:
                stats = timing_stats[key]
                f.write(f"{name:<25} {stats['mean']:<10.2f} {stats['std']:<10.2f} {stats['min']:<10.2f} {stats['max']:<10.2f}\n")

        # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œê°„
        total_pipeline_mean = sum(timing_stats[k]['mean'] for k in step_names.keys() if k in timing_stats)
        f.write("-" * 40 + "\n")
        f.write(f"{'Total Pipeline':<25} {total_pipeline_mean:<10.2f}\n")
        f.write("\n")

        f.write("ğŸ”¬ Per-Class Weighted ë°©ì‹ì˜ íŠ¹ì§•\n")
        f.write("-" * 40 + "\n")
        f.write("âœ“ BiSeNetìœ¼ë¡œ ë‘í”¼ ì˜ì—­ë§Œ ì •í™•íˆ ì¶”ì¶œ\n")
        f.write("âœ“ ë°°ê²½/ì–¼êµ´ ë“± ë…¸ì´ì¦ˆ ì œê±°\n")
        f.write("âœ“ ROI embedding DBì™€ ë¹„êµí•˜ì—¬ ì •í™•ë„ í–¥ìƒ\n")
        f.write("âœ“ Full embedding ìµœì í™” ê°€ì¤‘ì¹˜ë¥¼ ROIì— ì ìš©\n")
        f.write("âœ“ Stageë³„ë¡œ ìµœì í™”ëœ ê³ ì • ê°€ì¤‘ì¹˜ ì‚¬ìš©\n")
        f.write("âœ“ Override ë¡œì§ìœ¼ë¡œ ê³ ì‹ ë¢°ë„ ì˜ˆì¸¡ ê°•í™”\n\n")

        f.write("ğŸ’¡ ì¥ì \n")
        f.write("-" * 40 + "\n")
        f.write("âœ“ Full embeddingìœ¼ë¡œ ìµœì í™”ëœ ê°€ì¤‘ì¹˜ í™œìš©\n")
        f.write("âœ“ Stageë³„ ëª¨ë¸ ê°•ì•½ì  ë°˜ì˜\n")
        f.write("âœ“ ROI ê¸°ë°˜ìœ¼ë¡œ íƒˆëª¨ ì˜ì—­ì—ë§Œ ì§‘ì¤‘\n")
        f.write("âœ“ Override ë¡œì§ìœ¼ë¡œ í™•ì‹¤í•œ ê²½ìš° ì¦‰ì‹œ íŒë‹¨\n")
        f.write("âœ“ ì•ˆì •ì ì´ê³  ì¬í˜„ ê°€ëŠ¥í•œ ì„±ëŠ¥\n")

    # Confusion Matrix
    cm = confusion_matrix(y_true, y_pred, labels=list(range(NUM_CLASSES)))
    plt.rcParams['font.family'] = ['DejaVu Sans', 'sans-serif']
    plt.rcParams['axes.unicode_minus'] = False
    plt.figure(figsize=(10, 8))
    labels = [f"Stage {i + CLASS_OFFSET}" for i in range(NUM_CLASSES)]
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
    plt.title(f'Female BiSeNet ROI Per-Class Weighted Ensemble Confusion Matrix\nTest #{test_no}')
    plt.ylabel('True Stage')
    plt.xlabel('Predicted Stage')
    plt.tight_layout()
    plt.savefig(log_dir / "confusion_matrix.png", dpi=300, bbox_inches='tight')
    plt.close()

    # Performance chart
    import pandas as pd
    pd.DataFrame(results).to_csv(log_dir / "results.csv", index=False, encoding="utf-8-sig")

    plt.figure(figsize=(10, 6))
    names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
    vals = [acc, precision, recall, f1]
    bars = plt.bar(names, vals, color=['#3498db', '#e74c3c', '#27ae60', '#f39c12'])
    plt.ylim(0, 1)
    for b, v in zip(bars, vals):
        plt.text(b.get_x() + b.get_width() / 2, v + 0.01, f"{v:.3f}", ha='center', va='bottom')
    plt.title(f'Female BiSeNet ROI Per-Class Weighted Ensemble Performance\nTest #{test_no}')
    plt.tight_layout()
    plt.savefig(log_dir / "performance_metrics.png", dpi=300, bbox_inches='tight')
    plt.close()

    # Timing chart
    plt.figure(figsize=(12, 6))
    step_labels = list(step_names.values())
    step_means = [timing_stats[k]['mean'] for k in step_names.keys() if k in timing_stats]
    step_stds = [timing_stats[k]['std'] for k in step_names.keys() if k in timing_stats]

    bars = plt.bar(range(len(step_labels)), step_means, yerr=step_stds, capsize=5,
                   color=['#3498db', '#27ae60', '#e74c3c', '#f39c12', '#9b59b6', '#1abc9c', '#34495e', '#95a5a6'])
    plt.xticks(range(len(step_labels)), step_labels, rotation=45, ha='right')
    plt.ylabel('Time (ms)')
    plt.title(f'ROI Pipeline Step Timing Analysis\nTest #{test_no}')
    plt.grid(axis='y', alpha=0.3)
    plt.tight_layout()
    plt.savefig(log_dir / "timing_analysis.png", dpi=300, bbox_inches='tight')
    plt.close()

    # Weight comparison chart
    plt.figure(figsize=(10, 6))
    x = np.arange(NUM_CLASSES)
    width = 0.35
    stage_labels = [f"Stage {i+CLASS_OFFSET}" for i in range(NUM_CLASSES)]

    bars1 = plt.bar(x - width/2, weights_conv, width, label='ConvNeXt', color='#3498db')
    bars2 = plt.bar(x + width/2, weights_vit, width, label='ViT', color='#e74c3c')

    plt.xlabel('Stage')
    plt.ylabel('Weight')
    plt.title(f'Per-Class Optimal Weights Distribution\nTest #{test_no}')
    plt.xticks(x, stage_labels)
    plt.ylim(0, 1.1)
    plt.legend()
    plt.grid(axis='y', alpha=0.3)

    # ê°’ í‘œì‹œ
    for bars in [bars1, bars2]:
        for bar in bars:
            height = bar.get_height()
            plt.text(bar.get_x() + bar.get_width()/2., height + 0.02,
                    f'{height:.2f}', ha='center', va='bottom', fontsize=9)

    plt.tight_layout()
    plt.savefig(log_dir / "weight_distribution.png", dpi=300, bbox_inches='tight')
    plt.close()

    # ì„¤ì • íŒŒì¼ ì €ì¥
    config_out = log_dir / "test_config.json"
    with open(config_out, "w", encoding="utf-8") as f:
        json.dump({
            "method": "roi_bisenet_perclass_weighted_ensemble",
            "index_conv": INDEX_CONV,
            "index_vit": INDEX_VIT,
            "top_k": TOP_K,
            "Tconv": T_CONV,
            "Tvit": T_VIT,
            "num_classes": NUM_CLASSES,
            "filter": {"gender": "female", "embedding_type": "roi"},
            "roi_extraction": "BiSeNet (simulated)",
            "weight_config_source": str(WEIGHT_CONFIG_PATH),
            "weights": {
                "conv": weights_conv.tolist(),
                "vit": weights_vit.tolist(),
            },
            "strong_weights": {
                "conv": strong_conv,
                "vit": strong_vit,
            },
            "tau_thresholds": {
                "conv": tau_conv,
                "vit": tau_vit,
            },
            "override_stats": override_stats,
            "timing_stats": {k: {kk: float(vv) for kk, vv in v.items()}
                           for k, v in timing_stats.items()},
        }, f, ensure_ascii=False, indent=2)

    print(f"\n{'=' * 80}")
    print(f"Female BiSeNet ROI Per-Class Weighted Ensemble Test ì™„ë£Œ! - Test #{test_no}")
    print(f"{'=' * 80}")
    print(f"ì´ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {len(y_true)}ê°œ")
    print(f"ì •í™•ë„: {acc:.3f}")
    print(f"F1-Score: {f1:.3f}")
    print(f"Override ì ìš©: {override_stats['count']}íšŒ ({override_stats['count']/len(y_true)*100:.1f}%)")
    print(f"í‰ê·  ì²˜ë¦¬ ì‹œê°„: {total_pipeline_mean:.1f}ms/image")
    print(f"ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {log_dir}")
    print(f"{'=' * 80}")


if __name__ == "__main__":
    main()
