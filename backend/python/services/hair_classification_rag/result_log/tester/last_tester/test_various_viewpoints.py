#!/usr/bin/env python3
"""
ë‹¤ì–‘í•œ Viewpointë¥¼ í¬í•¨í•œ Hair Loss Analyzer ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ê° ë ˆë²¨ë‹¹ 20ê±´ì”© ëœë¤ ìƒ˜í”Œë§í•˜ì—¬ í…ŒìŠ¤íŠ¸
"""

import os
import sys
import json
import time
import asyncio
import random
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple
import numpy as np
import pandas as pd
from PIL import Image
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import (
    confusion_matrix, classification_report,
    accuracy_score, precision_recall_fscore_support
)

# ë°±ì—”ë“œ ëª¨ë“ˆ importë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
backend_path = Path("C:/Users/301/Desktop/main_project/backend/hair_classification/hair_loss_rag_analyzer_v1/backend")
sys.path.append(str(backend_path))

# í•˜ë“œì½”ë”©ëœ ê²½ë¡œë¡œ config ìš°íšŒ
class HardcodedSettings:
    UPLOAD_DIR = "C:/Users/301/Desktop/main_project/backend/hair_classification/hair_loss_rag_analyzer_v1/backend/uploads"
    INDEX_NAME = "hair-loss-rag-analysis-convnext"
    EMBEDDING_DIMENSION = 1536
    MODEL_NAME = "convnext_large.fb_in22k_ft_in1k_384"

    # íƒˆëª¨ ë‹¨ê³„ ì„¤ëª…
    STAGE_DESCRIPTIONS = {
        2: "ê²½ë¯¸í•œ íƒˆëª¨ - Mì íƒˆëª¨ê°€ ì‹œì‘ë˜ê±°ë‚˜ ì´ë§ˆì„ ì´ ì•½ê°„ í›„í‡´",
        3: "ì´ˆê¸° íƒˆëª¨ - Mì íƒˆëª¨ê°€ ëšœë ·í•´ì§€ê³  ì •ìˆ˜ë¦¬ ë¶€ë¶„ ëª¨ë°œ ë°€ë„ ê°ì†Œ",
        4: "ì¤‘ê¸° íƒˆëª¨ - Mì íƒˆëª¨ ì§„í–‰, ì •ìˆ˜ë¦¬ íƒˆëª¨ ë³¸ê²©í™”",
        5: "ì§„í–‰ëœ íƒˆëª¨ - ì•ë¨¸ë¦¬ì™€ ì •ìˆ˜ë¦¬ íƒˆëª¨ê°€ ì—°ê²°ë˜ê¸° ì‹œì‘",
        6: "ì‹¬í•œ íƒˆëª¨ - ì•ë¨¸ë¦¬ì™€ ì •ìˆ˜ë¦¬ê°€ ì™„ì „íˆ ì—°ê²°ë˜ì–´ í•˜ë‚˜ì˜ í° íƒˆëª¨ ì˜ì—­ í˜•ì„±",
        7: "ë§¤ìš° ì‹¬í•œ íƒˆëª¨ - ì¸¡ë©´ê³¼ ë’·ë¨¸ë¦¬ë¥¼ ì œì™¸í•œ ëŒ€ë¶€ë¶„ì˜ ëª¨ë°œ ì†ì‹¤"
    }

# configë¥¼ ì§ì ‘ ë®ì–´ì“°ê¸°
from app.services.hair_loss_analyzer import HairLossAnalyzer


def get_next_test_number(base_log_path: Path) -> int:
    """ë‹¤ìŒ í…ŒìŠ¤íŠ¸ ë²ˆí˜¸ ê²°ì •"""
    if not base_log_path.exists():
        return 1

    existing_tests = [d for d in base_log_path.iterdir() if d.is_dir() and d.name.startswith('test_viewpoint')]
    if not existing_tests:
        return 1

    test_numbers = []
    for test_dir in existing_tests:
        try:
            num = int(test_dir.name.replace('test_viewpoint', ''))
            test_numbers.append(num)
        except ValueError:
            continue

    return max(test_numbers) + 1 if test_numbers else 1


class VariousViewpointTester:
    def __init__(self, test_data_path: str, base_log_path: str, samples_per_level: int = 20):
        """
        ë‹¤ì–‘í•œ Viewpoint í…ŒìŠ¤í„° ì´ˆê¸°í™”

        Args:
            test_data_path: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ê²½ë¡œ
            base_log_path: ê¸°ë³¸ ë¡œê·¸ ì €ì¥ ê²½ë¡œ
            samples_per_level: ë ˆë²¨ë‹¹ ìƒ˜í”Œ ê°œìˆ˜
        """
        self.test_data_path = Path(test_data_path)
        self.base_log_path = Path(base_log_path)
        self.samples_per_level = samples_per_level

        # ë‹¤ìŒ í…ŒìŠ¤íŠ¸ ë²ˆí˜¸ ê²°ì •
        self.test_number = get_next_test_number(self.base_log_path)
        self.result_log_path = self.base_log_path / f"test_viewpoint{self.test_number}"

        self.analyzer = None
        self.test_results = []

        # ê²°ê³¼ ë¡œê·¸ ë””ë ‰í„°ë¦¬ ìƒì„±
        self.result_log_path.mkdir(parents=True, exist_ok=True)

        print(f"í…ŒìŠ¤íŠ¸ ë²ˆí˜¸: viewpoint{self.test_number}")
        print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ: {self.test_data_path}")
        print(f"ë ˆë²¨ë‹¹ ìƒ˜í”Œ ê°œìˆ˜: {self.samples_per_level}")
        print(f"ê²°ê³¼ ë¡œê·¸ ê²½ë¡œ: {self.result_log_path}")

    async def initialize_analyzer(self):
        """HairLossAnalyzer ì´ˆê¸°í™”"""
        try:
            print("HairLossAnalyzer ì´ˆê¸°í™” ì¤‘...")
            self.analyzer = HairLossAnalyzer()
            print("HairLossAnalyzer ì´ˆê¸°í™” ì™„ë£Œ")
            return True
        except Exception as e:
            print(f"HairLossAnalyzer ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    def load_test_data(self) -> Dict[int, List[Path]]:
        """
        í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ë° ìƒ˜í”Œë§ (ë ˆë²¨ 2-7)

        Returns:
            Dict[int, List[Path]]: {ë ˆë²¨: [ì´ë¯¸ì§€_ê²½ë¡œ_ë¦¬ìŠ¤íŠ¸]}
        """
        test_data = {}

        for level in range(2, 8):  # ë ˆë²¨ 2-7 í…ŒìŠ¤íŠ¸
            level_path = self.test_data_path / f"level_{level}" / f"LEVEL_{level}"

            if not level_path.exists():
                print(f"ê²½ê³ : ë ˆë²¨ {level} í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {level_path}")
                continue

            # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
            image_files = []
            for ext in ['.jpg', '.jpeg', '.png', '.bmp']:
                image_files.extend(list(level_path.glob(f"*{ext}")))
                image_files.extend(list(level_path.glob(f"*{ext.upper()}")))

            # ì¤‘ë³µ ì œê±°
            image_files = list(set(image_files))

            # ëœë¤ ìƒ˜í”Œë§
            if len(image_files) > self.samples_per_level:
                random.seed(42)  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•´
                sampled_files = random.sample(image_files, self.samples_per_level)
            else:
                sampled_files = image_files
                print(f"ê²½ê³ : ë ˆë²¨ {level}ì— {len(image_files)}ê°œ ì´ë¯¸ì§€ë§Œ ìˆì–´ì„œ ëª¨ë‘ ì‚¬ìš©í•©ë‹ˆë‹¤.")

            test_data[level] = sampled_files
            print(f"ë ˆë²¨ {level}: {len(sampled_files)}ê°œ ì´ë¯¸ì§€ íŒŒì¼ (ì „ì²´ {len(image_files)}ê°œ ì¤‘)")

            # ë·°í¬ì¸íŠ¸ ë¶„ì„
            viewpoint_counts = {}
            for img_path in sampled_files:
                filename = img_path.name.lower()
                if 'top-down' in filename or 'top_down' in filename:
                    viewpoint = 'top-down'
                elif 'front' in filename:
                    viewpoint = 'front'
                elif 'left' in filename:
                    viewpoint = 'left'
                elif 'right' in filename:
                    viewpoint = 'right'
                elif 'back' in filename:
                    viewpoint = 'back'
                else:
                    viewpoint = 'unknown'

                viewpoint_counts[viewpoint] = viewpoint_counts.get(viewpoint, 0) + 1

            print(f"  ë·°í¬ì¸íŠ¸ ë¶„í¬: {viewpoint_counts}")

        total_images = sum(len(files) for files in test_data.values())
        print(f"ì´ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {total_images}ê°œ")

        return test_data

    async def test_single_image(self, image_path: Path, true_level: int) -> Dict:
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸

        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            true_level: ì‹¤ì œ íƒˆëª¨ ë ˆë²¨

        Returns:
            Dict: í…ŒìŠ¤íŠ¸ ê²°ê³¼
        """
        try:
            # ë·°í¬ì¸íŠ¸ ì¶”ì¶œ
            filename = image_path.name.lower()
            if 'top-down' in filename or 'top_down' in filename:
                viewpoint = 'top-down'
            elif 'front' in filename:
                viewpoint = 'front'
            elif 'left' in filename:
                viewpoint = 'left'
            elif 'right' in filename:
                viewpoint = 'right'
            elif 'back' in filename:
                viewpoint = 'back'
            else:
                viewpoint = 'unknown'

            # ì´ë¯¸ì§€ ë¡œë“œ
            image = Image.open(image_path).convert('RGB')

            # ë¶„ì„ ì‹œì‘ ì‹œê°„
            start_time = time.time()

            # ë¶„ì„ ì‹¤í–‰ (LLM ë¹„í™œì„±í™”: ConvNeXt+RAG ì „ìš© ì„±ëŠ¥ ì¸¡ì •, ë·°í¬ì¸íŠ¸ í•„í„° ì ìš©)
            result = await self.analyzer.analyze_image(image, image_path.name, use_llm=False, viewpoint=viewpoint)

            # ë¶„ì„ ì¢…ë£Œ ì‹œê°„
            end_time = time.time()
            analysis_time = end_time - start_time

            if result['success']:
                return {
                    'image_path': str(image_path),
                    'filename': image_path.name,
                    'viewpoint': viewpoint,
                    'true_level': true_level,
                    'predicted_level': result['predicted_stage'],
                    'confidence': result['confidence'],
                    'analysis_time': analysis_time,
                    'stage_scores': result.get('stage_scores', {}),
                    'success': True,
                    'error': None
                }
            else:
                return {
                    'image_path': str(image_path),
                    'filename': image_path.name,
                    'viewpoint': viewpoint,
                    'true_level': true_level,
                    'predicted_level': None,
                    'confidence': 0.0,
                    'analysis_time': analysis_time,
                    'stage_scores': {},
                    'success': False,
                    'error': result.get('error', 'Unknown error')
                }

        except Exception as e:
            return {
                'image_path': str(image_path),
                'filename': image_path.name,
                'viewpoint': 'unknown',
                'true_level': true_level,
                'predicted_level': None,
                'confidence': 0.0,
                'analysis_time': 0.0,
                'stage_scores': {},
                'success': False,
                'error': str(e)
            }

    async def run_tests(self):
        """ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ë‹¤ì–‘í•œ Viewpoint Hair Loss Analyzer ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")

        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
        test_data = self.load_test_data()

        if not test_data:
            print("í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ì• ë„ë¼ì´ì € ì´ˆê¸°í™”
        if not await self.initialize_analyzer():
            return

        # ê° ë ˆë²¨ë³„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        for level, image_files in test_data.items():
            print(f"\në ˆë²¨ {level} í…ŒìŠ¤íŠ¸ ì¤‘... ({len(image_files)}ê°œ ì´ë¯¸ì§€)")

            for i, image_path in enumerate(image_files):
                print(f"  {i+1}/{len(image_files)}: {image_path.name}")

                result = await self.test_single_image(image_path, level)
                self.test_results.append(result)

                if not result['success']:
                    print(f"    ì‹¤íŒ¨: {result['error']}")
                else:
                    print(f"    ì˜ˆì¸¡: {result['predicted_level']} (ì‹ ë¢°ë„: {result['confidence']:.3f}, ë·°: {result['viewpoint']})")

        print(f"\nì´ {len(self.test_results)}ê°œ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

    def calculate_metrics(self) -> Dict:
        """ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°"""
        print("\nì„±ëŠ¥ ì§€í‘œ ê³„ì‚° ì¤‘...")

        # ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ë§Œ í•„í„°ë§
        successful_results = [r for r in self.test_results if r['success'] and r['predicted_level'] is not None]

        if not successful_results:
            print("ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {}

        # ì‹¤ì œ ë ˆë²¨ê³¼ ì˜ˆì¸¡ ë ˆë²¨ ì¶”ì¶œ
        y_true = [r['true_level'] for r in successful_results]
        y_pred = [r['predicted_level'] for r in successful_results]

        # ê¸°ë³¸ ì§€í‘œ ê³„ì‚°
        accuracy = accuracy_score(y_true, y_pred)
        precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred, average='weighted')

        # í´ë˜ìŠ¤ë³„ ì§€í‘œ
        class_report = classification_report(y_true, y_pred, output_dict=True)

        # ì»¨í“¨ì „ ë©”íŠ¸ë¦­ìŠ¤
        cm = confusion_matrix(y_true, y_pred, labels=[2,3,4,5,6,7])

        # í‰ê·  ë¶„ì„ ì‹œê°„
        avg_analysis_time = np.mean([r['analysis_time'] for r in successful_results])

        # ì‹ ë¢°ë„ í†µê³„
        confidences = [r['confidence'] for r in successful_results]
        avg_confidence = np.mean(confidences)

        # ë·°í¬ì¸íŠ¸ë³„ ì •í™•ë„
        viewpoint_accuracy = {}
        for viewpoint in ['top-down', 'front', 'left', 'right', 'back', 'unknown']:
            viewpoint_results = [r for r in successful_results if r['viewpoint'] == viewpoint]
            if viewpoint_results:
                vp_y_true = [r['true_level'] for r in viewpoint_results]
                vp_y_pred = [r['predicted_level'] for r in viewpoint_results]
                vp_accuracy = accuracy_score(vp_y_true, vp_y_pred)
                viewpoint_accuracy[viewpoint] = {
                    'accuracy': vp_accuracy,
                    'count': len(viewpoint_results)
                }

        metrics = {
            'total_tests': len(self.test_results),
            'successful_tests': len(successful_results),
            'failed_tests': len(self.test_results) - len(successful_results),
            'success_rate': len(successful_results) / len(self.test_results),
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'avg_analysis_time': avg_analysis_time,
            'avg_confidence': avg_confidence,
            'confusion_matrix': cm.tolist(),
            'class_report': class_report,
            'unique_labels': sorted(list(set(y_true + y_pred))),
            'viewpoint_accuracy': viewpoint_accuracy
        }

        return metrics

    def create_visualizations(self, metrics: Dict):
        """ì‹œê°í™” ìƒì„±"""
        print("\nì‹œê°í™” ìƒì„± ì¤‘...")

        # 1. ì»¨í“¨ì „ ë©”íŠ¸ë¦­ìŠ¤ íˆíŠ¸ë§µ
        plt.figure(figsize=(10, 8))
        cm = np.array(metrics['confusion_matrix'])
        labels = metrics['unique_labels']

        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=labels, yticklabels=labels)
        plt.title(f'Various Viewpoint Test{self.test_number} - Confusion Matrix')
        plt.xlabel('Predicted Level')
        plt.ylabel('True Level')
        plt.tight_layout()

        confusion_matrix_path = self.result_log_path / "confusion_matrix.png"
        plt.savefig(confusion_matrix_path, dpi=300, bbox_inches='tight')
        plt.close()

        # 2. ì„±ëŠ¥ ì§€í‘œ ë°” ì°¨íŠ¸
        plt.figure(figsize=(10, 6))
        metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
        metrics_values = [metrics['accuracy'], metrics['precision'], metrics['recall'], metrics['f1_score']]

        bars = plt.bar(metrics_names, metrics_values, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])
        plt.ylim(0, 1)
        plt.title(f'Various Viewpoint Test{self.test_number} - Performance Metrics')
        plt.ylabel('Score')

        for bar, value in zip(bars, metrics_values):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{value:.3f}', ha='center', va='bottom')

        plt.tight_layout()
        metrics_chart_path = self.result_log_path / "performance_metrics.png"
        plt.savefig(metrics_chart_path, dpi=300, bbox_inches='tight')
        plt.close()

        # 3. ë·°í¬ì¸íŠ¸ë³„ ì •í™•ë„ ì°¨íŠ¸
        plt.figure(figsize=(12, 6))
        viewpoint_data = metrics['viewpoint_accuracy']
        viewpoints = list(viewpoint_data.keys())
        accuracies = [viewpoint_data[vp]['accuracy'] for vp in viewpoints]
        counts = [viewpoint_data[vp]['count'] for vp in viewpoints]

        bars = plt.bar(viewpoints, accuracies, color='skyblue')
        plt.ylim(0, 1)
        plt.title(f'Various Viewpoint Test{self.test_number} - Accuracy by Viewpoint')
        plt.ylabel('Accuracy')
        plt.xlabel('Viewpoint')

        # ê°œìˆ˜ ì •ë³´ ì¶”ê°€
        for bar, acc, count in zip(bars, accuracies, counts):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{acc:.3f}\n({count})', ha='center', va='bottom')

        plt.xticks(rotation=45)
        plt.tight_layout()
        viewpoint_chart_path = self.result_log_path / "viewpoint_accuracy.png"
        plt.savefig(viewpoint_chart_path, dpi=300, bbox_inches='tight')
        plt.close()

        print(f"ì»¨í“¨ì „ ë©”íŠ¸ë¦­ìŠ¤ ì €ì¥: {confusion_matrix_path}")
        print(f"ì„±ëŠ¥ ì§€í‘œ ì°¨íŠ¸ ì €ì¥: {metrics_chart_path}")
        print(f"ë·°í¬ì¸íŠ¸ë³„ ì •í™•ë„ ì°¨íŠ¸ ì €ì¥: {viewpoint_chart_path}")

    def save_results(self, metrics: Dict):
        """ê²°ê³¼ ì €ì¥"""
        print("\nê²°ê³¼ ì €ì¥ ì¤‘...")

        # ë ˆë²¨ë³„ ì´ë¯¸ì§€ ìˆ˜ ê³„ì‚°
        level_counts = {}
        viewpoint_counts = {}
        for result in self.test_results:
            level = result['true_level']
            viewpoint = result['viewpoint']
            level_counts[level] = level_counts.get(level, 0) + 1
            viewpoint_counts[viewpoint] = viewpoint_counts.get(viewpoint, 0) + 1

        # ìƒì„¸ ê²°ê³¼ ì €ì¥ (JSON)
        detailed_results = {
            'test_info': {
                'test_type': 'various_viewpoint_analyzer',
                'test_number': self.test_number,
                'timestamp': datetime.now().isoformat(),
                'test_data_path': str(self.test_data_path),
                'samples_per_level': self.samples_per_level,
                'total_images': len(self.test_results),
                'level_counts': level_counts,
                'viewpoint_counts': viewpoint_counts
            },
            'metrics': metrics,
            'detailed_results': self.test_results
        }

        json_path = self.result_log_path / "results.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(detailed_results, f, ensure_ascii=False, indent=2)

        # ìš”ì•½ ë¦¬í¬íŠ¸ ì €ì¥ (í…ìŠ¤íŠ¸)
        report_path = self.result_log_path / "report.txt"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=" * 70 + "\n")
            f.write(f"Viewpoint-Specific RAG Hair Loss Analyzer ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸ (Test{self.test_number})\n")
            f.write("=" * 70 + "\n")
            f.write(f"í…ŒìŠ¤íŠ¸ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {self.test_data_path}\n")
            f.write(f"ë ˆë²¨ë‹¹ ìƒ˜í”Œ ìˆ˜: {self.samples_per_level}\n")
            f.write(f"RAG ê²€ìƒ‰ í•„í„°: male ì´ë¯¸ì§€ë§Œ (ì…ë ¥ ì´ë¯¸ì§€ì™€ ë™ì¼í•œ ë·°í¬ì¸íŠ¸ë§Œ)\n")
            f.write("\n")

            f.write("ğŸ“Š ì „ì²´ ê²°ê³¼\n")
            f.write("-" * 30 + "\n")
            f.write(f"ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {metrics['total_tests']}\n")
            f.write(f"ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {metrics['successful_tests']}\n")
            f.write(f"ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸: {metrics['failed_tests']}\n")
            f.write(f"ì„±ê³µë¥ : {metrics['success_rate']:.1%}\n")
            f.write("\n")

            f.write("ğŸ“ ë ˆë²¨ë³„ í…ŒìŠ¤íŠ¸ íŒŒì¼ ìˆ˜\n")
            f.write("-" * 30 + "\n")
            for level in sorted(level_counts.keys()):
                f.write(f"ë ˆë²¨ {level}: {level_counts[level]}ê°œ íŒŒì¼\n")
            f.write("\n")

            f.write("ğŸ¥ ë·°í¬ì¸íŠ¸ë³„ í…ŒìŠ¤íŠ¸ íŒŒì¼ ìˆ˜\n")
            f.write("-" * 30 + "\n")
            for viewpoint in sorted(viewpoint_counts.keys()):
                f.write(f"{viewpoint}: {viewpoint_counts[viewpoint]}ê°œ íŒŒì¼\n")
            f.write("\n")

            f.write("ğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ\n")
            f.write("-" * 30 + "\n")
            f.write(f"ì •í™•ë„ (Accuracy): {metrics['accuracy']:.3f}\n")
            f.write(f"ì •ë°€ë„ (Precision): {metrics['precision']:.3f}\n")
            f.write(f"ì¬í˜„ìœ¨ (Recall): {metrics['recall']:.3f}\n")
            f.write(f"F1-Score: {metrics['f1_score']:.3f}\n")
            f.write("\n")

            f.write("ğŸ¥ ë·°í¬ì¸íŠ¸ë³„ ì •í™•ë„\n")
            f.write("-" * 30 + "\n")
            for viewpoint, data in metrics['viewpoint_accuracy'].items():
                f.write(f"{viewpoint}: {data['accuracy']:.3f} ({data['count']}ê°œ ìƒ˜í”Œ)\n")
            f.write("\n")

            f.write("â±ï¸ ì„±ëŠ¥ í†µê³„\n")
            f.write("-" * 30 + "\n")
            f.write(f"í‰ê·  ë¶„ì„ ì‹œê°„: {metrics['avg_analysis_time']:.3f}ì´ˆ\n")
            f.write(f"í‰ê·  ì‹ ë¢°ë„: {metrics['avg_confidence']:.3f}\n")
            f.write("\n")

            f.write("ğŸ¯ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥\n")
            f.write("-" * 30 + "\n")
            for level in sorted(metrics['unique_labels']):
                level_str = str(level)
                if level_str in metrics['class_report']:
                    cr = metrics['class_report'][level_str]
                    f.write(f"ë ˆë²¨ {level}: ì •ë°€ë„={cr['precision']:.3f}, ì¬í˜„ìœ¨={cr['recall']:.3f}, F1={cr['f1-score']:.3f}\n")

        print(f"ìƒì„¸ ê²°ê³¼ ì €ì¥: {json_path}")
        print(f"ìš”ì•½ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")

        # CSVë¡œë„ ì €ì¥
        df = pd.DataFrame(self.test_results)
        csv_path = self.result_log_path / "results.csv"
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        print(f"CSV ë°ì´í„° ì €ì¥: {csv_path}")


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("Viewpoint-Specific RAG Hair Loss Analyzer ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 70)
    print("í…ŒìŠ¤íŠ¸ ì¡°ê±´: ê° ë ˆë²¨ë‹¹ 20ê±´ì”© ëœë¤ ìƒ˜í”Œë§")
    print("RAG ê²€ìƒ‰ ëŒ€ìƒ: male ì´ë¯¸ì§€ë§Œ (ì…ë ¥ ì´ë¯¸ì§€ì™€ ë™ì¼í•œ ë·°í¬ì¸íŠ¸ë§Œ)")
    print("=" * 70)

    # ê²½ë¡œ ì„¤ì •
    test_data_path = "C:/Users/301/Desktop/test_data_set_all_pointview"
    base_log_path = "C:/Users/301/Desktop/main_project/backend/hair_classification/result_log/log"

    # í…ŒìŠ¤í„° ì´ˆê¸°í™” ë° ì‹¤í–‰
    tester = VariousViewpointTester(test_data_path, base_log_path, samples_per_level=20)

    try:
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        await tester.run_tests()

        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        metrics = tester.calculate_metrics()

        if metrics:
            # ì‹œê°í™” ìƒì„±
            tester.create_visualizations(metrics)

            # ê²°ê³¼ ì €ì¥
            tester.save_results(metrics)

            print("\n" + "=" * 70)
            print(f"Viewpoint-Specific RAG í…ŒìŠ¤íŠ¸ ì™„ë£Œ! (Test{tester.test_number})")
            print("=" * 70)
            print(f"ì •í™•ë„: {metrics['accuracy']:.1%}")
            print(f"F1-Score: {metrics['f1_score']:.3f}")
            print(f"í‰ê·  ë¶„ì„ ì‹œê°„: {metrics['avg_analysis_time']:.3f}ì´ˆ")
            print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {tester.result_log_path}")

            print("\në·°í¬ì¸íŠ¸ë³„ ì •í™•ë„:")
            for viewpoint, data in metrics['viewpoint_accuracy'].items():
                print(f"  {viewpoint}: {data['accuracy']:.1%} ({data['count']}ê°œ)")
        else:
            print("\nì„±ëŠ¥ ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨")

    except KeyboardInterrupt:
        print("\n\nì‚¬ìš©ìì— ì˜í•´ í…ŒìŠ¤íŠ¸ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\ní…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    asyncio.run(main())