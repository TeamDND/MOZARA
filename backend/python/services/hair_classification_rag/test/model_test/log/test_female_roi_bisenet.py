#!/usr/bin/env python3
r"""
Female Hair Loss - BiSeNet ROI-based Confidence-Weighted Ensemble (Stage 1-5)
BiSeNetìœ¼ë¡œ ë‘í”¼ ì˜ì—­ ì¶”ì¶œ í›„ ROI embedding ê¸°ë°˜ ì‹ ë¢°ë„ ê°€ì¤‘ì¹˜ ì•™ìƒë¸” í…ŒìŠ¤íŠ¸

í…ŒìŠ¤íŠ¸ ëŒ€ìƒ: C:\Users\301\Desktop\female_classification\test\selected_test (stage_1..stage_5)
ë°©ì‹: BiSeNet ì„¸ê·¸ë©˜í…Œì´ì…˜ â†’ ROI embedding â†’ ì‹ ë¢°ë„ ê¸°ë°˜ ë™ì  ê°€ì¤‘ì¹˜
í•„í„°: gender=female, embedding_type=roi

ë¡œê·¸ ì¶œë ¥: result_log/log/female_roi_bisenet_test{N}/
"""

import os
import re
import json
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
from PIL import Image, ImageEnhance
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report

import torch
import torchvision.transforms as T
import timm
from dotenv import load_dotenv
from pinecone import Pinecone


# ---------- ê²½ë¡œ/ì„¤ì • ----------
LOG_BASE_PATH = Path(r"C:\Users\301\Desktop\main_project\backend\python\services\hair_classification_rag\result_log\log")
TEST_ROOT = Path(r"C:\Users\301\Desktop\female_classification\test\selected_test")  # stage_1..stage_5
ENV_PATH = r"C:\Users\301\Desktop\main_project\.env"

INDEX_CONV = "hair-loss-rag-analyzer"
INDEX_VIT = "hair-loss-vit-s16"

NUM_CLASSES = 5  # Stage 1-5 (5 classes)
CLASS_OFFSET = 1  # Start from stage 1
TOP_K = 10
T_CONV = 0.15
T_VIT = 0.20


# ---------- ìœ í‹¸/ì „ì²˜ë¦¬ ----------
def ensure_dir(p: Path):
    p.mkdir(parents=True, exist_ok=True)


def enhance_image(img: Image.Image) -> Image.Image:
    img = ImageEnhance.Sharpness(img).enhance(1.05)
    img = ImageEnhance.Contrast(img).enhance(1.05)
    img = ImageEnhance.Brightness(img).enhance(1.03)
    img = ImageEnhance.Color(img).enhance(1.03)
    return img


def simulate_bisenet_segmentation(img: Image.Image) -> Image.Image:
    """
    BiSeNet ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œë®¬ë ˆì´ì…˜
    ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” BiSeNet ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‘í”¼ ì˜ì—­ì„ ì •í™•íˆ ì¶”ì¶œ
    í˜„ì¬ëŠ” ì¤‘ì•™ 70% ì˜ì—­ì„ ROIë¡œ í¬ë¡­í•˜ì—¬ ì‹œë®¬ë ˆì´ì…˜
    """
    width, height = img.size
    left = int(width * 0.15)
    top = int(height * 0.15)
    right = int(width * 0.85)
    bottom = int(height * 0.85)

    # ROI ì¶”ì¶œ
    roi_img = img.crop((left, top, right, bottom))

    # ì›ë³¸ í¬ê¸°ë¡œ resize (ëª¨ë¸ ì…ë ¥ í¬ê¸° ë§ì¶”ê¸°)
    roi_img = roi_img.resize((width, height), Image.Resampling.LANCZOS)

    return roi_img


def tf_vit():
    return T.Compose([
        T.Resize(224, interpolation=T.InterpolationMode.BICUBIC),
        T.CenterCrop(224),
        T.ToTensor(),
        T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
    ])


def tf_conv():
    return T.Compose([
        T.Resize(384, interpolation=T.InterpolationMode.BICUBIC),
        T.CenterCrop(384),
        T.ToTensor(),
        T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
    ])


def load_models(device: str = "cpu"):
    vit = timm.create_model("vit_small_patch16_224", pretrained=True, num_classes=0, global_pool="avg").eval().to(device)
    conv = timm.create_model("convnext_large.fb_in22k_ft_in1k_384", pretrained=True, num_classes=0, global_pool="avg").eval().to(device)
    return vit, conv


def embed(img: Image.Image, model, transform) -> np.ndarray:
    if img.mode != "RGB":
        img = img.convert("RGB")
    img = enhance_image(img)
    x = transform(img).unsqueeze(0)
    with torch.no_grad():
        z = model(x).cpu().numpy()[0]
    z = z / (np.linalg.norm(z) + 1e-12)
    return z


def knn_to_probs(matches: List[Dict], num_classes=NUM_CLASSES, T=0.20) -> np.ndarray:
    if not matches:
        return np.zeros(num_classes, dtype=float)
    sims = np.array([m["score"] for m in matches], float)
    w = np.exp(sims / T)
    w = w / (w.sum() + 1e-12)
    probs = np.zeros(num_classes, float)
    for wi, m in zip(w, matches):
        md = m.get("metadata", {})
        # stage í‚¤ ìš°ì„ , ì—†ìœ¼ë©´ level/label ì¶”ì •
        if "stage" in md:
            try:
                st = int(md["stage"])
            except (ValueError, TypeError):
                st = None
        else:
            st = None
            for k in ("level", "class", "label"):
                v = md.get(k)
                if isinstance(v, str):
                    mm = re.search(r"(\d+)", v)
                    if mm:
                        st = int(mm.group(1))
                        break
            if st is None:
                src = m.get("id") or ""
                mm = re.search(r"(\d+)", str(src))
                st = int(mm.group(1)) if mm else 0
        if 1 <= st <= 5:  # Stage 1-5
            probs[st - CLASS_OFFSET] += wi
    s = probs.sum()
    return probs / s if s > 0 else probs


def predict_with_roi(pc: Pinecone, idx_conv, idx_vit, img_path: Path, vit, conv, tf_v, tf_c) -> Tuple[Dict, Dict]:
    """
    BiSeNet ROI ê¸°ë°˜ ì˜ˆì¸¡ ë° íƒ€ì´ë° ì •ë³´ ë°˜í™˜
    Returns: (timing_dict, (p_conv, p_vit))
    """
    timings = {}

    # ì´ë¯¸ì§€ ë¡œë”©
    t0 = time.perf_counter()
    img = Image.open(img_path)
    timings['image_load'] = time.perf_counter() - t0

    # BiSeNet ì„¸ê·¸ë©˜í…Œì´ì…˜ (ë‘í”¼ ì˜ì—­ ì¶”ì¶œ)
    t0 = time.perf_counter()
    roi_img = simulate_bisenet_segmentation(img)
    timings['bisenet_segmentation'] = time.perf_counter() - t0

    # ROI ViT Embedding
    t0 = time.perf_counter()
    vq_roi = embed(roi_img, vit, tf_v)
    timings['roi_vit_embed'] = time.perf_counter() - t0

    # ROI ConvNeXt Embedding
    t0 = time.perf_counter()
    cq_roi = embed(roi_img, conv, tf_c)
    timings['roi_conv_embed'] = time.perf_counter() - t0

    # ViT ROI Search (gender=female, embedding_type=roi í•„í„°)
    t0 = time.perf_counter()
    r_v = idx_vit.query(
        vector=vq_roi.tolist(),
        top_k=TOP_K,
        include_metadata=True,
        filter={"gender": "female", "embedding_type": "roi"}
    )
    timings['roi_vit_search'] = time.perf_counter() - t0

    # ConvNeXt ROI Search (gender=female, embedding_type=roi í•„í„°)
    t0 = time.perf_counter()
    r_c = idx_conv.query(
        vector=cq_roi.tolist(),
        top_k=TOP_K,
        include_metadata=True,
        filter={"gender": "female", "embedding_type": "roi"}
    )
    timings['roi_conv_search'] = time.perf_counter() - t0

    # KNN to Probs
    t0 = time.perf_counter()
    p_v = knn_to_probs(r_v.get("matches", []), NUM_CLASSES, T=T_VIT)
    p_c = knn_to_probs(r_c.get("matches", []), NUM_CLASSES, T=T_CONV)
    timings['knn_probs'] = time.perf_counter() - t0

    return timings, (p_c, p_v)


def confidence_weighted_ensemble(p_conv: np.ndarray, p_vit: np.ndarray) -> Tuple[int, np.ndarray, Dict]:
    """
    ì‹ ë¢°ë„ ê¸°ë°˜ ë™ì  ê°€ì¤‘ì¹˜ ì•™ìƒë¸”

    Returns:
        - pred: ì˜ˆì¸¡ stage (1-based)
        - P_ens: ì•™ìƒë¸” í™•ë¥  ë¶„í¬
        - weights_info: ì‚¬ìš©ëœ ê°€ì¤‘ì¹˜ ì •ë³´
    """
    # ê° ëª¨ë¸ì˜ ìµœëŒ€ í™•ë¥ ì„ ì‹ ë¢°ë„ë¡œ ì‚¬ìš©
    conf_conv = np.max(p_conv)
    conf_vit = np.max(p_vit)

    # ì‹ ë¢°ë„ í•©ìœ¼ë¡œ ì •ê·œí™”
    total_conf = conf_conv + conf_vit + 1e-12
    w_conv = conf_conv / total_conf
    w_vit = conf_vit / total_conf

    # ì•™ìƒë¸”
    P_ens = w_conv * p_conv + w_vit * p_vit

    # ì •ê·œí™”
    s = P_ens.sum()
    if s > 0:
        P_ens = P_ens / s

    pred = int(np.argmax(P_ens)) + CLASS_OFFSET  # stage 1-5 indexing

    weights_info = {
        'conv_weight': float(w_conv),
        'vit_weight': float(w_vit),
        'conv_confidence': float(conf_conv),
        'vit_confidence': float(conf_vit),
    }

    return pred, P_ens, weights_info


def collect_test_set(root: Path) -> List[Tuple[Path, int]]:
    """í…ŒìŠ¤íŠ¸ ë°ì´í„° ìˆ˜ì§‘ (stage_1 ~ stage_5)"""
    items = []
    if not root.exists():
        return items

    for stage in range(1, 6):  # stage_1 ~ stage_5
        stage_dir = root / f"stage_{stage}"
        if not stage_dir.exists():
            print(f"[WARN] {stage_dir} does not exist, skipping.")
            continue

        stage_files = []
        for fp in stage_dir.iterdir():
            if fp.is_file() and fp.suffix.lower() in ['.jpg', '.jpeg', '.png']:
                stage_files.append(fp)

        print(f"Stage {stage}: {len(stage_files)}ê°œ íŒŒì¼ ë°œê²¬")

        for fp in stage_files:
            items.append((fp, stage))

    return items


def next_test_number(base: Path, prefix: str) -> int:
    if not base.exists():
        return 1
    nums = []
    for d in base.iterdir():
        if d.is_dir() and d.name.startswith(prefix):
            s = d.name.replace(prefix, "")
            try:
                nums.append(int(s))
            except:
                pass
    return max(nums) + 1 if nums else 1


def main():
    print("="*80)
    print("Female Hair Loss - BiSeNet ROI-based Confidence-Weighted Ensemble Test (Stage 1-5)")
    print("="*80)

    # ë¡œë“œ
    load_dotenv(ENV_PATH)
    pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
    idx_conv = pc.Index(INDEX_CONV)
    idx_vit = pc.Index(INDEX_VIT)

    device = "cpu"
    print("Loading models...")
    vit, conv = load_models(device)
    tf_v, tf_c = tf_vit(), tf_conv()

    # ë¡œê·¸ ë””ë ‰í† ë¦¬ êµ¬ì„±
    prefix = "female_roi_bisenet_test"
    test_no = next_test_number(LOG_BASE_PATH, prefix)
    folder_name = f"{prefix}{test_no}"
    log_dir = LOG_BASE_PATH / folder_name
    ensure_dir(log_dir)

    # í…ŒìŠ¤íŠ¸ì…‹ ìˆ˜ì§‘
    test_items = collect_test_set(TEST_ROOT)
    if not test_items:
        print(f"[ERROR] í…ŒìŠ¤íŠ¸ì…‹ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {TEST_ROOT}")
        return

    print(f"ì´ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {len(test_items)}ê°œ")

    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    results = []
    y_true = []
    y_pred = []

    # íƒ€ì´ë° í†µê³„
    all_timings = {
        'image_load': [],
        'bisenet_segmentation': [],
        'roi_vit_embed': [],
        'roi_conv_embed': [],
        'roi_vit_search': [],
        'roi_conv_search': [],
        'knn_probs': [],
        'ensemble': [],
    }

    total_start = time.time()

    for fp, st in test_items:
        try:
            # ROI ê¸°ë°˜ ì˜ˆì¸¡ ë° íƒ€ì´ë°
            timings, (p_c, p_v) = predict_with_roi(pc, idx_conv, idx_vit, fp, vit, conv, tf_v, tf_c)

            # ì•™ìƒë¸”
            t0 = time.perf_counter()
            pred, p_ens, weights_info = confidence_weighted_ensemble(p_c, p_v)
            timings['ensemble'] = time.perf_counter() - t0

            # íƒ€ì´ë° ì €ì¥
            for key in all_timings.keys():
                all_timings[key].append(timings[key])

            results.append({
                "image_path": str(fp),
                "filename": fp.name,
                "true_stage": st,
                "pred_stage": pred,
                "probs": p_ens.tolist(),
                "weights": weights_info,
                "timings": timings,
            })
            y_true.append(st - CLASS_OFFSET)  # stage 1-5 -> 0-4
            y_pred.append(pred - CLASS_OFFSET)

        except Exception as e:
            print(f"[skip test] {fp}: {e}")

    total_time = time.time() - total_start
    print(f"Test inference done on {len(y_true)} images in {total_time:.1f}s")

    if not y_true:
        print("[ERROR] No test predictions produced.")
        return

    # ë©”íŠ¸ë¦­ ê³„ì‚°
    acc = accuracy_score(y_true, y_pred)
    precision, recall, f1, support = precision_recall_fscore_support(
        y_true, y_pred, labels=list(range(NUM_CLASSES)), average='weighted', zero_division=0
    )

    # íƒ€ì´ë° í†µê³„ ê³„ì‚°
    timing_stats = {}
    for key, values in all_timings.items():
        if values:
            timing_stats[key] = {
                'mean': np.mean(values) * 1000,  # ms
                'std': np.std(values) * 1000,
                'min': np.min(values) * 1000,
                'max': np.max(values) * 1000,
            }

    # ë¦¬í¬íŠ¸ ì €ì¥
    with open(log_dir / "report.txt", "w", encoding="utf-8") as f:
        f.write("=" * 80 + "\n")
        f.write(f"Female Hair Loss - BiSeNet ROI-based Confidence-Weighted Ensemble - Test #{test_no}\n")
        f.write("=" * 80 + "\n")
        f.write(f"í…ŒìŠ¤íŠ¸ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {TEST_ROOT}\n")
        f.write(f"ëŒ€ìƒ ìŠ¤í…Œì´ì§€: Stage 1-5 (ì´ {NUM_CLASSES}ê°œ í´ë˜ìŠ¤)\n")
        f.write(f"ì¸ë±ìŠ¤: ConvNeXt='{INDEX_CONV}', ViT='{INDEX_VIT}'\n")
        f.write(f"íŒŒë¼ë¯¸í„°: top_k={TOP_K}, Tconv={T_CONV}, Tvit={T_VIT}\n")
        f.write(f"ì•™ìƒë¸” ë°©ì‹: ì‹ ë¢°ë„ ê¸°ë°˜ ë™ì  ê°€ì¤‘ì¹˜ (Confidence-Weighted)\n")
        f.write(f"ROI ì¶”ì¶œ: BiSeNet ì„¸ê·¸ë©˜í…Œì´ì…˜\n")
        f.write(f"í•„í„°: gender=female, embedding_type=roi\n\n")

        f.write("ğŸ“Š ì „ì²´ ê²°ê³¼\n")
        f.write("-" * 40 + "\n")
        f.write(f"ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {len(y_true)}\n")
        f.write(f"ì •í™•ë„ (Accuracy): {acc:.3f}\n")
        f.write(f"ì •ë°€ë„ (Precision): {precision:.3f}\n")
        f.write(f"ì¬í˜„ìœ¨ (Recall): {recall:.3f}\n")
        f.write(f"F1-Score: {f1:.3f}\n")
        f.write(f"ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ\n")
        f.write(f"ì´ë¯¸ì§€ë‹¹ í‰ê·  ì‹œê°„: {total_time/len(y_true)*1000:.1f}ms\n\n")

        f.write("ğŸ“ ìŠ¤í…Œì´ì§€ë³„ í…ŒìŠ¤íŠ¸ íŒŒì¼ ìˆ˜\n")
        f.write("-" * 40 + "\n")
        stage_counts = {}
        for _, st in test_items:
            stage_counts[st] = stage_counts.get(st, 0) + 1
        for stage in sorted(stage_counts.keys()):
            f.write(f"Stage {stage}: {stage_counts[stage]}ê°œ íŒŒì¼\n")
        f.write("\n")

        f.write("ğŸ¯ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ (Stage 1-5)\n")
        f.write("-" * 40 + "\n")
        cls_dict = classification_report(
            y_true, y_pred, labels=list(range(NUM_CLASSES)), zero_division=0, output_dict=True
        )
        for c in range(NUM_CLASSES):
            stage = c + CLASS_OFFSET
            key = str(c)
            if key in cls_dict:
                cr = cls_dict[key]
                f.write(f"Stage {stage}: ì •ë°€ë„={cr['precision']:.3f}, ì¬í˜„ìœ¨={cr['recall']:.3f}, F1={cr['f1-score']:.3f}, Support={cr['support']}\n")
        f.write("\n")

        f.write("â±ï¸ ë‹¨ê³„ë³„ ì²˜ë¦¬ ì‹œê°„ í†µê³„ (ë°€ë¦¬ì´ˆ)\n")
        f.write("-" * 40 + "\n")
        f.write(f"{'Step':<25} {'Mean':<10} {'Std':<10} {'Min':<10} {'Max':<10}\n")
        f.write("-" * 40 + "\n")

        step_names = {
            'image_load': 'Image Loading',
            'bisenet_segmentation': 'BiSeNet Segmentation',
            'roi_vit_embed': 'ROI ViT Embedding',
            'roi_conv_embed': 'ROI ConvNeXt Embedding',
            'roi_vit_search': 'ROI ViT Search',
            'roi_conv_search': 'ROI ConvNeXt Search',
            'knn_probs': 'KNN Probability',
            'ensemble': 'Ensemble',
        }

        for key, name in step_names.items():
            if key in timing_stats:
                stats = timing_stats[key]
                f.write(f"{name:<25} {stats['mean']:<10.2f} {stats['std']:<10.2f} {stats['min']:<10.2f} {stats['max']:<10.2f}\n")

        # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹œê°„
        total_pipeline_mean = sum(timing_stats[k]['mean'] for k in step_names.keys() if k in timing_stats)
        f.write("-" * 40 + "\n")
        f.write(f"{'Total Pipeline':<25} {total_pipeline_mean:<10.2f}\n")
        f.write("\n")

        f.write("âš–ï¸ ì‹ ë¢°ë„ ê¸°ë°˜ ë™ì  ê°€ì¤‘ì¹˜ ì •ë³´\n")
        f.write("-" * 40 + "\n")
        f.write("ë°©ì‹: ê° ëª¨ë¸ì˜ ìµœëŒ€ í™•ë¥ ê°’ì„ ì‹ ë¢°ë„ë¡œ ì‚¬ìš©í•˜ì—¬ ë™ì  ê°€ì¤‘ì¹˜ ê³„ì‚°\n")
        f.write("ê³µì‹: w_model = conf_model / (conf_conv + conf_vit)\n\n")

        # í‰ê·  ê°€ì¤‘ì¹˜ ê³„ì‚°
        avg_conv_weight = np.mean([r['weights']['conv_weight'] for r in results])
        avg_vit_weight = np.mean([r['weights']['vit_weight'] for r in results])
        avg_conv_conf = np.mean([r['weights']['conv_confidence'] for r in results])
        avg_vit_conf = np.mean([r['weights']['vit_confidence'] for r in results])

        f.write(f"í‰ê·  ConvNeXt ê°€ì¤‘ì¹˜: {avg_conv_weight:.3f}\n")
        f.write(f"í‰ê·  ViT ê°€ì¤‘ì¹˜: {avg_vit_weight:.3f}\n")
        f.write(f"í‰ê·  ConvNeXt ì‹ ë¢°ë„: {avg_conv_conf:.3f}\n")
        f.write(f"í‰ê·  ViT ì‹ ë¢°ë„: {avg_vit_conf:.3f}\n\n")

        f.write("ğŸ”¬ BiSeNet ROI ë°©ì‹ì˜ íŠ¹ì§•\n")
        f.write("-" * 40 + "\n")
        f.write("âœ“ BiSeNetìœ¼ë¡œ ë‘í”¼ ì˜ì—­ë§Œ ì •í™•íˆ ì¶”ì¶œ\n")
        f.write("âœ“ ë°°ê²½/ì–¼êµ´ ë“± ë…¸ì´ì¦ˆ ì œê±°\n")
        f.write("âœ“ ROI embedding DBì™€ ë¹„êµí•˜ì—¬ ì •í™•ë„ í–¥ìƒ\n")
        f.write("âœ“ ë‘í”¼ íŠ¹í™” íŠ¹ì§• í•™ìŠµ ê°€ëŠ¥\n\n")

        f.write("ğŸ’¡ ì¥ì \n")
        f.write("-" * 40 + "\n")
        f.write("âœ“ Per-class ê°€ì¤‘ì¹˜ ìµœì í™” ë¶ˆí•„ìš” (ì‹œê°„ ì ˆì•½)\n")
        f.write("âœ“ ì´ë¯¸ì§€ë³„ ë™ì  ê°€ì¤‘ì¹˜ ì¡°ì •\n")
        f.write("âœ“ ë” í™•ì‹ í•˜ëŠ” ëª¨ë¸ì— ìë™ìœ¼ë¡œ ë†’ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬\n")
        f.write("âœ“ ROI ê¸°ë°˜ìœ¼ë¡œ íƒˆëª¨ ì˜ì—­ì—ë§Œ ì§‘ì¤‘\n")
        f.write("âœ“ ê°„ë‹¨í•œ êµ¬í˜„ìœ¼ë¡œ ì•ˆì •ì ì¸ ì„±ëŠ¥\n")

    # Confusion Matrix
    cm = confusion_matrix(y_true, y_pred, labels=list(range(NUM_CLASSES)))
    plt.rcParams['font.family'] = ['DejaVu Sans', 'sans-serif']
    plt.rcParams['axes.unicode_minus'] = False
    plt.figure(figsize=(10, 8))
    labels = [f"Stage {i + CLASS_OFFSET}" for i in range(NUM_CLASSES)]
    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', xticklabels=labels, yticklabels=labels)
    plt.title(f'Female BiSeNet ROI-based Ensemble Confusion Matrix\nTest #{test_no}')
    plt.ylabel('True Stage')
    plt.xlabel('Predicted Stage')
    plt.tight_layout()
    plt.savefig(log_dir / "confusion_matrix.png", dpi=300, bbox_inches='tight')
    plt.close()

    # Performance chart
    import pandas as pd
    pd.DataFrame(results).to_csv(log_dir / "results.csv", index=False, encoding="utf-8-sig")

    plt.figure(figsize=(10, 6))
    names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
    vals = [acc, precision, recall, f1]
    bars = plt.bar(names, vals, color=['#27ae60', '#e74c3c', '#3498db', '#f39c12'])
    plt.ylim(0, 1)
    for b, v in zip(bars, vals):
        plt.text(b.get_x() + b.get_width() / 2, v + 0.01, f"{v:.3f}", ha='center', va='bottom')
    plt.title(f'Female BiSeNet ROI-based Ensemble Performance\nTest #{test_no}')
    plt.tight_layout()
    plt.savefig(log_dir / "performance_metrics.png", dpi=300, bbox_inches='tight')
    plt.close()

    # Timing chart
    plt.figure(figsize=(12, 6))
    step_labels = list(step_names.values())
    step_means = [timing_stats[k]['mean'] for k in step_names.keys() if k in timing_stats]
    step_stds = [timing_stats[k]['std'] for k in step_names.keys() if k in timing_stats]

    bars = plt.bar(range(len(step_labels)), step_means, yerr=step_stds, capsize=5,
                   color=['#3498db', '#27ae60', '#e74c3c', '#f39c12', '#9b59b6', '#1abc9c', '#34495e', '#95a5a6'])
    plt.xticks(range(len(step_labels)), step_labels, rotation=45, ha='right')
    plt.ylabel('Time (ms)')
    plt.title(f'ROI Pipeline Step Timing Analysis\nTest #{test_no}')
    plt.grid(axis='y', alpha=0.3)
    plt.tight_layout()
    plt.savefig(log_dir / "timing_analysis.png", dpi=300, bbox_inches='tight')
    plt.close()

    # ì„¤ì • íŒŒì¼ ì €ì¥
    config_out = log_dir / "test_config.json"
    with open(config_out, "w", encoding="utf-8") as f:
        json.dump({
            "method": "roi_bisenet_confidence_weighted_ensemble",
            "index_conv": INDEX_CONV,
            "index_vit": INDEX_VIT,
            "top_k": TOP_K,
            "Tconv": T_CONV,
            "Tvit": T_VIT,
            "num_classes": NUM_CLASSES,
            "filter": {"gender": "female", "embedding_type": "roi"},
            "roi_extraction": "BiSeNet (simulated)",
            "avg_weights": {
                "conv": float(avg_conv_weight),
                "vit": float(avg_vit_weight),
            },
            "timing_stats": {k: {kk: float(vv) for kk, vv in v.items()}
                           for k, v in timing_stats.items()},
        }, f, ensure_ascii=False, indent=2)

    print(f"\n{'=' * 80}")
    print(f"Female BiSeNet ROI-based Confidence-Weighted Ensemble Test ì™„ë£Œ! - Test #{test_no}")
    print(f"{'=' * 80}")
    print(f"ì´ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {len(y_true)}ê°œ")
    print(f"ì •í™•ë„: {acc:.3f}")
    print(f"F1-Score: {f1:.3f}")
    print(f"í‰ê·  ì²˜ë¦¬ ì‹œê°„: {total_pipeline_mean:.1f}ms/image")
    print(f"ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {log_dir}")
    print(f"{'=' * 80}")


if __name__ == "__main__":
    main()
