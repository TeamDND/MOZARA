"""
ì‹¤ì œ ëª¨ë°œ ì†ìƒ ë°ì´í„°ë¥¼ Pineconeì— ì…ë ¥í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""
import os
import pinecone
from dotenv import load_dotenv
from PIL import Image
from transformers import CLIPProcessor, CLIPModel
import torch
from pathlib import Path

# .env íŒŒì¼ ë¡œë“œ (ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ .env íŒŒì¼ ì‚¬ìš©)
load_dotenv("../../../../.env")

def load_clip_model():
    """CLIP ëª¨ë¸ ë¡œë“œ"""
    print("ğŸ”„ CLIP ëª¨ë¸ ë¡œë”© ì¤‘...")
    model = CLIPModel.from_pretrained("openai/clip-vit-large-patch14")
    processor = CLIPProcessor.from_pretrained("openai/clip-vit-large-patch14")
    print("âœ… CLIP ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
    return model, processor

def get_image_embedding(image_path, model, processor):
    """ì´ë¯¸ì§€ì—ì„œ ë²¡í„° ì¶”ì¶œ"""
    try:
        image = Image.open(image_path).convert('RGB')
        inputs = processor(images=image, return_tensors="pt")
        
        with torch.no_grad():
            image_features = model.get_image_features(**inputs)
            # ì •ê·œí™”
            image_features = image_features / image_features.norm(dim=-1, keepdim=True)
            
        return image_features.squeeze().tolist()
    except Exception as e:
        print(f"âŒ ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜ {image_path}: {str(e)}")
        return None

def parse_filename(filename):
    """íŒŒì¼ëª…ì—ì„œ ë¼ë²¨ ì •ë³´ ì¶”ì¶œ"""
    if filename.startswith('mild_'):
        return "ê²½ë¯¸", 1
    elif filename.startswith('moderate_'):
        return "ì¤‘ë“±ë„", 2
    elif filename.startswith('severe_'):
        return "ì‹¬ê°", 3
    else:
        return "ì•Œ ìˆ˜ ì—†ìŒ", 0

def import_real_data():
    """ì‹¤ì œ ë°ì´í„°ë¥¼ Pineconeì— ì…ë ¥"""
    
    # Pinecone API í‚¤ ë° í˜¸ìŠ¤íŠ¸ ì •ë³´ ë¡œë“œ
    api_key = os.getenv("PINECONE_API_KEY")
    index_host = os.getenv("PINECONE_INDEX_HOST")

    if not api_key or not index_host:
        print("âŒ PINECONE_API_KEY ë˜ëŠ” PINECONE_INDEX_HOST í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return

    print("ğŸŒ² Pinecone í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘...")
    try:
        # Pinecone í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (v3.x ë°©ì‹)
        from pinecone import Pinecone
        pc = Pinecone(api_key=api_key)
        
        # ì¸ë±ìŠ¤ í˜¸ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ì ‘ ì¸ë±ìŠ¤ì— ì—°ê²°
        print(f"ğŸ”— ì¸ë±ìŠ¤ í˜¸ìŠ¤íŠ¸ì— ì—°ê²° ì¤‘: {index_host}")
        index = pc.Index(host=index_host)
        
        # ì¸ë±ìŠ¤ ì—°ê²° í™•ì¸
        stats = index.describe_index_stats()
        print("âœ… ì¸ë±ìŠ¤ ì—°ê²° ì„±ê³µ!")
        print(f"ğŸ“Š í˜„ì¬ ì¸ë±ìŠ¤ í†µê³„: {stats}")

        # CLIP ëª¨ë¸ ë¡œë“œ
        model, processor = load_clip_model()
        
        # ë°ì´í„° ë””ë ‰í† ë¦¬
        data_dir = Path("C:/Users/301/Desktop/hair_damage/train")
        
        # ì´ë¯¸ì§€ íŒŒì¼ë“¤ ì²˜ë¦¬
        image_files = list(data_dir.glob("*.jpg"))
        print(f"ğŸ“Š ì´ {len(image_files)}ê°œ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬")
        
        batch_size = 10
        vectors_to_upsert = []
        
        for i, image_path in enumerate(image_files):
            print(f"ğŸ”„ ì²˜ë¦¬ ì¤‘: {i+1}/{len(image_files)} - {image_path.name}")
            
            vector = get_image_embedding(image_path, model, processor)
            if vector is None:
                continue
            
            diagnosis, stage = parse_filename(image_path.name)
            
            metadata = {
                "filename": image_path.name,
                "diagnosis": diagnosis,
                "gender": "ë‚¨ì„±",
                "stage": stage,
                "confidence": 0.95,
                "data_type": "real"
            }
            
            vectors_to_upsert.append({
                "id": f"real_{i}",
                "values": vector,
                "metadata": metadata
            })
            
            if len(vectors_to_upsert) >= batch_size:
                print(f"ğŸ“¤ {len(vectors_to_upsert)}ê°œ ë²¡í„° ì—…ë¡œë“œ ì¤‘...")
                index.upsert(vectors=vectors_to_upsert)
                vectors_to_upsert = []
        
        if vectors_to_upsert:
            print(f"ğŸ“¤ ë§ˆì§€ë§‰ {len(vectors_to_upsert)}ê°œ ë²¡í„° ì—…ë¡œë“œ ì¤‘...")
            index.upsert(vectors=vectors_to_upsert)
        
        stats = index.describe_index_stats()
        print(f"ğŸ“Š ìµœì¢… ì¸ë±ìŠ¤ í†µê³„: {stats}")
        print("âœ… ì‹¤ì œ ë°ì´í„° ì…ë ¥ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    import_real_data()