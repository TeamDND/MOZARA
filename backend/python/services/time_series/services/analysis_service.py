"""
Time-Series Analysis Service
ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì²˜ë¦¬ (ê²½ëŸ‰í™”: ë°€ë„ ë¹„êµë§Œ)
"""

import requests
import logging
from typing import List, Dict, Any

from .density_analyzer import DensityAnalyzer
# from .feature_extractor import FeatureExtractor  # â† ê²½ëŸ‰í™”: ì£¼ì„ ì²˜ë¦¬
from .timeseries_comparator import TimeSeriesComparator

logger = logging.getLogger(__name__)

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ (í•œ ë²ˆë§Œ ë¡œë“œ)
_density_analyzer = None
# _feature_extractor = None  # â† ê²½ëŸ‰í™”: ì£¼ì„ ì²˜ë¦¬
_comparator = TimeSeriesComparator()


def _initialize_models():
    """ëª¨ë¸ ì´ˆê¸°í™” (lazy loading) - ë°€ë„ ë¶„ì„ë§Œ"""
    global _density_analyzer  # , _feature_extractor

    if _density_analyzer is None:
        logger.info("ğŸ”„ DensityAnalyzer ì´ˆê¸°í™” ì¤‘...")
        _density_analyzer = DensityAnalyzer(device='cpu')
        logger.info("âœ… DensityAnalyzer ì´ˆê¸°í™” ì™„ë£Œ")

    # â† ê²½ëŸ‰í™”: Feature ì¶”ì¶œ ë¹„í™œì„±í™”
    # if _feature_extractor is None:
    #     logger.info("ğŸ”„ FeatureExtractor ì´ˆê¸°í™” ì¤‘...")
    #     _feature_extractor = FeatureExtractor(device='cpu')
    #     logger.info("âœ… FeatureExtractor ì´ˆê¸°í™” ì™„ë£Œ")


def analyze_single_image(image_url: str) -> Dict[str, Any]:
    """
    ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„ (ë°€ë„ë§Œ)

    Args:
        image_url: ì´ë¯¸ì§€ URL

    Returns:
        ë¶„ì„ ê²°ê³¼ (ë°€ë„ë§Œ)
    """
    _initialize_models()

    logger.info(f"ğŸ“¥ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ: {image_url}")

    response = requests.get(image_url, timeout=10)
    if response.status_code != 200:
        raise ValueError(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {response.status_code}")

    image_bytes = response.content

    logger.info("ğŸ” ë°€ë„ ì¸¡ì • ì¤‘...")
    density_result = _density_analyzer.calculate_density(image_bytes)

    # â† ê²½ëŸ‰í™”: Feature ì¶”ì¶œ ë¹„í™œì„±í™”
    # logger.info("ğŸ§  Feature ì¶”ì¶œ ì¤‘...")
    # feature_result = _feature_extractor.extract_features(image_bytes)

    logger.info("âœ… ë¶„ì„ ì™„ë£Œ (ë°€ë„ë§Œ)")

    return {
        "success": True,
        "density": density_result,
        # "features": feature_result  # â† ê²½ëŸ‰í™”: ì œê±°
    }


def compare_timeseries(current_image_url: str, past_image_urls: List[str]) -> Dict[str, Any]:
    """
    ì‹œê³„ì—´ ë¹„êµ ë¶„ì„ (ë°€ë„ë§Œ)

    Args:
        current_image_url: í˜„ì¬ ì´ë¯¸ì§€ URL
        past_image_urls: ê³¼ê±° ì´ë¯¸ì§€ URL ë¦¬ìŠ¤íŠ¸

    Returns:
        ë¹„êµ ë¶„ì„ ê²°ê³¼ (ë°€ë„ë§Œ)
    """
    _initialize_models()

    logger.info(f"ğŸ“¥ í˜„ì¬ ì´ë¯¸ì§€ ë¶„ì„: {current_image_url}")

    # 1. í˜„ì¬ ì´ë¯¸ì§€ ë¶„ì„ (ë°€ë„ë§Œ)
    current_response = requests.get(current_image_url, timeout=10)
    if current_response.status_code != 200:
        raise ValueError("í˜„ì¬ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨")

    current_bytes = current_response.content
    current_density = _density_analyzer.calculate_density(current_bytes)
    # current_features = _feature_extractor.extract_features(current_bytes)  # â† ê²½ëŸ‰í™”: ì£¼ì„

    logger.info(f"ğŸ“¥ ê³¼ê±° ì´ë¯¸ì§€ {len(past_image_urls)}ê°œ ë¶„ì„")

    # 2. ê³¼ê±° ì´ë¯¸ì§€ë“¤ ë¶„ì„ (ë°€ë„ë§Œ)
    past_densities = []
    # past_features = []  # â† ê²½ëŸ‰í™”: ì£¼ì„
    # past_maps = []  # â† ê²½ëŸ‰í™”: ì£¼ì„

    for idx, url in enumerate(past_image_urls):
        try:
            logger.info(f"  - ê³¼ê±° ì´ë¯¸ì§€ {idx+1}/{len(past_image_urls)}")
            past_response = requests.get(url, timeout=10)
            if past_response.status_code != 200:
                logger.warning(f"  âš ï¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {url}")
                continue

            past_bytes = past_response.content
            past_density = _density_analyzer.calculate_density(past_bytes)
            # past_feature = _feature_extractor.extract_features(past_bytes)  # â† ê²½ëŸ‰í™”: ì£¼ì„

            past_densities.append(past_density)
            # past_features.append(past_feature['feature_vector'])  # â† ê²½ëŸ‰í™”: ì£¼ì„
            # past_maps.append(past_density['distribution_map'])  # â† ê²½ëŸ‰í™”: ì£¼ì„

        except Exception as e:
            logger.warning(f"  âš ï¸ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            continue

    if not past_densities:
        return {
            "success": False,
            "message": "ë¹„êµí•  ê³¼ê±° ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        }

    logger.info("ğŸ“Š ì‹œê³„ì—´ ë¹„êµ ë¶„ì„ ì¤‘ (ë°€ë„ë§Œ)...")

    # 3. ì‹œê³„ì—´ ë¹„êµ (ë°€ë„ë§Œ)
    density_comparison = _comparator.compare_density(current_density, past_densities)
    # distribution_comparison = _comparator.compare_distribution(  # â† ê²½ëŸ‰í™”: ì£¼ì„
    #     current_density['distribution_map'],
    #     past_maps
    # )
    # feature_comparison = _comparator.compare_features(  # â† ê²½ëŸ‰í™”: ì£¼ì„
    #     current_features['feature_vector'],
    #     past_features
    # )

    # 4. ì¢…í•© ìš”ì•½ (ë°€ë„ë§Œ)
    summary = _comparator.generate_summary(
        density_comparison,
        None,  # distribution_comparison  # â† ê²½ëŸ‰í™”: None
        None   # feature_comparison  # â† ê²½ëŸ‰í™”: None
    )

    logger.info("âœ… ì‹œê³„ì—´ ë¶„ì„ ì™„ë£Œ (ë°€ë„ë§Œ)")

    return {
        "success": True,
        "current": {
            "density": current_density,
            # "features": current_features  # â† ê²½ëŸ‰í™”: ì œê±°
        },
        "comparison": {
            "density": density_comparison,
            # "distribution": distribution_comparison,  # â† ê²½ëŸ‰í™”: ì œê±°
            # "features": feature_comparison  # â† ê²½ëŸ‰í™”: ì œê±°
        },
        "summary": summary
    }
