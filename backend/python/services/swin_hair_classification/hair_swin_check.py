import os
import json
import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import cv2
import numpy as np
import sys
from typing import Dict, Any, List
from datetime import datetime
import io
from dotenv import load_dotenv
import google.generativeai as genai

# Swin ëª¨ë¸ import
from services.swin_hair_classification.models.swin_hair_classifier import SwinHairClassifier

# Face parsing ëª¨ë¸ import
from services.swin_hair_classification.models.face_parsing.model import BiSeNet

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv("../../../.env")
load_dotenv("../../.env")
load_dotenv(".env")

def log_message(message):
    """ë¡œê¹… í•¨ìˆ˜"""
    timestamp = datetime.now().strftime("[%H:%M:%S]")
    print(f"{timestamp} {message}")

def load_swin_model(model_path: str, device: torch.device) -> SwinHairClassifier:
    """Swin ëª¨ë¸ ë¡œë“œ"""
    model = SwinHairClassifier(num_classes=4)

    if os.path.exists(model_path):
        checkpoint = torch.load(model_path, map_location=device)
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)
        log_message(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
    else:
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")

    model.to(device)
    model.eval()
    return model

def load_face_parsing_model(device: torch.device) -> BiSeNet:
    """Face parsing ëª¨ë¸ ë¡œë“œ (ë§ˆìŠ¤í‚¹ìš©)"""
    model = BiSeNet(n_classes=19)
    model_path = 'services/swin_hair_classification/models/face_parsing/res/cp/79999_iter.pth'

    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path, map_location=device))
        model.to(device)
        model.eval()
        log_message(f"Face parsing ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {model_path}")
    else:
        raise FileNotFoundError(f"Face parsing ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")

    return model

def apply_face_blur(image_bytes: bytes, face_parsing_model: BiSeNet, device: torch.device, blur_strength: int = 25) -> bytes:
    """
    ì–¼êµ´ ë¶€ë¶„ë§Œ ë¸”ëŸ¬ ì²˜ë¦¬í•œ ì´ë¯¸ì§€ ë°˜í™˜
    Args:
        image_bytes: ì›ë³¸ ì´ë¯¸ì§€ì˜ ì´ì§„ ë°ì´í„°
        face_parsing_model: Face parsing ëª¨ë¸
        device: ë””ë°”ì´ìŠ¤
        blur_strength: ë¸”ëŸ¬ ê°•ë„ (ê¸°ë³¸ê°’ 25)
    Returns: ë¸”ëŸ¬ ì²˜ë¦¬ëœ ì´ë¯¸ì§€ì˜ ì´ì§„ ë°ì´í„°
    """
    try:
        # bytesë¥¼ PIL Imageë¡œ ë³€í™˜
        image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
        image_np = np.array(image)
        original_size = image_np.shape[:2]  # (height, width)

        # OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ë° ë¦¬ì‚¬ì´ì¦ˆ
        image_resized = cv2.resize(image_np, (512, 512))

        # ì •ê·œí™” ë° í…ì„œ ë³€í™˜
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
        ])

        input_tensor = transform(image_resized).unsqueeze(0).to(device)

        # Face Parsingìœ¼ë¡œ ì–¼êµ´ ë§ˆìŠ¤í¬ ìƒì„±
        with torch.no_grad():
            output = face_parsing_model(input_tensor)[0]
            mask = torch.argmax(output, dim=1).squeeze().cpu().numpy()

        # ì–¼êµ´ ì˜ì—­ ë§ˆìŠ¤í¬ ìƒì„± (í´ë˜ìŠ¤: 1=skin, 10=nose, 11=eyes, 12=eyebrows, 13=ears)
        face_mask = np.isin(mask, [1, 10, 11, 12, 13]).astype(np.uint8) * 255

        # ë§ˆìŠ¤í¬ë¥¼ ì›ë³¸ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        face_mask_resized = cv2.resize(face_mask, (original_size[1], original_size[0]))

        # ë¸”ëŸ¬ ì²˜ë¦¬í•  ì´ë¯¸ì§€ ìƒì„±
        blurred_image = cv2.GaussianBlur(image_np, (blur_strength, blur_strength), 0)

        # ë§ˆìŠ¤í¬ë¥¼ 3ì±„ë„ë¡œ í™•ì¥
        face_mask_3ch = cv2.cvtColor(face_mask_resized, cv2.COLOR_GRAY2BGR) / 255.0

        # ì–¼êµ´ ë¶€ë¶„ë§Œ ë¸”ëŸ¬ ì ìš©
        result = (image_np * (1 - face_mask_3ch) + blurred_image * face_mask_3ch).astype(np.uint8)

        # ê²°ê³¼ë¥¼ bytesë¡œ ë³€í™˜
        result_image = Image.fromarray(result)
        output_buffer = io.BytesIO()
        result_image.save(output_buffer, format='JPEG', quality=90)
        output_buffer.seek(0)

        log_message("ì–¼êµ´ ë¸”ëŸ¬ ì²˜ë¦¬ ì™„ë£Œ")
        return output_buffer.read()

    except Exception as e:
        log_message(f"ì–¼êµ´ ë¸”ëŸ¬ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        return image_bytes  # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜

def generate_hair_mask(image_bytes: bytes, face_parsing_model: BiSeNet, device: torch.device) -> np.ndarray:
    """ì´ë¯¸ì§€ì—ì„œ í—¤ì–´ ë§ˆìŠ¤í¬ ìƒì„±"""
    try:
        # bytesë¥¼ PIL Imageë¡œ ë³€í™˜
        image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
        image_np = np.array(image)

        # OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ë° ë¦¬ì‚¬ì´ì¦ˆ
        image_resized = cv2.resize(image_np, (512, 512))

        # ì •ê·œí™” ë° í…ì„œ ë³€í™˜
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
        ])

        input_tensor = transform(image_resized).unsqueeze(0).to(device)

        # ë§ˆìŠ¤í¬ ìƒì„±
        with torch.no_grad():
            output = face_parsing_model(input_tensor)[0]
            mask = torch.argmax(output, dim=1).squeeze().cpu().numpy()

        # í—¤ì–´ ë§ˆìŠ¤í¬ (í´ë˜ìŠ¤ 17)
        hair_mask = (mask == 17).astype(np.uint8) * 255
        return hair_mask

    except Exception as e:
        log_message(f"ë§ˆìŠ¤í¬ ìƒì„± ì‹¤íŒ¨: {e}")
        return np.zeros((512, 512), dtype=np.uint8)

def preprocess_image_with_mask(image_bytes: bytes, mask: np.ndarray) -> torch.Tensor:
    """ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ë¥¼ ì „ì²˜ë¦¬í•˜ì—¬ 6ì±„ë„ í…ì„œ ìƒì„±"""
    # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
    image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
    image = image.resize((224, 224))

    # ë§ˆìŠ¤í¬ ë¦¬ì‚¬ì´ì¦ˆ
    mask_resized = cv2.resize(mask, (224, 224))

    # ì´ë¯¸ì§€ ì •ê·œí™”
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    image_tensor = transform(image)  # [3, 224, 224]

    # ë§ˆìŠ¤í¬ë¥¼ 3ì±„ë„ë¡œ í™•ì¥í•˜ê³  ì •ê·œí™”
    mask_normalized = mask_resized.astype(np.float32) / 255.0
    mask_tensor = torch.from_numpy(mask_normalized).unsqueeze(0)  # [1, 224, 224]
    mask_tensor = mask_tensor.repeat(3, 1, 1)  # [3, 224, 224]

    # 6ì±„ë„ ê²°í•©
    combined = torch.cat([image_tensor, mask_tensor], dim=0)  # [6, 224, 224]

    return combined

def analyze_single_image(image_bytes: bytes, model: SwinHairClassifier,
                        face_parsing_model: BiSeNet, device: torch.device) -> Dict[str, Any]:
    """ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„"""
    try:
        # 1. ë§ˆìŠ¤í¬ ìƒì„±
        mask = generate_hair_mask(image_bytes, face_parsing_model, device)

        # 2. ì „ì²˜ë¦¬
        input_tensor = preprocess_image_with_mask(image_bytes, mask)
        input_tensor = input_tensor.unsqueeze(0).to(device)  # [1, 6, 224, 224]

        # 3. ì˜ˆì¸¡
        with torch.no_grad():
            outputs = model(input_tensor)
            probabilities = torch.softmax(outputs, dim=1)
            predicted_class = torch.argmax(outputs, dim=1).item()
            confidence = probabilities[0][predicted_class].item()

        return {
            'level': predicted_class,
            'confidence': confidence,
            'probabilities': probabilities[0].cpu().numpy().tolist()
        }

    except Exception as e:
        log_message(f"ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return None

def calculate_survey_score(survey_data: Dict[str, Any]) -> float:
    """
    ì„¤ë¬¸ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚° (0-3 ë²”ìœ„)
    """
    score = 0.0

    # ë‚˜ì´ (0-0.5)
    age = int(survey_data.get('age', 25))
    if age >= 50:
        score += 0.5
    elif age >= 40:
        score += 0.3
    elif age >= 30:
        score += 0.1

    # ê°€ì¡±ë ¥ (0-0.8)
    if survey_data.get('familyHistory') == 'yes':
        score += 0.8

    # ìµœê·¼ íƒˆëª¨ (0-0.8)
    if survey_data.get('recentHairLoss') == 'yes':
        score += 0.8

    # ìŠ¤íŠ¸ë ˆìŠ¤ (0-0.5)
    stress = survey_data.get('stress', 'low')
    if stress == 'high':
        score += 0.5
    elif stress == 'medium':
        score += 0.25

    # 0-3 ë²”ìœ„ë¡œ ì •ê·œí™” (ìµœëŒ€ 2.6ì´ë¯€ë¡œ ì•½ê°„ ì¡°ì •)
    normalized_score = min(score * (3.0 / 2.6), 3.0)

    return normalized_score

def calculate_dynamic_weights(age: int, family_history: str,
                              top_confidence: float, side_confidence: float) -> Dict[str, float]:
    """
    ë‚˜ì´/ì¦ìƒë³„ + ì‹ ë¢°ë„ ê¸°ë°˜ ë™ì  ê°€ì¤‘ì¹˜ ê³„ì‚° (B + C ê²°í•©)
    """
    # 1ë‹¨ê³„: ë‚˜ì´ë³„ ê¸°ë³¸ ê°€ì¤‘ì¹˜ (B)
    if age < 30:
        base_top = 0.6
        base_side = 0.4
        base_survey = 0.0
    elif age < 50:
        base_top = 0.5
        base_side = 0.35
        base_survey = 0.15
    else:  # 50ëŒ€ ì´ìƒ
        base_top = 0.45
        base_side = 0.3
        base_survey = 0.25

    # ê°€ì¡±ë ¥ì´ ìˆìœ¼ë©´ ì„¤ë¬¸ ê°€ì¤‘ì¹˜ ì¦ê°€
    if family_history == 'yes':
        base_survey += 0.1
        base_top -= 0.05
        base_side -= 0.05

    # 2ë‹¨ê³„: ì‹ ë¢°ë„ ê¸°ë°˜ ë™ì  ì¡°ì • (C)
    # Swin ëª¨ë¸ì˜ í‰ê·  ì‹ ë¢°ë„
    avg_swin_confidence = (top_confidence + side_confidence) / 2.0

    if avg_swin_confidence > 0.85:  # AIê°€ í™•ì‹ í•¨
        adjustment = 0.1
        final_top = base_top + adjustment * 0.6
        final_side = base_side + adjustment * 0.4
        final_survey = max(0, base_survey - adjustment)
    elif avg_swin_confidence < 0.6:  # AIê°€ ë¶ˆí™•ì‹¤
        adjustment = 0.15
        final_top = base_top - adjustment * 0.6
        final_side = base_side - adjustment * 0.4
        final_survey = base_survey + adjustment
    else:  # ë³´í†µ
        final_top = base_top
        final_side = base_side
        final_survey = base_survey

    # ê°€ì¤‘ì¹˜ í•©ì´ 1ì´ ë˜ë„ë¡ ì •ê·œí™”
    total = final_top + final_side + final_survey
    final_top /= total
    final_side /= total
    final_survey /= total

    return {
        'top': final_top,
        'side': final_side,
        'survey': final_survey,
        'avg_confidence': avg_swin_confidence
    }

def fuse_results(top_result: Dict[str, Any], side_result: Dict[str, Any] = None,
                survey_data: Dict[str, Any] = None) -> Dict[str, Any]:
    """Topê³¼ Side ê²°ê³¼ë¥¼ ìœµí•© (B+C ë™ì  ê°€ì¤‘ì¹˜ ì‹œìŠ¤í…œ)"""
    # Topë§Œ ìˆëŠ” ê²½ìš° (ì—¬ì„±) - ì„¤ë¬¸ ë°ì´í„° ì—†ìœ¼ë©´ ë‹¨ìˆœ ë°˜í™˜
    if not side_result:
        if top_result:
            return {
                'stage': top_result['level'],
                'confidence': top_result['confidence'],
                'source': 'single_model_top',
                'weights': {'top': 1.0, 'side': 0.0, 'survey': 0.0}
            }
        else:
            return {'stage': 0, 'confidence': 0.5, 'source': 'error'}

    # Sideë§Œ ìˆëŠ” ê²½ìš° (ë“œë¬¸ ê²½ìš°)
    if not top_result:
        return {
            'stage': side_result['level'],
            'confidence': side_result['confidence'],
            'source': 'single_model_side',
            'weights': {'top': 0.0, 'side': 1.0, 'survey': 0.0}
        }

    # ë‘˜ ë‹¤ ìˆëŠ” ê²½ìš° (ë‚¨ì„±) - B+C ë™ì  ê°€ì¤‘ì¹˜ ì ìš©
    top_stage = top_result['level']
    side_stage = side_result['level']
    top_confidence = top_result['confidence']
    side_confidence = side_result['confidence']

    # ì„¤ë¬¸ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë™ì  ê°€ì¤‘ì¹˜ ê³„ì‚°
    if survey_data:
        age = int(survey_data.get('age', 25))
        family_history = survey_data.get('familyHistory', 'no')

        # B+C ê²°í•©: ë™ì  ê°€ì¤‘ì¹˜ ê³„ì‚°
        weights = calculate_dynamic_weights(age, family_history, top_confidence, side_confidence)

        # ì„¤ë¬¸ ì ìˆ˜ ê³„ì‚°
        survey_score = calculate_survey_score(survey_data)

        # ìµœì¢… stage ê³„ì‚° (ê°€ì¤‘ í‰ê· )
        weighted_stage = (
            top_stage * weights['top'] +
            side_stage * weights['side'] +
            survey_score * weights['survey']
        )
        final_stage = round(weighted_stage)

        # ì‹ ë¢°ë„ ê³„ì‚°
        final_confidence = (
            top_confidence * weights['top'] +
            side_confidence * weights['side'] +
            0.7 * weights['survey']  # ì„¤ë¬¸ì€ 70% ì‹ ë¢°ë„ë¡œ ê°€ì •
        )

        log_message(f"ë™ì  ê°€ì¤‘ì¹˜ - Top: {weights['top']:.2f}, Side: {weights['side']:.2f}, Survey: {weights['survey']:.2f}")
        log_message(f"Stage ê³„ì‚° - Top: {top_stage}, Side: {side_stage}, Survey: {survey_score:.2f} â†’ Final: {final_stage}")

        return {
            'stage': final_stage,
            'confidence': final_confidence,
            'top_result': top_result,
            'side_result': side_result,
            'survey_score': survey_score,
            'weights': weights,
            'source': 'dynamic_weighted'
        }
    else:
        # ì„¤ë¬¸ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ê°€ì¤‘ì¹˜ ì‚¬ìš©
        top_weight = 0.6
        side_weight = 0.4

        weighted_stage = (top_stage * top_weight + side_stage * side_weight)
        final_stage = round(weighted_stage)

        final_confidence = (top_confidence * top_weight + side_confidence * side_weight)

        return {
            'stage': final_stage,
            'confidence': final_confidence,
            'top_result': top_result,
            'side_result': side_result,
            'weights': {'top': top_weight, 'side': side_weight, 'survey': 0.0},
            'source': 'dual_model'
        }

def generate_advice(stage: int) -> List[str]:
    """ë‹¨ê³„ë³„ ì¡°ì–¸ ìƒì„±"""
    advice_map = {
        0: [
            "í˜„ì¬ ê±´ê°•í•œ ëª¨ë°œ ìƒíƒœë¥¼ ìœ ì§€í•˜ê³  ìˆìŠµë‹ˆë‹¤.",
            "ì˜ˆë°© ì°¨ì›ì—ì„œ ê·œì¹™ì ì¸ ë‘í”¼ ë§ˆì‚¬ì§€ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.",
            "ê· í˜• ì¡íŒ ì˜ì–‘ ì„­ì·¨ì™€ ì¶©ë¶„í•œ ìˆ˜ë©´ì„ ìœ ì§€í•˜ì„¸ìš”."
        ],
        1: [
            "ì´ˆê¸° ë‹¨ê³„ì˜ ëª¨ë°œ ë³€í™”ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "ì „ë¬¸ì˜ ìƒë‹´ì„ í†µí•œ ì •í™•í•œ ì§„ë‹¨ì„ ë°›ì•„ë³´ì„¸ìš”.",
            "íƒˆëª¨ ì˜ˆë°© ìƒ´í‘¸ ì‚¬ìš©ê³¼ ë‘í”¼ ì¼€ì–´ë¥¼ ì‹œì‘í•˜ì„¸ìš”."
        ],
        2: [
            "ì¤‘ë“±ë„ì˜ íƒˆëª¨ ì§„í–‰ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "í”¼ë¶€ê³¼ ì „ë¬¸ì˜ ë°©ë¬¸ì„ ê°•ë ¥íˆ ê¶Œì¥í•©ë‹ˆë‹¤.",
            "ë¯¸ë…¹ì‹œë”œ ë“±ì˜ ì¹˜ë£Œì œ ì‚¬ìš©ì„ ê³ ë ¤í•´ë³´ì„¸ìš”."
        ],
        3: [
            "ì§„í–‰ëœ íƒˆëª¨ ìƒíƒœì…ë‹ˆë‹¤.",
            "ì¦‰ì‹œ ì „ë¬¸ì˜ ì§„ë£Œë¥¼ ë°›ìœ¼ì‹œê¸° ë°”ëë‹ˆë‹¤.",
            "ëª¨ë°œì´ì‹ì´ë‚˜ ê¸°íƒ€ ì¹˜ë£Œ ì˜µì…˜ì„ ìƒë‹´ë°›ì•„ë³´ì„¸ìš”."
        ]
    }
    return advice_map.get(stage, advice_map[0])

def enhance_with_llm(stage: int, confidence: float, survey_data: Dict[str, Any] = None) -> Dict[str, Any]:
    """
    LLMì„ ì‚¬ìš©í•˜ì—¬ ë¶„ì„ ê²°ê³¼ë¥¼ ìì—°ìŠ¤ëŸ½ê³  ìƒì„¸í•˜ê²Œ í¬ì¥
    Args:
        stage: ë¶„ì„ëœ íƒˆëª¨ ë‹¨ê³„ (0-3)
        confidence: ë¶„ì„ ì‹ ë¢°ë„
        survey_data: ì„¤ë¬¸ ë°ì´í„° (optional)
    Returns: {"title": str, "description": str, "advice": List[str]}
    """
    try:
        # Gemini API ì„¤ì • (ê²°ê³¼ í¬ì¥ ì „ìš© í‚¤ ì‚¬ìš©)
        api_key = os.getenv("GEMINI_API_KEY_1")
        log_message(f"ğŸ”‘ API í‚¤ í™•ì¸: {'ì¡´ì¬í•¨' if api_key else 'ì—†ìŒ'}")

        if not api_key:
            log_message("âš ï¸ GEMINI_API_KEY_1 ì—†ìŒ - ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©")
            return generate_title_and_description_fallback(stage)

        log_message("ğŸ“¡ Gemini API í˜¸ì¶œ ì¤€ë¹„ ì¤‘...")
        genai.configure(api_key=api_key)

        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ëª… ì‹œë„ (ìˆœì„œëŒ€ë¡œ)
        model_names = [
            'gemini-2.5-pro',
            'gemini-pro',
            'gemini-1.5-pro-latest',
            'models/gemini-pro',
            'gemini-1.0-pro'
        ]

        model = None
        for model_name in model_names:
            try:
                model = genai.GenerativeModel(model_name)
                log_message(f"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {model_name}")
                break
            except Exception as e:
                log_message(f"âš ï¸ {model_name} ì‹¤íŒ¨: {str(e)[:100]}")
                continue

        if model is None:
            log_message("âŒ ëª¨ë“  ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ - ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©")
            return generate_title_and_description_fallback(stage)

        # ì„¤ë¬¸ ë°ì´í„° ì •ë³´ ì¶”ê°€
        survey_context = ""
        if survey_data:
            age = survey_data.get('age', 'ì•Œ ìˆ˜ ì—†ìŒ')
            family_history = "ìˆìŒ" if survey_data.get('familyHistory') == 'yes' else "ì—†ìŒ"
            recent_loss = "ìˆìŒ" if survey_data.get('recentHairLoss') == 'yes' else "ì—†ìŒ"
            stress = survey_data.get('stress', 'low')
            stress_level = {"low": "ë‚®ìŒ", "medium": "ë³´í†µ", "high": "ë†’ìŒ"}.get(stress, "ë³´í†µ")

            survey_context = f"""
ì‚¬ìš©ì ì •ë³´:
- ë‚˜ì´: {age}ì„¸
- ê°€ì¡±ë ¥: {family_history}
- ìµœê·¼ íƒˆëª¨ ì¦ìƒ: {recent_loss}
- ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€: {stress_level}
"""

        # ë‹¨ê³„ë³„ ê¸°ë³¸ ì •ë³´
        stage_info = {
            0: {"level": "ì •ìƒ", "severity": "ê±´ê°•í•œ ìƒíƒœ"},
            1: {"level": "ì´ˆê¸° ë‹¨ê³„", "severity": "ê²½ë¯¸í•œ ë³€í™”"},
            2: {"level": "ì¤‘ë“±ë„", "severity": "ì§„í–‰ ì¤‘"},
            3: {"level": "ì‹¬ê° ë‹¨ê³„", "severity": "ìƒë‹¹íˆ ì§„í–‰ë¨"}
        }
        info = stage_info.get(stage, stage_info[0])

        # ì„±ë³„ ì •ë³´ ì¶”ê°€
        gender_text = "ë‚¨ì„±" if survey_data and survey_data.get('gender') == 'male' else "ì—¬ì„±"

        # LLM í”„ë¡¬í”„íŠ¸
        prompt = f"""ë‹¹ì‹ ì€ ê²½í—˜ì´ í’ë¶€í•œ íƒˆëª¨ ì „ë¬¸ì˜ì…ë‹ˆë‹¤. AI ë¶„ì„ ê²°ê³¼ì™€ í™˜ìì˜ ì„¤ë¬¸ì¡°ì‚¬ ì •ë³´ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬, í™˜ì ê°œê°œì¸ì—ê²Œ ë§ì¶¤í™”ëœ ìƒì„¸í•œ ì„¤ëª…ê³¼ ì¡°ì–¸ì„ ì œê³µí•´ì£¼ì„¸ìš”.

AI ë¶„ì„ ê²°ê³¼:
- ì„±ë³„: {gender_text}
- íƒˆëª¨ ë‹¨ê³„: {stage}ë‹¨ê³„ ({info['level']})
- ì‹¬ê°ë„: {info['severity']}
- ë¶„ì„ ì‹ ë¢°ë„: {confidence:.1%}
{survey_context}

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "title": "í™˜ì ìƒíƒœë¥¼ ì •í™•íˆ í‘œí˜„í•˜ëŠ” ì§„ë‹¨ëª… (15ì ì´ë‚´, ì„±ë³„ íŠ¹ì„± ë°˜ì˜)",
  "description": "í˜„ì¬ ìƒíƒœì— ëŒ€í•œ ìƒì„¸í•˜ê³  ì „ë¬¸ì ì¸ ì„¤ëª… (100-200ì). ë°˜ë“œì‹œ **{gender_text} íƒˆëª¨ì˜ íŠ¹ì§•**ê³¼ ì„¤ë¬¸ì¡°ì‚¬ ì •ë³´(ë‚˜ì´, ê°€ì¡±ë ¥, ìµœê·¼ íƒˆëª¨ ì¦ìƒ, ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€)ë¥¼ ì–¸ê¸‰í•˜ë©° í™˜ìì˜ ìƒí™©ì„ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”. {gender_text} íƒˆëª¨ íŒ¨í„´(ì˜ˆ: ë‚¨ì„±ì€ Mì íƒˆëª¨ë‚˜ ì •ìˆ˜ë¦¬ íƒˆëª¨, ì—¬ì„±ì€ ì „ì²´ì ì¸ ëª¨ë°œ ë°€ë„ ê°ì†Œ)ì„ ì„¤ëª…ì— í¬í•¨í•˜ì„¸ìš”.",
  "advice": [
    "{gender_text} íƒˆëª¨ íŠ¹ì„±ì„ ê³ ë ¤í•œ êµ¬ì²´ì ì´ê³  ì‹¤ì²œ ê°€ëŠ¥í•œ ì¡°ì–¸ 1 (30-50ì, í™˜ìì˜ ë‚˜ì´/ìƒí™œìŠµê´€ ê³ ë ¤)",
    "í™˜ì ë§ì¶¤í˜• ì¡°ì–¸ 2 (30-50ì, ê°€ì¡±ë ¥/ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€ ë°˜ì˜)",
    "ë‹¨ê³„ë³„ í•„ìˆ˜ ê´€ë¦¬ ë°©ë²• ì¡°ì–¸ 3 (30-50ì, ì¦‰ì‹œ ì‹¤ì²œ ê°€ëŠ¥í•œ ë‚´ìš©)"
  ]
}}

ì¤‘ìš” ìš”êµ¬ì‚¬í•­:
1. **ì„±ë³„ íŠ¹ì„±ì„ ë°˜ë“œì‹œ ì–¸ê¸‰**
   - {gender_text} íƒˆëª¨ì˜ ì¼ë°˜ì ì¸ íŒ¨í„´ ì„¤ëª…
   - {gender_text}ì—ê²Œ í”í•œ íƒˆëª¨ ì›ì¸ ì–¸ê¸‰ (ì˜ˆ: ë‚¨ì„±ì€ DHT, ì—¬ì„±ì€ í˜¸ë¥´ëª¬ ë³€í™”)
   - {gender_text} í™˜ìì—ê²Œ ì í•©í•œ ê´€ë¦¬ ë°©ë²• ì œì‹œ

2. ì„¤ë¬¸ì¡°ì‚¬ ì •ë³´ë¥¼ ì ê·¹ì ìœ¼ë¡œ í™œìš©í•˜ì—¬ ê°œì¸ ë§ì¶¤í˜• ì„¤ëª… ì‘ì„±
   - ë‚˜ì´ëŒ€ë³„ íŠ¹ì„± ì–¸ê¸‰ (ì˜ˆ: "30ëŒ€ {gender_text}ìœ¼ë¡œ íƒˆëª¨ê°€ ì‹œì‘ë˜ê¸° ì‰¬ìš´ ì‹œê¸°ì…ë‹ˆë‹¤")
   - ê°€ì¡±ë ¥ì´ ìˆìœ¼ë©´ ìœ ì „ì  ìš”ì¸ ê°•ì¡°
   - ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€ì´ ë†’ìœ¼ë©´ ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ì˜ ì¤‘ìš”ì„± ì–¸ê¸‰
   - ìµœê·¼ íƒˆëª¨ ì¦ìƒì´ ìˆìœ¼ë©´ ì§„í–‰ ì†ë„ ì£¼ì˜ì‚¬í•­ ì„¤ëª…

3. descriptionì€ ìµœì†Œ 100ì ì´ìƒìœ¼ë¡œ ìì„¸í•˜ê²Œ ì‘ì„±
   - {gender_text} íƒˆëª¨ì˜ íŠ¹ì§•
   - í˜„ì¬ ìƒíƒœ ë¶„ì„
   - ì„¤ë¬¸ì¡°ì‚¬ ì •ë³´ì™€ì˜ ì—°ê´€ì„±
   - í–¥í›„ ì „ë§ ë° ê´€ë¦¬ í•„ìš”ì„±

4. adviceëŠ” {gender_text} í™˜ìì˜ ìƒí™©ì— ë§ëŠ” êµ¬ì²´ì ì¸ í–‰ë™ ì§€ì¹¨ ì œê³µ
   - ì¼ë°˜ì ì¸ ì¡°ì–¸ì´ ì•„ë‹Œ ì„±ë³„ê³¼ ê°œì¸ ìƒí™©ì— ë§ì¶¤í™”ëœ ì¡°ì–¸
   - ì‹¤ì²œ ê°€ëŠ¥í•œ êµ¬ì²´ì ì¸ ë°©ë²• ì œì‹œ

5. ì¹œì ˆí•˜ê³  í¬ë§ì ì¸ í†¤ ìœ ì§€í•˜ë˜, ì •í™•í•œ ì •ë³´ ì „ë‹¬
6. ì¶”ê°€ í…ìŠ¤íŠ¸ ì—†ì´ JSONë§Œ ë°˜í™˜"""

        # LLM í˜¸ì¶œ
        log_message("ğŸ¤– Geminiì— ìš”ì²­ ì „ì†¡ ì¤‘...")
        response = model.generate_content(prompt)
        response_text = response.text.strip()
        log_message(f"ğŸ“¥ Gemini ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ (ê¸¸ì´: {len(response_text)})")

        # JSON ì¶”ì¶œ
        import re
        json_match = re.search(r'\{[\s\S]*\}', response_text)
        if not json_match:
            log_message(f"âŒ JSON ì¶”ì¶œ ì‹¤íŒ¨ - ì‘ë‹µ ë‚´ìš©: {response_text[:200]}")
            return generate_title_and_description_fallback(stage)

        result = json.loads(json_match.group())

        # ê²€ì¦
        if not all(key in result for key in ['title', 'description', 'advice']):
            log_message(f"âŒ í•„ë“œ ëˆ„ë½ - ì‘ë‹µ: {result}")
            return generate_title_and_description_fallback(stage)

        log_message(f"âœ… LLM í¬ì¥ ì™„ë£Œ: {result['title']}")
        return result

    except Exception as e:
        log_message(f"LLM í¬ì¥ ì‹¤íŒ¨: {e} - ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©")
        return generate_title_and_description_fallback(stage)

def generate_title_and_description_fallback(stage: int) -> Dict[str, Any]:
    """LLM ì‚¬ìš© ë¶ˆê°€ ì‹œ ê¸°ë³¸ í…œí”Œë¦¿ (ê¸°ì¡´ í•¨ìˆ˜)"""
    stage_info = {
        0: {
            'title': 'ì •ìƒ - ê±´ê°•í•œ ëª¨ë°œ ìƒíƒœ',
            'description': 'í˜„ì¬ íƒˆëª¨ ì§•í›„ê°€ ê´€ì°°ë˜ì§€ ì•ŠëŠ” ê±´ê°•í•œ ëª¨ë°œ ìƒíƒœì…ë‹ˆë‹¤. ì§€ì†ì ì¸ ê´€ë¦¬ë¥¼ í†µí•´ í˜„ì¬ ìƒíƒœë¥¼ ìœ ì§€í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.',
            'advice': generate_advice(0)
        },
        1: {
            'title': 'ì´ˆê¸° ë‹¨ê³„ - ê²½ë¯¸í•œ ëª¨ë°œ ë³€í™”',
            'description': 'ì´ˆê¸° ë‹¨ê³„ì˜ ëª¨ë°œ ë³€í™”ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì ˆí•œ ì˜ˆë°© ê´€ë¦¬ì™€ ì „ë¬¸ì˜ ìƒë‹´ì„ í†µí•´ ì§„í–‰ì„ ëŠ¦ì¶œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
            'advice': generate_advice(1)
        },
        2: {
            'title': 'ì¤‘ë“±ë„ - ì§„í–‰ ì¤‘ì¸ íƒˆëª¨',
            'description': 'ì¤‘ë“±ë„ì˜ íƒˆëª¨ê°€ ì§„í–‰ë˜ê³  ìˆìŠµë‹ˆë‹¤. ì „ë¬¸ì ì¸ ì¹˜ë£Œì™€ ê´€ë¦¬ê°€ í•„ìš”í•œ ì‹œì ì…ë‹ˆë‹¤.',
            'advice': generate_advice(2)
        },
        3: {
            'title': 'ì‹¬ê° ë‹¨ê³„ - ì§„í–‰ëœ íƒˆëª¨',
            'description': 'ìƒë‹¹íˆ ì§„í–‰ëœ íƒˆëª¨ ìƒíƒœì…ë‹ˆë‹¤. ì „ë¬¸ì˜ì™€ì˜ ìƒë‹´ì„ í†µí•œ ì ê·¹ì ì¸ ì¹˜ë£Œê°€ í•„ìš”í•©ë‹ˆë‹¤.',
            'advice': generate_advice(3)
        }
    }
    return stage_info.get(stage, stage_info[0])

def generate_title_and_description(stage: int) -> tuple:
    """ë‹¨ê³„ë³„ ì œëª©ê³¼ ì„¤ëª… ìƒì„± (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)"""
    result = generate_title_and_description_fallback(stage)
    return result['title'], result['description']

# ê¸€ë¡œë²Œ ëª¨ë¸ ë³€ìˆ˜ (ëª¨ë¸ ë¡œë”© ìµœì í™”)
_side_model = None
_top_model = None
_face_parsing_model = None
_device = None

def initialize_models():
    """ëª¨ë¸ë“¤ì„ ì´ˆê¸°í™” (í•œ ë²ˆë§Œ ë¡œë“œ)"""
    global _side_model, _top_model, _face_parsing_model, _device

    if _side_model is None:
        _device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        log_message(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {_device}")

        # ëª¨ë¸ ê²½ë¡œ
        side_model_path = 'services/swin_hair_classification/models/best_swin_hair_classifier_side.pth'
        top_model_path = 'services/swin_hair_classification/models/best_swin_hair_classifier_top.pth'

        # ëª¨ë¸ ë¡œë“œ
        _side_model = load_swin_model(side_model_path, _device)
        _top_model = load_swin_model(top_model_path, _device)
        _face_parsing_model = load_face_parsing_model(_device)

        log_message("ëª¨ë“  ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")

def analyze_hair_with_swin(top_image_data: bytes, side_image_data: bytes = None,
                          survey_data: Dict[str, Any] = None) -> Dict[str, Any]:
    """
    Swin ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  í‘œì¤€ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    Args:
        top_image_data: Top view ì´ë¯¸ì§€ì˜ ì´ì§„(bytes) ë°ì´í„°
        side_image_data: Side view ì´ë¯¸ì§€ì˜ ì´ì§„(bytes) ë°ì´í„° (optional, ì—¬ì„±ì˜ ê²½ìš° None)
        survey_data: ì„¤ë¬¸ ë°ì´í„° (optional, ë™ì  ê°€ì¤‘ì¹˜ ê³„ì‚°ì— ì‚¬ìš©)
    Returns: {"stage": int, "title": str, "description": str, "advice": List[str]}
    """
    try:
        # ëª¨ë¸ ì´ˆê¸°í™” (ì²˜ìŒ í•œ ë²ˆë§Œ)
        initialize_models()

        log_message("Swin ëª¨ë¸ ë¶„ì„ ì‹œì‘")
        if survey_data:
            log_message(f"ì„¤ë¬¸ ë°ì´í„°: ë‚˜ì´={survey_data.get('age')}, ê°€ì¡±ë ¥={survey_data.get('familyHistory')}")

        # Top ì´ë¯¸ì§€ ë¶„ì„
        log_message("Top view ë¶„ì„ ì¤‘...")
        top_result = analyze_single_image(top_image_data, _top_model, _face_parsing_model, _device)

        # Side ì´ë¯¸ì§€ ë¶„ì„ (ìˆëŠ” ê²½ìš°ë§Œ)
        side_result = None
        if side_image_data:
            log_message("Side view ë¶„ì„ ì¤‘...")
            side_result = analyze_single_image(side_image_data, _side_model, _face_parsing_model, _device)
        else:
            log_message("Side view ì´ë¯¸ì§€ ì—†ìŒ (ì—¬ì„± ë¶„ì„)")

        # ê²°ê³¼ ìœµí•© (ì„¤ë¬¸ ë°ì´í„° í¬í•¨)
        log_message("ê²°ê³¼ ìœµí•© ì¤‘...")
        fused_result = fuse_results(top_result, side_result, survey_data)

        # ìµœì¢… ê²°ê³¼ êµ¬ì„±
        final_stage = fused_result['stage']
        final_confidence = fused_result['confidence']

        # LLMìœ¼ë¡œ ê²°ê³¼ í¬ì¥ (ì„¤ë¬¸ ë°ì´í„° í¬í•¨)
        log_message("=" * 50)
        log_message("LLMìœ¼ë¡œ ê²°ê³¼ í¬ì¥ ì¤‘...")
        log_message(f"ì…ë ¥ ì •ë³´ - Stage: {final_stage}, Confidence: {final_confidence:.2%}")

        llm_result = enhance_with_llm(final_stage, final_confidence, survey_data)

        log_message(f"LLM í¬ì¥ ê²°ê³¼:")
        log_message(f"  - ì œëª©: {llm_result['title']}")
        log_message(f"  - ì„¤ëª…: {llm_result['description'][:50]}...")
        log_message(f"  - ì¡°ì–¸ ê°œìˆ˜: {len(llm_result['advice'])}")
        for i, advice in enumerate(llm_result['advice'], 1):
            log_message(f"    [{i}] {advice}")
        log_message("=" * 50)

        # advice ë°°ì—´ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸° (êµ¬ë¶„ì: ì¤„ë°”ê¿ˆ)
        advice_text = "\n".join(llm_result['advice']) if isinstance(llm_result['advice'], list) else str(llm_result['advice'])
        
        result = {
            "stage": final_stage,
            "title": llm_result['title'],
            "description": llm_result['description'],
            "advice": advice_text,
            "confidence": final_confidence,
            "analysis_type": "hairloss"
        }

        log_message(f"âœ… ë¶„ì„ ì™„ë£Œ: Stage {final_stage}, ì‹ ë¢°ë„ {final_confidence:.2%}")
        return result

    except Exception as e:
        log_message(f"Swin ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

        # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ ê²°ê³¼ ë°˜í™˜
        return {
            "stage": 0,
            "title": "ë¶„ì„ ì˜¤ë¥˜ ë°œìƒ",
            "description": "ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            "advice": ["ì´ë¯¸ì§€ë¥¼ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", "ë¬¸ì œê°€ ì§€ì†ë˜ë©´ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."],
            "confidence": 0.0,
            "analysis_type": "error"
        }