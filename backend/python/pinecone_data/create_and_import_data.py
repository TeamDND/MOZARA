"""
Pinecone ì¸ë±ìŠ¤ ìƒì„± ë° ë°ì´í„° ì…ë ¥ ìŠ¤í¬ë¦½íŠ¸
"""
import os
import pinecone
from dotenv import load_dotenv
import random
import json
import glob
from pathlib import Path

# .env íŒŒì¼ ë¡œë“œ (ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ .env íŒŒì¼ ì‚¬ìš©)
load_dotenv("../../../.env")

def create_index_and_import_data():
    """ì¸ë±ìŠ¤ ìƒì„± ë° ë°ì´í„° ì…ë ¥"""
    
    # Pinecone ì´ˆê¸°í™”
    api_key = os.getenv("PINECONE_API_KEY")
    if not api_key:
        print("âŒ PINECONE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    print("ğŸŒ² Pinecone í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘...")
    pinecone.init(api_key=api_key, environment="us-east-1")
    
    index_name = os.getenv("PINECONE_INDEX_NAME2")
    
    try:
        # ê¸°ì¡´ ì¸ë±ìŠ¤ í™•ì¸
        existing_indexes = [index.name for index in pinecone.list_indexes()]
        print(f"ğŸ“‹ ê¸°ì¡´ ì¸ë±ìŠ¤ ëª©ë¡: {existing_indexes}")
        
        if index_name in existing_indexes:
            print(f"âœ… ì¸ë±ìŠ¤ '{index_name}'ì´(ê°€) ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
            # ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚­ì œ
            print(f"ğŸ—‘ï¸ ê¸°ì¡´ ì¸ë±ìŠ¤ '{index_name}' ì‚­ì œ ì¤‘...")
            pinecone.delete_index(index_name)
            print(f"âœ… ì¸ë±ìŠ¤ '{index_name}' ì‚­ì œ ì™„ë£Œ!")
        
        # ìƒˆ ì¸ë±ìŠ¤ ìƒì„±
        print(f"ğŸ†• ì¸ë±ìŠ¤ '{index_name}' ìƒì„± ì¤‘...")
        pinecone.create_index(
            name=index_name,
            dimension=768,  # CLIP ëª¨ë¸ì˜ ë²¡í„° ì°¨ì›
            metric="cosine"
        )
        print(f"âœ… ì¸ë±ìŠ¤ '{index_name}' ìƒì„± ì™„ë£Œ!")
        
        # ì¸ë±ìŠ¤ ì—°ê²°
        index = pinecone.Index(index_name)
        
        # ì‹¤ì œ ë°ì´í„° ì…ë ¥
        print("ğŸ“Š ì‹¤ì œ ë°ì´í„° ì…ë ¥ ì¤‘...")
        data_path = "C:/Users/301/Desktop/data_all"
        vectors_data = []
        
        # ë¼ë²¨ë§ ë°ì´í„° í´ë” ê²½ë¡œ
        labeling_path = os.path.join(data_path, "ë¼ë²¨ë§ë°ì´í„°")
        
        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë°ì´í„° ì²˜ë¦¬
        categories = ["1.ë¯¸ì„¸ê°ì§ˆ", "2.í”¼ì§€ê³¼ë‹¤", "3.ëª¨ë‚­ì‚¬ì´í™ë°˜", "4.ëª¨ë‚­í™ë°˜ë†í¬", "5.ë¹„ë“¬", "6.íƒˆëª¨"]
        severity_levels = ["0.ì–‘í˜¸", "1.ê²½ì¦", "2.ì¤‘ë“±ë„", "3.ì¤‘ì¦"]
        
        for category in categories:
            print(f"ğŸ“ ì¹´í…Œê³ ë¦¬ '{category}' ì²˜ë¦¬ ì¤‘...")
            
            for severity in severity_levels:
                category_path = os.path.join(labeling_path, category, severity)
                
                if not os.path.exists(category_path):
                    continue
                
                # JSON íŒŒì¼ë“¤ ì½ê¸°
                json_files = glob.glob(os.path.join(category_path, "*.json"))
                
                for json_file in json_files:
                    try:
                        with open(json_file, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                        
                        # 768ì°¨ì› ëœë¤ ë²¡í„° ìƒì„± (ì‹¤ì œë¡œëŠ” ì´ë¯¸ì§€ ì„ë² ë”©ì„ ì‚¬ìš©í•´ì•¼ í•¨)
                        vector = [random.random() for _ in range(768)]
                        
                        # ë©”íƒ€ë°ì´í„° êµ¬ì„±
                        metadata = {
                            "image_id": data.get("image_id", ""),
                            "image_file_name": data.get("image_file_name", ""),
                            "category": category,
                            "severity": severity,
                            "severity_level": severity.split(".")[0],
                            "value_1": data.get("value_1", "0"),
                            "value_2": data.get("value_2", "0"),
                            "value_3": data.get("value_3", "0"),
                            "value_4": data.get("value_4", "0"),
                            "value_5": data.get("value_5", "0"),
                            "value_6": data.get("value_6", "0")
                        }
                        
                        vectors_data.append({
                            "id": data.get("image_id", f"unknown_{len(vectors_data)}"),
                            "values": vector,
                            "metadata": metadata
                        })
                        
                    except Exception as e:
                        print(f"âš ï¸ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {json_file} - {str(e)}")
                        continue
        
        # ë²¡í„° ì—…ë¡œë“œ (ë°°ì¹˜ ë‹¨ìœ„ë¡œ)
        batch_size = 100
        total_uploaded = 0
        
        for i in range(0, len(vectors_data), batch_size):
            batch = vectors_data[i:i + batch_size]
            index.upsert(vectors=batch)
            total_uploaded += len(batch)
            print(f"ğŸ“¤ {total_uploaded}/{len(vectors_data)} ë²¡í„° ì—…ë¡œë“œ ì™„ë£Œ...")
        
        print(f"âœ… ì´ {len(vectors_data)}ê°œ ë°ì´í„° ì…ë ¥ ì™„ë£Œ!")
        
        # ì¸ë±ìŠ¤ ìƒíƒœ í™•ì¸
        stats = index.describe_index_stats()
        print(f"ğŸ“Š ì¸ë±ìŠ¤ í†µê³„: {stats}")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if __name__ == "__main__":
    create_index_and_import_data()