#!/usr/bin/env python3
r"""
ì‚¬ì´ë“œ ë·°í¬ì¸íŠ¸ ë¹„êµ í…ŒìŠ¤íŠ¸: ì¼ë°˜ ì•™ìƒë¸” vs GeM í’€ë§ ì•™ìƒë¸”
- ì¼ë°˜ ì•™ìƒë¸”: ëª¨ë“  ì´ë¯¸ì§€ì— ë™ì¼í•œ ë°©ì‹ ì ìš©
- GeM ì•™ìƒë¸”: Left/Right ë·°í¬ì¸íŠ¸ë§Œ GeM pooling ì ìš©

í…ŒìŠ¤íŠ¸ ë°ì´í„°: C:\Users\301\Desktop\classification_test_side (level_2..level_6)
"""

import os
import re
import json
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
from PIL import Image, ImageEnhance
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as T
import timm
from dotenv import load_dotenv

from pinecone import Pinecone


# ---------- ê²½ë¡œ/ì„¤ì • ----------
THIS_DIR = Path(__file__).parent
LOG_BASE_PATH = Path(r"C:\Users\301\Desktop\main_project\backend\hair_classification\result_log\log")

TEST_ROOT = Path(r"C:\Users\301\Desktop\classification_test_side")  # level_2..level_6 (ì‚¬ì´ë“œ ë·° ì „ìš©)
ENV_PATH = r"C:\Users\301\Desktop\main_project\.env"

INDEX_CONV = "hair-loss-rag-analyzer"
INDEX_VIT = "hair-loss-vit-s16"

NUM_CLASSES = 5  # Level 2-6 only (5 classes)
CLASS_OFFSET = 2  # Start from level 2
TOP_K = 10
T_CONV = 0.15
T_VIT = 0.20
USE_OVERRIDE = True


class GeM(nn.Module):
    """GeM (Generalized Mean) Pooling Layer"""
    def __init__(self, p=3, eps=1e-6):
        super(GeM, self).__init__()
        self.p = nn.Parameter(torch.ones(1) * p)
        self.eps = eps

    def forward(self, x):
        # x: (batch_size, channels, height, width) or (batch_size, seq_len, channels)
        if len(x.shape) == 4:  # ConvNet features
            return self.gem_2d(x)
        elif len(x.shape) == 3:  # ViT features
            return self.gem_1d(x)
        else:
            return F.adaptive_avg_pool2d(x, 1).flatten(1)

    def gem_2d(self, x):
        # For ConvNet: (batch, channels, h, w)
        x = torch.clamp(x, min=self.eps)
        x = F.adaptive_avg_pool2d(x.pow(self.p), 1)
        x = x.pow(1./self.p)
        return x.flatten(1)

    def gem_1d(self, x):
        # For ViT: (batch, seq_len, channels) -> take mean over seq_len
        x = torch.clamp(x, min=self.eps)
        x = x.pow(self.p).mean(dim=1)  # Average over sequence length
        x = x.pow(1./self.p)
        return x


def detect_viewpoint_from_filename(filename: str) -> str:
    """íŒŒì¼ëª…ì—ì„œ ë·°í¬ì¸íŠ¸ ì¶”ì •"""
    filename_upper = filename.upper()
    if 'LEFT' in filename_upper or '_L_' in filename_upper:
        return 'left'
    elif 'RIGHT' in filename_upper or '_R_' in filename_upper:
        return 'right'
    elif 'TOP' in filename_upper or 'DOWN' in filename_upper or '_T_' in filename_upper:
        return 'top-down'
    elif 'FRONT' in filename_upper or '_F_' in filename_upper:
        return 'front'
    elif 'BACK' in filename_upper or '_B_' in filename_upper:
        return 'back'
    else:
        return 'unknown'


def is_side_viewpoint(filename: str) -> bool:
    """ì‚¬ì´ë“œ ë·°í¬ì¸íŠ¸ (Left/Right) ì¸ì§€ í™•ì¸"""
    viewpoint = detect_viewpoint_from_filename(filename)
    return viewpoint in ['left', 'right']


# ---------- ìœ í‹¸/ì „ì²˜ë¦¬ ----------
def ensure_dir(p: Path):
    p.mkdir(parents=True, exist_ok=True)


def enhance_image(img: Image.Image) -> Image.Image:
    img = ImageEnhance.Sharpness(img).enhance(1.05)
    img = ImageEnhance.Contrast(img).enhance(1.05)
    img = ImageEnhance.Brightness(img).enhance(1.03)
    img = ImageEnhance.Color(img).enhance(1.03)
    return img


def tf_vit():
    return T.Compose([
        T.Resize(224, interpolation=T.InterpolationMode.BICUBIC),
        T.CenterCrop(224),
        T.ToTensor(),
        T.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225)),
    ])


def tf_conv():
    return T.Compose([
        T.Resize(384, interpolation=T.InterpolationMode.BICUBIC),
        T.CenterCrop(384),
        T.ToTensor(),
        T.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225)),
    ])


def load_models(device: str = "cpu", use_gem: bool = False):
    vit = timm.create_model("vit_small_patch16_224", pretrained=True, num_classes=0, global_pool="avg").eval().to(device)
    conv = timm.create_model("convnext_large.fb_in22k_ft_in1k_384", pretrained=True, num_classes=0, global_pool="avg").eval().to(device)

    gem_layer = None
    if use_gem:
        gem_layer = GeM(p=3).to(device).eval()

    return vit, conv, gem_layer


def embed_normal(img: Image.Image, model, transform) -> np.ndarray:
    """ì¼ë°˜ ì„ë² ë”© (Global Average Pooling)"""
    if img.mode != "RGB":
        img = img.convert("RGB")
    img = enhance_image(img)
    x = transform(img).unsqueeze(0)
    with torch.no_grad():
        z = model(x).cpu().numpy()[0]
    z = z / (np.linalg.norm(z) + 1e-12)
    return z


def embed_gem(img: Image.Image, model, transform, gem_layer) -> np.ndarray:
    """GeM í’€ë§ ì„ë² ë”©"""
    if img.mode != "RGB":
        img = img.convert("RGB")
    img = enhance_image(img)
    x = transform(img).unsqueeze(0)

    with torch.no_grad():
        # ëª¨ë¸ë³„ íŠ¹ì§• ì¶”ì¶œ ë°©ì‹
        if 'vit' in str(model.__class__).lower():
            # ViTì˜ ê²½ìš° - íŒ¨ì¹˜ í† í°ë“¤ì„ ì–»ê¸° ìœ„í•´ forward_features ì‚¬ìš©
            if hasattr(model, 'forward_features'):
                features = model.forward_features(x)  # (batch, seq_len, channels)
                z = gem_layer(features).cpu().numpy()[0]
            else:
                # ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ í´ë°±
                z = model(x).cpu().numpy()[0]
        else:
            # ConvNetì˜ ê²½ìš° - feature mapì„ ì–»ê¸° ìœ„í•´ forward_features ì‚¬ìš©
            if hasattr(model, 'forward_features'):
                features = model.forward_features(x)  # (batch, channels, h, w)
                z = gem_layer(features).cpu().numpy()[0]
            else:
                # ê¸°ë³¸ ë°©ì‹ìœ¼ë¡œ í´ë°±
                z = model(x).cpu().numpy()[0]

    z = z / (np.linalg.norm(z) + 1e-12)
    return z


def knn_to_probs(matches: List[Dict], num_classes=NUM_CLASSES, T=0.20) -> np.ndarray:
    if not matches:
        return np.zeros(num_classes, dtype=float)
    sims = np.array([m["score"] for m in matches], float)
    w = np.exp(sims / T)
    w = w / (w.sum() + 1e-12)
    probs = np.zeros(num_classes, float)
    for wi, m in zip(w, matches):
        md = m.get("metadata", {})
        if "stage" in md:
            st = int(md["stage"])
        else:
            st = None
            for k in ("level", "class", "label"):
                v = md.get(k)
                if isinstance(v, str):
                    mm = re.search(r"(\d+)", v)
                    if mm:
                        st = int(mm.group(1))
                        break
            if st is None:
                src = m.get("id") or ""
                mm = re.search(r"(\d+)", str(src))
                st = int(mm.group(1)) if mm else 0
        if 2 <= st <= 6:  # Only level 2-6
            probs[st-CLASS_OFFSET] += wi
    s = probs.sum()
    return probs / s if s > 0 else probs


def predict_normal(pc: Pinecone, idx_conv, idx_vit, img_path: Path, vit, conv, tf_v, tf_c) -> Tuple[np.ndarray, np.ndarray]:
    """ì¼ë°˜ ì•™ìƒë¸” ì˜ˆì¸¡"""
    img = Image.open(img_path)
    vq = embed_normal(img, vit, tf_v)
    cq = embed_normal(img, conv, tf_c)
    r_v = idx_vit.query(vector=vq.tolist(), top_k=TOP_K, include_metadata=True)
    r_c = idx_conv.query(vector=cq.tolist(), top_k=TOP_K, include_metadata=True)
    p_v = knn_to_probs(r_v.get("matches", []), NUM_CLASSES, T=T_VIT)
    p_c = knn_to_probs(r_c.get("matches", []), NUM_CLASSES, T=T_CONV)
    return p_c, p_v


def predict_gem_selective(pc: Pinecone, idx_conv, idx_vit, img_path: Path,
                         vit, conv, tf_v, tf_c, gem_layer) -> Tuple[np.ndarray, np.ndarray]:
    """ì„ íƒì  GeM ì•™ìƒë¸” ì˜ˆì¸¡ (ì‚¬ì´ë“œ ë·°í¬ì¸íŠ¸ë§Œ GeM ì ìš©)"""
    img = Image.open(img_path)

    # ì‚¬ì´ë“œ ë·°í¬ì¸íŠ¸ ì—¬ë¶€ í™•ì¸
    is_side = is_side_viewpoint(img_path.name)

    if is_side:
        # Left/RightëŠ” GeM pooling ì‚¬ìš©
        vq = embed_gem(img, vit, tf_v, gem_layer)
        cq = embed_gem(img, conv, tf_c, gem_layer)
    else:
        # ë‹¤ë¥¸ ë·°í¬ì¸íŠ¸ëŠ” ì¼ë°˜ pooling ì‚¬ìš©
        vq = embed_normal(img, vit, tf_v)
        cq = embed_normal(img, conv, tf_c)

    r_v = idx_vit.query(vector=vq.tolist(), top_k=TOP_K, include_metadata=True)
    r_c = idx_conv.query(vector=cq.tolist(), top_k=TOP_K, include_metadata=True)
    p_v = knn_to_probs(r_v.get("matches", []), NUM_CLASSES, T=T_VIT)
    p_c = knn_to_probs(r_c.get("matches", []), NUM_CLASSES, T=T_CONV)
    return p_c, p_v


def collect_test_set(root: Path) -> List[Tuple[Path, int]]:
    items = []
    seen_files = set()
    if not root.exists():
        return items
    for child in sorted(root.iterdir()):
        if not child.is_dir():
            continue
        if child.name.lower().startswith("pick"):
            continue
        mm = re.search(r"level[_-]?(\d+)", child.name, re.IGNORECASE)
        if not mm:
            continue
        st = int(mm.group(1))
        if not (2 <= st <= 6):  # Only level 2-6
            continue
        print(f"Processing {child.name} (level {st})")
        level_count = 0
        for fp in child.iterdir():
            if fp.is_file() and fp.suffix.lower() in ['.jpg', '.jpeg', '.png']:
                if "pick" in fp.parts:
                    continue
                if fp not in seen_files:
                    seen_files.add(fp)
                    items.append((fp, st))
                    level_count += 1
        print(f"  -> {level_count} files added")
    return items


def apply_ensemble(p_conv: np.ndarray, p_vit: np.ndarray, cfg: Dict) -> Tuple[int, np.ndarray]:
    # Level 2-6ì— í•´ë‹¹í•˜ëŠ” ê°€ì¤‘ì¹˜ë§Œ ì‚¬ìš©
    w_conv = np.array(cfg["weights"]["conv"][1:6], float)  # index 1-5 (level 2-6)
    w_vit = np.array(cfg["weights"]["vit"][1:6], float)
    P_ens = w_conv * p_conv + w_vit * p_vit

    if USE_OVERRIDE:
        strong_c = np.array(cfg["strong"]["conv"][1:6], int)
        strong_v = np.array(cfg["strong"]["vit"][1:6], int)
        tau_c = np.array(cfg["tau"]["conv"][1:6], float)
        tau_v = np.array(cfg["tau"]["vit"][1:6], float)

        for c in range(NUM_CLASSES):
            if strong_c[c] and p_conv[c] >= tau_c[c] and tau_c[c] > 0:
                P_ens[c] = p_conv[c]
            if strong_v[c] and p_vit[c] >= tau_v[c] and tau_v[c] > 0:
                P_ens[c] = p_vit[c]

    s = P_ens.sum()
    if s > 0:
        P_ens = P_ens / s
    pred = int(np.argmax(P_ens)) + CLASS_OFFSET  # level 2-6 indexing
    return pred, P_ens


def next_test_number(base: Path, prefix: str) -> int:
    if not base.exists():
        return 1
    nums = []
    for d in base.iterdir():
        if d.is_dir() and d.name.startswith(prefix):
            s = d.name.replace(prefix, "")
            try:
                nums.append(int(s))
            except:
                pass
    return max(nums) + 1 if nums else 1


def calculate_viewpoint_stats(results: List[Dict]) -> Dict:
    """ë·°í¬ì¸íŠ¸ë³„ í†µê³„ ê³„ì‚°"""
    viewpoint_stats = {}

    for result in results:
        vp = result.get('viewpoint', 'unknown')
        if vp not in viewpoint_stats:
            viewpoint_stats[vp] = {'correct': 0, 'total': 0, 'true_stages': [], 'pred_stages': []}

        viewpoint_stats[vp]['total'] += 1
        viewpoint_stats[vp]['true_stages'].append(result['true_stage'] - CLASS_OFFSET)
        viewpoint_stats[vp]['pred_stages'].append(result['pred_stage'] - CLASS_OFFSET)

        if result['true_stage'] == result['pred_stage']:
            viewpoint_stats[vp]['correct'] += 1

    # ê° ë·°í¬ì¸íŠ¸ë³„ ë©”íŠ¸ë¦­ ê³„ì‚°
    for vp in viewpoint_stats:
        if viewpoint_stats[vp]['total'] > 0:
            y_true = viewpoint_stats[vp]['true_stages']
            y_pred = viewpoint_stats[vp]['pred_stages']

            accuracy = viewpoint_stats[vp]['correct'] / viewpoint_stats[vp]['total']
            precision, recall, f1, _ = precision_recall_fscore_support(
                y_true, y_pred, labels=list(range(NUM_CLASSES)), average='weighted', zero_division=0
            )

            viewpoint_stats[vp].update({
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1': f1
            })

    return viewpoint_stats


def run_test(test_name: str, predict_func, models, cfg: Dict) -> Dict:
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    pc, idx_conv, idx_vit = models['pinecone']

    test_items = collect_test_set(TEST_ROOT)
    if not test_items:
        print(f"[ERROR] í…ŒìŠ¤íŠ¸ì…‹ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {TEST_ROOT}")
        return {}

    results = []
    y_true = []
    y_pred = []
    t0 = time.time()

    for fp, st in test_items:
        try:
            if predict_func == predict_normal:
                p_c, p_v = predict_func(pc, idx_conv, idx_vit, fp, *models['normal'])
            else:  # predict_gem_selective
                p_c, p_v = predict_func(pc, idx_conv, idx_vit, fp, *models['gem'])

            pred, p_ens = apply_ensemble(p_c, p_v, cfg)
            viewpoint = detect_viewpoint_from_filename(fp.name)

            results.append({
                "image_path": str(fp),
                "filename": fp.name,
                "true_stage": st,
                "pred_stage": pred,
                "probs": p_ens.tolist(),
                "viewpoint": viewpoint,
                "is_side": is_side_viewpoint(fp.name)
            })
            y_true.append(st-CLASS_OFFSET)
            y_pred.append(pred-CLASS_OFFSET)
        except Exception as e:
            print(f"[skip test] {fp}: {e}")

    dt = time.time()-t0
    print(f"{test_name} inference done on {len(y_true)} images in {dt:.1f}s")

    if not y_true:
        return {
            'test_name': test_name,
            'results': [],
            'y_true': [],
            'y_pred': [],
            'accuracy': 0.0,
            'precision': 0.0,
            'recall': 0.0,
            'f1': 0.0,
            'viewpoint_stats': {},
            'test_time': dt
        }

    acc = accuracy_score(y_true, y_pred)
    precision, recall, f1, support = precision_recall_fscore_support(
        y_true, y_pred, labels=list(range(NUM_CLASSES)), average='weighted', zero_division=0)

    viewpoint_stats = calculate_viewpoint_stats(results)

    return {
        'test_name': test_name,
        'results': results,
        'y_true': y_true,
        'y_pred': y_pred,
        'accuracy': acc,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'viewpoint_stats': viewpoint_stats,
        'test_time': dt
    }


def main():
    # ë¡œë“œ
    load_dotenv(ENV_PATH)
    pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
    idx_conv = pc.Index(INDEX_CONV)
    idx_vit = pc.Index(INDEX_VIT)

    device = "cpu"

    # ì¼ë°˜ ëª¨ë¸ë“¤
    vit_normal, conv_normal, _ = load_models(device, use_gem=False)
    tf_v, tf_c = tf_vit(), tf_conv()

    # GeM ëª¨ë¸ë“¤
    vit_gem, conv_gem, gem_layer = load_models(device, use_gem=True)

    models = {
        'pinecone': (pc, idx_conv, idx_vit),
        'normal': (vit_normal, conv_normal, tf_v, tf_c),
        'gem': (vit_gem, conv_gem, tf_v, tf_c, gem_layer)
    }

    # ë¡œê·¸ ë””ë ‰í† ë¦¬ êµ¬ì„±
    prefix = "side_comparison_test"
    test_no = next_test_number(LOG_BASE_PATH, prefix)
    folder_name = f"{prefix}{test_no}"
    log_dir = LOG_BASE_PATH / folder_name
    ensure_dir(log_dir)

    # ê¸°ì¡´ ì €ì¥ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
    weight_config_path = Path(r"C:\Users\301\Desktop\main_project\backend\hair_classification\result_log\tester\weight\weight1(ensemble_per_class1_vit_s_16)\ensemble_config.json")

    if weight_config_path.exists():
        print(f"ê¸°ì¡´ ê°€ì¤‘ì¹˜ ë¡œë“œ: {weight_config_path}")
        with open(weight_config_path, "r", encoding="utf-8") as f:
            saved_config = json.load(f)
        cfg = saved_config["config"]
    else:
        print(f"[ERROR] ê°€ì¤‘ì¹˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {weight_config_path}")
        return

    print("="*80)
    print("ì‚¬ì´ë“œ ë·°í¬ì¸íŠ¸ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("="*80)

    # í…ŒìŠ¤íŠ¸ 1: ì¼ë°˜ ì•™ìƒë¸”
    print("\n[Test 1] ì¼ë°˜ ì•™ìƒë¸” í…ŒìŠ¤íŠ¸...")
    normal_results = run_test("Normal Ensemble", predict_normal, models, cfg)

    # í…ŒìŠ¤íŠ¸ 2: ì„ íƒì  GeM ì•™ìƒë¸”
    print("\n[Test 2] ì„ íƒì  GeM ì•™ìƒë¸” í…ŒìŠ¤íŠ¸...")
    gem_results = run_test("Selective GeM Ensemble", predict_gem_selective, models, cfg)

    # ê²°ê³¼ ë¹„êµ ë° ë¦¬í¬íŠ¸ ìƒì„±
    generate_comparison_report(normal_results, gem_results, log_dir, test_no, cfg)

    print(f"\nSaved logs under: {log_dir}")


def generate_comparison_report(normal_results: Dict, gem_results: Dict, log_dir: Path, test_no: int, cfg: Dict):
    """ë¹„êµ ë¦¬í¬íŠ¸ ìƒì„±"""

    # ë¦¬í¬íŠ¸ íŒŒì¼ ì‘ì„±
    with open(log_dir/"comparison_report.txt", "w", encoding="utf-8") as f:
        f.write("="*80+"\n")
        f.write(f"ì‚¬ì´ë“œ ë·°í¬ì¸íŠ¸ ë¹„êµ í…ŒìŠ¤íŠ¸ - Test #{test_no}\n")
        f.write("="*80+"\n")
        f.write(f"í…ŒìŠ¤íŠ¸ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {TEST_ROOT}\n")
        f.write(f"ëŒ€ìƒ ë ˆë²¨: Level 2-6 (ì´ {NUM_CLASSES}ê°œ í´ë˜ìŠ¤)\n")
        f.write(f"ì¸ë±ìŠ¤: ConvNeXt='{INDEX_CONV}', ViT='{INDEX_VIT}'\n")
        f.write(f"íŒŒë¼ë¯¸í„°: top_k={TOP_K}, Tconv={T_CONV}, Tvit={T_VIT}, override={USE_OVERRIDE}\n\n")

        # Test 1 ê²°ê³¼
        f.write("="*60+"\n")
        f.write("TEST 1: ì¼ë°˜ ì•™ìƒë¸” (Global Average Pooling)\n")
        f.write("="*60+"\n")
        f.write("ğŸ“Š ì „ì²´ ê²°ê³¼\n")
        f.write("-"*40+"\n")
        f.write(f"ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {len(normal_results['y_true'])}\n")
        f.write(f"ì •í™•ë„ (Accuracy): {normal_results['accuracy']:.3f}\n")
        f.write(f"ì •ë°€ë„ (Precision): {normal_results['precision']:.3f}\n")
        f.write(f"ì¬í˜„ìœ¨ (Recall): {normal_results['recall']:.3f}\n")
        f.write(f"F1-Score: {normal_results['f1']:.3f}\n")
        f.write(f"ì²˜ë¦¬ ì‹œê°„: {normal_results['test_time']:.1f}s\n\n")

        # ë·°í¬ì¸íŠ¸ë³„ í†µê³„ (ì¼ë°˜)
        f.write("ğŸ“ ë·°í¬ì¸íŠ¸ë³„ í†µê³„ (ì¼ë°˜ ì•™ìƒë¸”)\n")
        f.write("-"*40+"\n")
        for vp, stats in normal_results['viewpoint_stats'].items():
            if stats['total'] > 0:
                f.write(f"{vp}: {stats['correct']}/{stats['total']} ({stats['accuracy']:.3f})\n")
        f.write("\n")

        # Test 2 ê²°ê³¼
        f.write("="*60+"\n")
        f.write("TEST 2: ì„ íƒì  GeM ì•™ìƒë¸” (ì‚¬ì´ë“œ ë·°ë§Œ GeM Pooling)\n")
        f.write("="*60+"\n")
        f.write("ğŸ“Š ì „ì²´ ê²°ê³¼\n")
        f.write("-"*40+"\n")
        f.write(f"ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {len(gem_results['y_true'])}\n")
        f.write(f"ì •í™•ë„ (Accuracy): {gem_results['accuracy']:.3f}\n")
        f.write(f"ì •ë°€ë„ (Precision): {gem_results['precision']:.3f}\n")
        f.write(f"ì¬í˜„ìœ¨ (Recall): {gem_results['recall']:.3f}\n")
        f.write(f"F1-Score: {gem_results['f1']:.3f}\n")
        f.write(f"ì²˜ë¦¬ ì‹œê°„: {gem_results['test_time']:.1f}s\n\n")

        # ë·°í¬ì¸íŠ¸ë³„ í†µê³„ (GeM)
        f.write("ğŸ“ ë·°í¬ì¸íŠ¸ë³„ í†µê³„ (GeM ì•™ìƒë¸”)\n")
        f.write("-"*40+"\n")
        for vp, stats in gem_results['viewpoint_stats'].items():
            if stats['total'] > 0:
                f.write(f"{vp}: {stats['correct']}/{stats['total']} ({stats['accuracy']:.3f})\n")
        f.write("\n")

        # ë¹„êµ ë¶„ì„
        f.write("="*60+"\n")
        f.write("ì„±ëŠ¥ ë¹„êµ ë¶„ì„\n")
        f.write("="*60+"\n")

        acc_diff = gem_results['accuracy'] - normal_results['accuracy']
        f1_diff = gem_results['f1'] - normal_results['f1']

        f.write(f"ì •í™•ë„ ë³€í™”: {normal_results['accuracy']:.3f} â†’ {gem_results['accuracy']:.3f} ({acc_diff:+.3f})\n")
        f.write(f"F1-Score ë³€í™”: {normal_results['f1']:.3f} â†’ {gem_results['f1']:.3f} ({f1_diff:+.3f})\n\n")

        # ì‚¬ì´ë“œ ë·°í¬ì¸íŠ¸ë³„ ìƒì„¸ ë¹„êµ
        f.write("ğŸ¯ ì‚¬ì´ë“œ ë·°í¬ì¸íŠ¸ë³„ ìƒì„¸ ë¹„êµ\n")
        f.write("-"*40+"\n")

        side_viewpoints = ['left', 'right']
        for vp in side_viewpoints:
            if vp in normal_results['viewpoint_stats'] and vp in gem_results['viewpoint_stats']:
                normal_stats = normal_results['viewpoint_stats'][vp]
                gem_stats = gem_results['viewpoint_stats'][vp]

                if normal_stats['total'] > 0 and gem_stats['total'] > 0:
                    acc_diff_vp = gem_stats['accuracy'] - normal_stats['accuracy']
                    f1_diff_vp = gem_stats['f1'] - normal_stats['f1']

                    f.write(f"{vp.upper()} ë·°í¬ì¸íŠ¸:\n")
                    f.write(f"  ì •í™•ë„: {normal_stats['accuracy']:.3f} â†’ {gem_stats['accuracy']:.3f} ({acc_diff_vp:+.3f})\n")
                    f.write(f"  F1-Score: {normal_stats['f1']:.3f} â†’ {gem_stats['f1']:.3f} ({f1_diff_vp:+.3f})\n")
                    f.write(f"  í…ŒìŠ¤íŠ¸ ìˆ˜: {normal_stats['total']}ê°œ\n\n")

        # ê²°ë¡ 
        f.write("ğŸ” ê²°ë¡  ë° ë¶„ì„\n")
        f.write("-"*40+"\n")

        if f1_diff > 0.01:
            f.write("âœ… GeM Poolingì´ ì‚¬ì´ë“œ ë·°í¬ì¸íŠ¸ì—ì„œ ì„±ëŠ¥ í–¥ìƒì„ ë³´ì˜€ìŠµë‹ˆë‹¤.\n")
            f.write("ì´ìœ : GeM poolingì´ Left/Right ë·°ì˜ ê³µê°„ì  íŠ¹ì„±ì„ ë” ì˜ í¬ì°©í•˜ì—¬\n")
            f.write("      ëª¨ë°œ ì†ì‹¤ íŒ¨í„´ì˜ ë¯¸ì„¸í•œ ì°¨ì´ë¥¼ êµ¬ë¶„í•˜ëŠ” ë° ë„ì›€ì„ ì¤€ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\n\n")
        elif f1_diff < -0.01:
            f.write("âŒ ì¼ë°˜ ì•™ìƒë¸”ì´ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.\n")
            f.write("ì´ìœ : ì‚¬ì´ë“œ ë·°í¬ì¸íŠ¸ì—ì„œë„ Global Average Poolingì´ ì¶©ë¶„íˆ íš¨ê³¼ì ì´ë©°,\n")
            f.write("      GeM poolingì˜ ë³µì¡ì„±ì´ ì˜¤íˆë ¤ ì„±ëŠ¥ ì €í•˜ë¥¼ ì¼ìœ¼í‚¨ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\n\n")
        else:
            f.write("â‰ˆ ë‘ ë°©ë²• ê°„ ì„±ëŠ¥ ì°¨ì´ê°€ ë¯¸ë¯¸í•©ë‹ˆë‹¤.\n")
            f.write("ì´ìœ : í˜„ì¬ ë°ì´í„°ì…‹ì—ì„œëŠ” í’€ë§ ë°©ë²•ì˜ ì„ íƒì´ í¬ê²Œ ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•Šìœ¼ë©°,\n")
            f.write("      ë‹¤ë¥¸ ìš”ì†Œë“¤(ì•™ìƒë¸” ê°€ì¤‘ì¹˜, ë°ì´í„° í’ˆì§ˆ ë“±)ì´ ë” ì¤‘ìš”í•œ ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤.\n\n")

        # ê°€ì¤‘ì¹˜ ì •ë³´
        f.write("âš–ï¸ ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ì„¤ì •\n")
        f.write("-"*40+"\n")
        f.write("Per-class weights (ConvNeXt/ViT):\n")
        for c in range(len(cfg['weights']['conv'])):
            level = c + 1
            if 2 <= level <= 6:  # Only show level 2-6
                f.write(f"  ë ˆë²¨ {level}: {cfg['weights']['conv'][c]:.3f} / {cfg['weights']['vit'][c]:.3f}\n")

    # Confusion Matrix ìƒì„±
    plt.rcParams['font.family'] = ['DejaVu Sans', 'sans-serif']
    plt.rcParams['axes.unicode_minus'] = False

    # ì¼ë°˜ ì•™ìƒë¸” Confusion Matrix
    cm_normal = confusion_matrix(normal_results['y_true'], normal_results['y_pred'], labels=list(range(NUM_CLASSES)))
    plt.figure(figsize=(12,5))

    plt.subplot(1,2,1)
    labels = [f"Level {i+CLASS_OFFSET}" for i in range(NUM_CLASSES)]
    sns.heatmap(cm_normal, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
    plt.title(f'Normal Ensemble\nAccuracy: {normal_results["accuracy"]:.3f}')
    plt.ylabel('True Level')
    plt.xlabel('Predicted Level')

    # GeM ì•™ìƒë¸” Confusion Matrix
    cm_gem = confusion_matrix(gem_results['y_true'], gem_results['y_pred'], labels=list(range(NUM_CLASSES)))
    plt.subplot(1,2,2)
    sns.heatmap(cm_gem, annot=True, fmt='d', cmap='Greens', xticklabels=labels, yticklabels=labels)
    plt.title(f'Selective GeM Ensemble\nAccuracy: {gem_results["accuracy"]:.3f}')
    plt.ylabel('True Level')
    plt.xlabel('Predicted Level')

    plt.suptitle(f'Side Viewpoint Comparison - Test #{test_no}', fontsize=14)
    plt.tight_layout()
    plt.savefig(log_dir/"comparison_confusion_matrix.png", dpi=300, bbox_inches='tight')
    plt.close()

    # ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸
    plt.figure(figsize=(10,6))
    metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
    normal_vals = [normal_results['accuracy'], normal_results['precision'], normal_results['recall'], normal_results['f1']]
    gem_vals = [gem_results['accuracy'], gem_results['precision'], gem_results['recall'], gem_results['f1']]

    x = np.arange(len(metrics))
    width = 0.35

    bars1 = plt.bar(x - width/2, normal_vals, width, label='Normal Ensemble', color='skyblue', alpha=0.8)
    bars2 = plt.bar(x + width/2, gem_vals, width, label='GeM Ensemble', color='lightgreen', alpha=0.8)

    plt.ylim(0,1)
    for i, (b1, b2, v1, v2) in enumerate(zip(bars1, bars2, normal_vals, gem_vals)):
        plt.text(b1.get_x()+b1.get_width()/2, v1+0.01, f"{v1:.3f}", ha='center', va='bottom', fontsize=9)
        plt.text(b2.get_x()+b2.get_width()/2, v2+0.01, f"{v2:.3f}", ha='center', va='bottom', fontsize=9)

    plt.xlabel('Metrics')
    plt.ylabel('Score')
    plt.title(f'Side Viewpoint Comparison - Test #{test_no}')
    plt.xticks(x, metrics)
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(log_dir/"comparison_performance.png", dpi=300, bbox_inches='tight')
    plt.close()

    # CSV íŒŒì¼ ì €ì¥
    import pandas as pd
    pd.DataFrame(normal_results['results']).to_csv(log_dir/"normal_results.csv", index=False, encoding="utf-8-sig")
    pd.DataFrame(gem_results['results']).to_csv(log_dir/"gem_results.csv", index=False, encoding="utf-8-sig")

    # ì„¤ì • íŒŒì¼ ì €ì¥
    cfg_out = log_dir / "test_config.json"
    with open(cfg_out, "w", encoding="utf-8") as f:
        json.dump({
            "test_type": "side_viewpoint_comparison",
            "normal_results_summary": {
                "accuracy": normal_results['accuracy'],
                "f1": normal_results['f1'],
                "test_time": normal_results['test_time']
            },
            "gem_results_summary": {
                "accuracy": gem_results['accuracy'],
                "f1": gem_results['f1'],
                "test_time": gem_results['test_time']
            },
            "config": cfg,
        }, f, ensure_ascii=False, indent=2)


if __name__ == "__main__":
    main()