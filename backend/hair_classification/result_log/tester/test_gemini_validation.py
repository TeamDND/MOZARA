#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Gemini ë°ì´í„°ì…‹ ê²€ì¦ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- ë¹ ë¥¸ API ì²˜ë¦¬ (ì§€ì—°ì‹œê°„ ìµœì†Œí™”)
- 2+ ë ˆë²¨ ì°¨ì´ ì´ë¯¸ì§€ ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±
- ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì´ë¯¸ì§€ íŠ¹ì§• ë¶„ì„
"""

import os
import io
import json
import time
import base64
import asyncio
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from sklearn.metrics import (
    confusion_matrix, classification_report,
    accuracy_score, precision_recall_fscore_support
)
import aiohttp


def get_next_test_number(base_log_path: Path, prefix: str = "gemini_validation") -> int:
    if not base_log_path.exists():
        return 1
    existing = [d for d in base_log_path.iterdir() if d.is_dir() and d.name.startswith(prefix)]
    if not existing:
        return 1
    nums = []
    for d in existing:
        try:
            nums.append(int(d.name.replace(prefix, '')))
        except:
            pass
    return max(nums) + 1 if nums else 1


class GeminiValidationTester:
    def __init__(self, test_data_path: str, base_log_path: str, api_base_url: str = "http://localhost:8080"):
        self.test_data_path = Path(test_data_path)
        self.base_log_path = Path(base_log_path)
        self.test_number = get_next_test_number(self.base_log_path, "gemini_validation")
        self.result_log_path = self.base_log_path / f"gemini_validation{self.test_number}"
        self.api_base_url = api_base_url.rstrip('/')
        self.api_endpoint = f"{self.api_base_url}/api/ai/gemini-check/analyze"
        self.login_endpoint = f"{self.api_base_url}/api/login"
        self.test_results: List[Dict] = []
        self.jwt_token = None
        self.result_log_path.mkdir(parents=True, exist_ok=True)

        print(f"Gemini ê²€ì¦ í…ŒìŠ¤íŠ¸ ë²ˆí˜¸: {self.test_number}")
        print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ: {self.test_data_path}")
        print(f"ê²°ê³¼ ë¡œê·¸ ê²½ë¡œ: {self.result_log_path}")
        print(f"API ì—”ë“œí¬ì¸íŠ¸: {self.api_endpoint}")

    def load_test_data(self, samples_per_level: int = 20) -> Dict[int, List[Path]]:
        """ê° ë ˆë²¨ë‹¹ ì§€ì •ëœ ê°œìˆ˜ë§Œí¼ ìƒ˜í”Œë§"""
        test_data: Dict[int, List[Path]] = {}

        for level in range(2, 8):
            level_path = self.test_data_path / f"level_{level}" / f"LEVEL_{level}"
            if not level_path.exists():
                print(f"ê²½ê³ : ë ˆë²¨ {level} í´ë” ì—†ìŒ: {level_path}")
                continue

            images: List[Path] = []
            for ext in ['.jpg', '.jpeg', '.png', '.bmp', '.JPG', '.JPEG', '.PNG', '.BMP']:
                images.extend(list(level_path.glob(f"*{ext}")))
            images = sorted(list(set(images)))

            # ìƒ˜í”Œë§
            if len(images) > samples_per_level:
                import random
                random.seed(42)
                images = random.sample(images, samples_per_level)

            test_data[level] = images
            print(f"ë ˆë²¨ {level}: {len(images)}ê°œ ì´ë¯¸ì§€ (ì „ì²´ ì¤‘ ìƒ˜í”Œë§)")

        total = sum(len(v) for v in test_data.values())
        print(f"ì´ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {total}ê°œ")
        return test_data

    def map_gemini_to_backend_level(self, gemini_stage: int) -> int:
        """Gemini ë‹¨ê³„(0~3) â†’ ë°±ì—”ë“œ ë ˆë²¨(2~7) ë§¤í•‘"""
        mapping = {0: 2, 1: 3, 2: 5, 3: 7}
        return mapping.get(int(gemini_stage), int(gemini_stage) + 2)

    async def login_and_get_token(self, session: aiohttp.ClientSession) -> bool:
        """ë¡œê·¸ì¸í•´ì„œ JWT í† í° ë°›ì•„ì˜¤ê¸°"""
        try:
            login_data = {
                "username": "aaaaaa",
                "password": "11111111"
            }

            async with session.post(self.login_endpoint, json=login_data, timeout=30) as resp:
                if resp.status == 200:
                    result = await resp.json()
                    auth_header = resp.headers.get('Authorization', '')
                    if auth_header.startswith('Bearer '):
                        self.jwt_token = auth_header[7:]
                        print(f"JWT í† í° íšë“ ì„±ê³µ")
                        return True
                    else:
                        self.jwt_token = result.get('jwt_token') or result.get('token') or result.get('access_token')
                        if self.jwt_token:
                            print(f"JWT í† í° íšë“ ì„±ê³µ")
                            return True
                        else:
                            print(f"ì‘ë‹µì—ì„œ í† í°ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {result}")
                            return False
                else:
                    text = await resp.text()
                    print(f"ë¡œê·¸ì¸ ì‹¤íŒ¨ (Status: {resp.status}): {text}")
                    return False
        except Exception as e:
            print(f"ë¡œê·¸ì¸ ìš”ì²­ ì‹¤íŒ¨: {e}")
            return False

    async def test_single_image(self, session: aiohttp.ClientSession, image_path: Path, true_level: int) -> Dict:
        """ë‹¨ì¼ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸"""
        try:
            with open(image_path, 'rb') as f:
                image_data = f.read()

            form_data = aiohttp.FormData()
            form_data.add_field('image', image_data, filename=image_path.name, content_type='image/jpeg')

            headers = {}
            if self.jwt_token:
                headers["Authorization"] = f"Bearer {self.jwt_token}"

            t0 = time.time()
            async with session.post(self.api_endpoint, data=form_data, headers=headers, timeout=60) as resp:
                status = resp.status
                text = await resp.text()
                dt = time.time() - t0

                if status == 200:
                    data = json.loads(text)
                    if 'analysis' in data:
                        analysis = data['analysis']
                        stage_raw = int(analysis.get('stage', 0))
                        stage_mapped = self.map_gemini_to_backend_level(stage_raw)

                        return {
                            'success': True,
                            'filename': image_path.name,
                            'image_path': str(image_path),
                            'true_level': true_level,
                            'predicted_stage': stage_mapped,
                            'gemini_stage_raw': stage_raw,
                            'gemini_title': analysis.get('title', ''),
                            'gemini_description': analysis.get('description', ''),
                            'analysis_time': dt,
                            'api_status': status,
                            'level_difference': abs(true_level - stage_mapped)
                        }
                    else:
                        stage_raw = int(data.get('stage', 0))
                        stage_mapped = self.map_gemini_to_backend_level(stage_raw)

                        return {
                            'success': True,
                            'filename': image_path.name,
                            'image_path': str(image_path),
                            'true_level': true_level,
                            'predicted_stage': stage_mapped,
                            'gemini_stage_raw': stage_raw,
                            'gemini_title': data.get('title', ''),
                            'gemini_description': data.get('description', ''),
                            'analysis_time': dt,
                            'api_status': status,
                            'level_difference': abs(true_level - stage_mapped)
                        }
                else:
                    return {
                        'success': False,
                        'filename': image_path.name,
                        'image_path': str(image_path),
                        'true_level': true_level,
                        'predicted_stage': None,
                        'error': f"HTTP {status}: {text[:200]}",
                        'analysis_time': dt,
                        'api_status': status,
                        'level_difference': None
                    }
        except Exception as e:
            return {
                'success': False,
                'filename': image_path.name,
                'image_path': str(image_path),
                'true_level': true_level,
                'predicted_stage': None,
                'error': str(e),
                'analysis_time': 0,
                'api_status': 'exception',
                'level_difference': None
            }

    async def run_tests(self, samples_per_level: int = 20):
        """í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ë¹ ë¥¸ ì²˜ë¦¬)"""
        print("Gemini ê²€ì¦ í…ŒìŠ¤íŠ¸ ì‹œì‘ (ë¹ ë¥¸ ì²˜ë¦¬)")
        test_data = self.load_test_data(samples_per_level)
        if not test_data:
            print("í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        async with aiohttp.ClientSession() as session:
            print("ë¡œê·¸ì¸ ì‹œë„ ì¤‘...")
            if not await self.login_and_get_token(session):
                print("ë¡œê·¸ì¸ ì‹¤íŒ¨. í…ŒìŠ¤íŠ¸ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                return

            count = 0
            total = sum(len(v) for v in test_data.values())

            for level, images in test_data.items():
                print(f"\në ˆë²¨ {level} í…ŒìŠ¤íŠ¸ ì§„í–‰ ({len(images)}ì¥)")
                for i, image_path in enumerate(images):
                    count += 1
                    print(f"  [{count}/{total}] {i+1}/{len(images)}: {image_path.name}")
                    result = await self.test_single_image(session, image_path, level)
                    self.test_results.append(result)

                    if not result['success']:
                        print(f"    ì‹¤íŒ¨: {result.get('error')}")
                    else:
                        diff = result['level_difference']
                        print(f"    ì˜ˆì¸¡: {result['predicted_stage']} (ì°¨ì´: {diff}) - {result['gemini_title']}")

                    # ë¹ ë¥¸ ì²˜ë¦¬: 0.5ì´ˆ ëŒ€ê¸°
                    await asyncio.sleep(0.5)

        print(f"\nì´ {len(self.test_results)}ì¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")

    def calculate_metrics(self) -> Dict:
        """ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°"""
        print("\nì„±ëŠ¥ ì§€í‘œ ê³„ì‚° ì¤‘...")
        successful = [r for r in self.test_results if r['success'] and r.get('predicted_stage') is not None]

        if not successful:
            print("ì„±ê³µ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {}

        y_true = [r['true_level'] for r in successful]
        y_pred = [r['predicted_stage'] for r in successful]

        acc = accuracy_score(y_true, y_pred)
        prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=0)
        cm = confusion_matrix(y_true, y_pred, labels=[2,3,4,5,6,7])
        report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)
        avg_time = np.mean([r['analysis_time'] for r in successful])

        return {
            'total_tests': len(self.test_results),
            'successful_tests': len(successful),
            'failed_tests': len(self.test_results) - len(successful),
            'success_rate': len(successful) / len(self.test_results) if self.test_results else 0,
            'accuracy': acc,
            'precision': prec,
            'recall': rec,
            'f1_score': f1,
            'confusion_matrix': cm.tolist(),
            'class_report': report,
            'unique_labels': sorted(list(set(y_true + y_pred))),
            'avg_analysis_time': avg_time
        }

    def generate_validation_report(self) -> Dict:
        """2+ ë ˆë²¨ ì°¨ì´ ì´ë¯¸ì§€ ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\nê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")

        successful = [r for r in self.test_results if r['success'] and r.get('predicted_stage') is not None]

        # 2+ ë ˆë²¨ ì°¨ì´ ì´ë¯¸ì§€ í•„í„°ë§
        problematic_images = []
        for result in successful:
            diff = result.get('level_difference', 0)
            if diff >= 2:
                # ì´ë¯¸ì§€ íŠ¹ì§• ë¶„ì„ (íŒŒì¼ëª… ê¸°ë°˜)
                filename = result['filename'].lower()
                suspected_features = []

                # íŒŒì¼ëª…ì—ì„œ íŠ¹ì§• ì¶”ì¶œ
                if 'front' in filename:
                    suspected_features.append("ì •ë©´ê°ë„")
                if 'top' in filename:
                    suspected_features.append("ìƒë‹¨ê°ë„")
                if 'side' in filename or 'left' in filename or 'right' in filename:
                    suspected_features.append("ì¸¡ë©´ê°ë„")
                if 'back' in filename:
                    suspected_features.append("í›„ë©´ê°ë„")
                if 'male' in filename:
                    suspected_features.append("ë‚¨ì„±")
                if 'female' in filename:
                    suspected_features.append("ì—¬ì„±")

                # ë ˆë²¨ ì°¨ì´ íŒ¨í„´ ë¶„ì„
                if result['true_level'] < result['predicted_stage']:
                    error_pattern = f"ê³¼ëŒ€í‰ê°€ ({result['true_level']} â†’ {result['predicted_stage']})"
                else:
                    error_pattern = f"ê³¼ì†Œí‰ê°€ ({result['true_level']} â†’ {result['predicted_stage']})"

                problematic_images.append({
                    'filename': result['filename'],
                    'image_path': result['image_path'],
                    'true_level': result['true_level'],
                    'predicted_level': result['predicted_stage'],
                    'level_difference': diff,
                    'error_pattern': error_pattern,
                    'gemini_title': result.get('gemini_title', ''),
                    'gemini_description': result.get('gemini_description', ''),
                    'suspected_features': suspected_features,
                    'analysis_time': result['analysis_time']
                })

        # ì—ëŸ¬ íŒ¨í„´ í†µê³„
        error_patterns = {}
        feature_patterns = {}

        for img in problematic_images:
            pattern = img['error_pattern']
            error_patterns[pattern] = error_patterns.get(pattern, 0) + 1

            for feature in img['suspected_features']:
                feature_patterns[feature] = feature_patterns.get(feature, 0) + 1

        validation_report = {
            'total_problematic': len(problematic_images),
            'problematic_rate': len(problematic_images) / len(successful) if successful else 0,
            'problematic_images': problematic_images,
            'error_patterns': error_patterns,
            'feature_patterns': feature_patterns,
            'validation_guidelines': self.get_validation_guidelines()
        }

        return validation_report

    def get_validation_guidelines(self) -> Dict:
        """ë°ì´í„°ì…‹ ê²€ì¦ ê°€ì´ë“œë¼ì¸"""
        return {
            "ìˆ˜ë™_ê²€ì¦_ì²´í¬ë¦¬ìŠ¤íŠ¸": [
                "1. í—¤ì–´ë¼ì¸ íŒ¨í„´: Mì íƒˆëª¨ ì •ë„ê°€ ë ˆë²¨ê³¼ ì¼ì¹˜í•˜ëŠ”ê°€?",
                "2. ì •ìˆ˜ë¦¬ ìƒíƒœ: ì •ìˆ˜ë¦¬ íƒˆëª¨ ì§„í–‰ë„ê°€ ì ì ˆí•œê°€?",
                "3. ì „ì²´ ëª¨ë°œ ë°€ë„: ì „ë°˜ì ì¸ ëª¨ë°œ ì–‘ì´ ë ˆë²¨ì— ë§ëŠ”ê°€?",
                "4. ì´ë¯¸ì§€ í’ˆì§ˆ: ì¡°ëª…, ê°ë„, í•´ìƒë„ê°€ ë¶„ì„ì— ì í•©í•œê°€?",
                "5. ì„±ë³„ ì¼ì¹˜: ë‚¨ì„±/ì—¬ì„± ë¶„ë¥˜ê°€ ì •í™•í•œê°€?",
                "6. ë·°í¬ì¸íŠ¸ ì¼ì¹˜: ì´¬ì˜ ê°ë„ê°€ ë¼ë²¨ê³¼ ì¼ì¹˜í•˜ëŠ”ê°€?"
            ],
            "ì˜ì‹¬_ì¼€ì´ìŠ¤_ìš°ì„ ìˆœìœ„": [
                "1. 3ë ˆë²¨ ì´ìƒ ì°¨ì´ë‚˜ëŠ” ì´ë¯¸ì§€ (ìµœìš°ì„ )",
                "2. ê³¼ëŒ€í‰ê°€ëœ ì´ë¯¸ì§€ (ì‹¤ì œë³´ë‹¤ ë†’ê²Œ í‰ê°€)",
                "3. ì •ë©´ê°ë„ì—ì„œ ì˜¤ë¶„ë¥˜ëœ ì´ë¯¸ì§€",
                "4. ìƒë‹¨ê°ë„ì—ì„œ ì˜¤ë¶„ë¥˜ëœ ì´ë¯¸ì§€"
            ],
            "ì¬ë¼ë²¨ë§_ê¸°ì¤€": [
                "1. ì „ë¬¸ê°€ 2ëª… ì´ìƒì˜ í•©ì˜",
                "2. ë…¸ìš°ë“œ ë¶„ë¥˜ ê¸°ì¤€í‘œ ì¬ì°¸ì¡°",
                "3. ìœ ì‚¬í•œ ì¼€ì´ìŠ¤ë“¤ê³¼ì˜ ì¼ê´€ì„± í™•ì¸",
                "4. ì´ë¯¸ì§€ í’ˆì§ˆì´ ë¶„ì„ì— ë¶€ì í•©í•œ ê²½ìš° ì œì™¸ ê³ ë ¤"
            ],
            "ë°ì´í„°ì…‹_ê°œì„ _ì œì•ˆ": [
                "1. ê°ë„ë³„ ê· ë“±í•œ ë¶„í¬ í™•ë³´",
                "2. ê²½ê³„ ì¼€ì´ìŠ¤(ë ˆë²¨ ê°„ ì• ë§¤í•œ ê²½ìš°) ì¶”ê°€ ìˆ˜ì§‘",
                "3. ì´ë¯¸ì§€ í’ˆì§ˆ í‘œì¤€í™”",
                "4. ì „ë¬¸ê°€ ê²€ì¦ ë‹¨ê³„ ì¶”ê°€"
            ]
        }

    def create_visualizations(self, metrics: Dict, validation_report: Dict):
        """ì‹œê°í™” ìƒì„±"""
        print("\nì‹œê°í™” ìƒì„± ì¤‘...")

        # 1. Confusion Matrix
        plt.figure(figsize=(10, 8))
        cm = np.array(metrics['confusion_matrix'])
        labels = [2,3,4,5,6,7]
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
        plt.xlabel('Predicted Level')
        plt.ylabel('True Level')
        plt.title(f'Gemini Validation Test{self.test_number} - Confusion Matrix')
        confusion_path = self.result_log_path / 'confusion_matrix.png'
        plt.tight_layout()
        plt.savefig(confusion_path, dpi=300, bbox_inches='tight')
        plt.close()

        # 2. ì„±ëŠ¥ ì§€í‘œ
        plt.figure(figsize=(10, 6))
        metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
        metrics_values = [metrics['accuracy'], metrics['precision'], metrics['recall'], metrics['f1_score']]
        bars = plt.bar(metrics_names, metrics_values, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])
        plt.ylim(0, 1)
        plt.title(f'Gemini Validation Test{self.test_number} - Performance Metrics')
        plt.ylabel('Score')
        for bar, value in zip(bars, metrics_values):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                    f'{value:.3f}', ha='center', va='bottom')
        plt.tight_layout()
        metrics_path = self.result_log_path / 'performance_metrics.png'
        plt.savefig(metrics_path, dpi=300, bbox_inches='tight')
        plt.close()

        # 3. ì—ëŸ¬ íŒ¨í„´ ë¶„ì„
        if validation_report['error_patterns']:
            plt.figure(figsize=(12, 6))
            patterns = list(validation_report['error_patterns'].keys())
            counts = list(validation_report['error_patterns'].values())
            plt.bar(patterns, counts, color='coral')
            plt.title(f'Error Patterns in Problematic Images (Test{self.test_number})')
            plt.ylabel('Count')
            plt.xticks(rotation=45)
            plt.tight_layout()
            error_path = self.result_log_path / 'error_patterns.png'
            plt.savefig(error_path, dpi=300, bbox_inches='tight')
            plt.close()

        print(f"ì‹œê°í™” ì €ì¥ ì™„ë£Œ: {self.result_log_path}")

    def save_results(self, metrics: Dict, validation_report: Dict):
        """ê²°ê³¼ ì €ì¥"""
        print("\nê²°ê³¼ ì €ì¥ ì¤‘...")

        # ë ˆë²¨ë³„ í†µê³„
        level_counts = {}
        for r in self.test_results:
            level = r['true_level']
            level_counts[level] = level_counts.get(level, 0) + 1

        # ìƒì„¸ ê²°ê³¼ JSON
        detailed_results = {
            'test_info': {
                'test_type': 'gemini_validation',
                'test_number': self.test_number,
                'timestamp': datetime.now().isoformat(),
                'test_data_path': str(self.test_data_path),
                'api_endpoint': self.api_endpoint,
                'total_images': len(self.test_results),
                'level_counts': level_counts
            },
            'metrics': metrics,
            'validation_report': validation_report,
            'detailed_results': self.test_results
        }

        json_path = self.result_log_path / 'results.json'
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(detailed_results, f, ensure_ascii=False, indent=2)

        # ê²€ì¦ ë¦¬í¬íŠ¸ (í…ìŠ¤íŠ¸)
        report_path = self.result_log_path / 'validation_report.txt'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write(f"Gemini ë°ì´í„°ì…‹ ê²€ì¦ ë¦¬í¬íŠ¸ (Test{self.test_number})\n")
            f.write("=" * 80 + "\n")
            f.write(f"í…ŒìŠ¤íŠ¸ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {self.test_data_path}\n")
            f.write(f"API ì—”ë“œí¬ì¸íŠ¸: {self.api_endpoint}\n\n")

            f.write("ğŸ“Š ì „ì²´ ì„±ëŠ¥\n")
            f.write("-" * 40 + "\n")
            f.write(f"ì´ í…ŒìŠ¤íŠ¸: {metrics['total_tests']}\n")
            f.write(f"ì„±ê³µ: {metrics['successful_tests']}\n")
            f.write(f"ì‹¤íŒ¨: {metrics['failed_tests']}\n")
            f.write(f"ì •í™•ë„: {metrics['accuracy']:.3f}\n")
            f.write(f"F1-Score: {metrics['f1_score']:.3f}\n")
            f.write(f"í‰ê·  ì²˜ë¦¬ì‹œê°„: {metrics['avg_analysis_time']:.3f}ì´ˆ\n\n")

            f.write("ğŸš¨ ê²€ì¦ í•„ìš” ì´ë¯¸ì§€\n")
            f.write("-" * 40 + "\n")
            f.write(f"ë¬¸ì œ ì´ë¯¸ì§€ ìˆ˜: {validation_report['total_problematic']}\n")
            f.write(f"ë¬¸ì œ ë¹„ìœ¨: {validation_report['problematic_rate']:.1%}\n\n")

            f.write("ğŸ“‹ ê²€ì¦ ëŒ€ìƒ ìƒì„¸ ëª©ë¡\n")
            f.write("-" * 40 + "\n")
            for img in validation_report['problematic_images']:
                f.write(f"íŒŒì¼ëª…: {img['filename']}\n")
                f.write(f"  ì‹¤ì œ: Level {img['true_level']} â†’ ì˜ˆì¸¡: Level {img['predicted_level']}\n")
                f.write(f"  ì°¨ì´: {img['level_difference']}ë ˆë²¨\n")
                f.write(f"  íŒ¨í„´: {img['error_pattern']}\n")
                f.write(f"  ì œë¯¸ë‚˜ì´ ì œëª©: {img['gemini_title']}\n")
                f.write(f"  ì œë¯¸ë‚˜ì´ ì„¤ëª…: {img['gemini_description'][:100]}...\n")
                f.write(f"  ì˜ì‹¬ íŠ¹ì§•: {', '.join(img['suspected_features'])}\n")
                f.write(f"  ê²½ë¡œ: {img['image_path']}\n\n")

            f.write("ğŸ“ˆ ì—ëŸ¬ íŒ¨í„´ ë¶„ì„\n")
            f.write("-" * 40 + "\n")
            for pattern, count in validation_report['error_patterns'].items():
                f.write(f"{pattern}: {count}ê±´\n")
            f.write("\n")

            f.write("ğŸ” ë°ì´í„°ì…‹ ê²€ì¦ ê°€ì´ë“œë¼ì¸\n")
            f.write("-" * 40 + "\n")
            guidelines = validation_report['validation_guidelines']

            f.write("ìˆ˜ë™ ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸:\n")
            for item in guidelines['ìˆ˜ë™_ê²€ì¦_ì²´í¬ë¦¬ìŠ¤íŠ¸']:
                f.write(f"  {item}\n")
            f.write("\n")

            f.write("ì˜ì‹¬ ì¼€ì´ìŠ¤ ìš°ì„ ìˆœìœ„:\n")
            for item in guidelines['ì˜ì‹¬_ì¼€ì´ìŠ¤_ìš°ì„ ìˆœìœ„']:
                f.write(f"  {item}\n")
            f.write("\n")

            f.write("ì¬ë¼ë²¨ë§ ê¸°ì¤€:\n")
            for item in guidelines['ì¬ë¼ë²¨ë§_ê¸°ì¤€']:
                f.write(f"  {item}\n")
            f.write("\n")

            f.write("ë°ì´í„°ì…‹ ê°œì„  ì œì•ˆ:\n")
            for item in guidelines['ë°ì´í„°ì…‹_ê°œì„ _ì œì•ˆ']:
                f.write(f"  {item}\n")

        # CSV ì €ì¥
        df = pd.DataFrame(self.test_results)
        csv_path = self.result_log_path / 'results.csv'
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')

        # ë¬¸ì œ ì´ë¯¸ì§€ë§Œ ë³„ë„ CSV
        if validation_report['problematic_images']:
            problem_df = pd.DataFrame(validation_report['problematic_images'])
            problem_csv_path = self.result_log_path / 'problematic_images.csv'
            problem_df.to_csv(problem_csv_path, index=False, encoding='utf-8-sig')
            print(f"ë¬¸ì œ ì´ë¯¸ì§€ ëª©ë¡: {problem_csv_path}")

        print(f"ìƒì„¸ ê²°ê³¼: {json_path}")
        print(f"ê²€ì¦ ë¦¬í¬íŠ¸: {report_path}")
        print(f"ê²°ê³¼ CSV: {csv_path}")


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("Gemini ë°ì´í„°ì…‹ ê²€ì¦ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 80)
    print("ëª©ì : 2+ ë ˆë²¨ ì°¨ì´ ì´ë¯¸ì§€ ê²€ì¦ ë° ë°ì´í„°ì…‹ í’ˆì§ˆ ë¶„ì„")
    print("ì²˜ë¦¬: ë¹ ë¥¸ API í˜¸ì¶œ (0.5ì´ˆ ê°„ê²©)")
    print("=" * 80)

    # ê²½ë¡œ ì„¤ì •
    test_data_path = "C:/Users/301/Desktop/test_data_set/test"
    base_log_path = "C:/Users/301/Desktop/main_project/backend/hair_classification/result_log/log"

    # í…ŒìŠ¤í„° ì´ˆê¸°í™”
    tester = GeminiValidationTester(test_data_path, base_log_path)

    try:
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ê° ë ˆë²¨ë‹¹ 20ê°œì”©)
        await tester.run_tests(samples_per_level=20)

        # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
        metrics = tester.calculate_metrics()

        if metrics:
            # ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±
            validation_report = tester.generate_validation_report()

            # ì‹œê°í™” ìƒì„±
            tester.create_visualizations(metrics, validation_report)

            # ê²°ê³¼ ì €ì¥
            tester.save_results(metrics, validation_report)

            print("\n" + "=" * 80)
            print(f"Gemini ê²€ì¦ í…ŒìŠ¤íŠ¸ ì™„ë£Œ! (Test{tester.test_number})")
            print("=" * 80)
            print(f"ì •í™•ë„: {metrics['accuracy']:.1%}")
            print(f"ë¬¸ì œ ì´ë¯¸ì§€: {validation_report['total_problematic']}ê°œ ({validation_report['problematic_rate']:.1%})")
            print(f"í‰ê·  ì²˜ë¦¬ì‹œê°„: {metrics['avg_analysis_time']:.3f}ì´ˆ")
            print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {tester.result_log_path}")
            print("\nğŸš¨ ìˆ˜ë™ ê²€ì¦ í•„ìš” ì´ë¯¸ì§€ë“¤ì„ problematic_images.csvì—ì„œ í™•ì¸í•˜ì„¸ìš”!")
        else:
            print("\nì„±ëŠ¥ ì§€í‘œ ê³„ì‚° ì‹¤íŒ¨")

    except KeyboardInterrupt:
        print("\n\nì‚¬ìš©ìì— ì˜í•´ í…ŒìŠ¤íŠ¸ê°€ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\ní…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    asyncio.run(main())