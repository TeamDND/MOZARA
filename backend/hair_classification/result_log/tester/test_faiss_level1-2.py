#!/usr/bin/env python3
r"""
FAISS ê¸°ë°˜ RAG ëª¨ë¸ ë ˆë²¨ 1-2 êµ¬ë¶„ í…ŒìŠ¤íŠ¸
Hair Loss RAG Analyzer v2.0 - ConvNext + CLIP + FAISS ì‚¬ìš©

í…ŒìŠ¤íŠ¸ ëŒ€ìƒ: C:\Users\301\Desktop\test_data_set\test (level 1, 2)
FAISS ì¸ë±ìŠ¤: hair_loss_rag_analyzer_v0 ê¸°ì¡´ ì¸ë±ìŠ¤ ì‚¬ìš©

ë¡œê·¸ ì¶œë ¥: result_log/log/faiss_level1-2_test{N}/
"""

import os
import sys
import json
import time
import numpy as np
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Any

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report
import pandas as pd

# FAISS RAG ì‹œìŠ¤í…œ ê²½ë¡œ ì¶”ê°€
RAG_PROJECT_PATH = Path(r"C:\Users\301\Desktop\main_project\backend\hair_classification\hair_loss_rag_analyzer_v0\backend")
sys.path.append(str(RAG_PROJECT_PATH))

from improved_faiss_manager import ImprovedFAISSManager
from app.services.image_processor import ImageProcessor

# ---------- ê²½ë¡œ/ì„¤ì • ----------
THIS_DIR = Path(__file__).parent
LOG_BASE_PATH = Path(r"C:\Users\301\Desktop\main_project\backend\hair_classification\result_log\log")

TEST_ROOT = Path(r"C:\Users\301\Desktop\test_data_set\test")  # level 1, 2

# í…ŒìŠ¤íŠ¸ ì„¤ì •
TARGET_LEVELS = [1, 2]  # ë ˆë²¨ 1, 2ë§Œ í…ŒìŠ¤íŠ¸
TOP_K_VALUES = [10, 20, 30, 50]  # ë‹¤ì–‘í•œ k ê°’ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
EXCLUDE_LEVEL_1_TEST = True  # ë ˆë²¨ 1 ì œì™¸ í…ŒìŠ¤íŠ¸ë„ ì‹¤í–‰


def ensure_dir(p: Path):
    """ë””ë ‰í† ë¦¬ ìƒì„±"""
    p.mkdir(parents=True, exist_ok=True)


def collect_test_set(root: Path, target_levels: List[int]) -> List[Tuple[Path, int]]:
    """í…ŒìŠ¤íŠ¸ì…‹ ìˆ˜ì§‘ (ë ˆë²¨ 1, 2ë§Œ)"""
    items = []
    seen_files = set()

    if not root.exists():
        print(f"[ERROR] í…ŒìŠ¤íŠ¸ ë£¨íŠ¸ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {root}")
        return items

    for level in target_levels:
        level_dir = root / str(level)
        if not level_dir.exists():
            print(f"[WARNING] ë ˆë²¨ {level} ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {level_dir}")
            continue

        print(f"Processing level {level} directory: {level_dir}")
        level_count = 0

        for fp in level_dir.iterdir():
            if fp.is_file() and fp.suffix.lower() in ['.jpg', '.jpeg', '.png']:
                if fp not in seen_files:
                    seen_files.add(fp)
                    items.append((fp, level))
                    level_count += 1

        print(f"  -> Level {level}: {level_count} files added")

    return items


def analyze_faiss_prediction(faiss_manager: ImprovedFAISSManager,
                           image_processor: ImageProcessor,
                           image_path: Path,
                           top_k: int = 20,
                           exclude_levels: List[int] = None) -> Dict[str, Any]:
    """FAISS ê¸°ë°˜ ì˜ˆì¸¡ ë¶„ì„"""
    try:
        # ì´ë¯¸ì§€ ì„ë² ë”© ì¶”ì¶œ
        embedding = image_processor.extract_clip_embedding_from_path(str(image_path))

        if embedding is None:
            raise ValueError("ì´ë¯¸ì§€ ì„ë² ë”© ì¶”ì¶œ ì‹¤íŒ¨")

        # FAISSì—ì„œ ìœ ì‚¬ ì´ë¯¸ì§€ ê²€ìƒ‰ ë° ì˜ˆì¸¡
        if exclude_levels:
            result = faiss_manager.predict_hair_loss_stage_improved(
                embedding,
                top_k=top_k,
                exclude_levels=exclude_levels,
                use_distance_weighting=True
            )
        else:
            result = faiss_manager.predict_hair_loss_stage_improved(
                embedding,
                top_k=top_k,
                use_distance_weighting=True
            )

        predicted_stage = result.get('predicted_stage', 0)
        confidence = result.get('confidence', 0.0)
        similar_images = result.get('similar_images', [])
        stage_scores = result.get('stage_scores', {})

        # None ê°’ ì²˜ë¦¬
        if predicted_stage is None:
            predicted_stage = 0

        return {
            'predicted_stage': predicted_stage,
            'confidence': confidence,
            'similar_images': similar_images,
            'stage_scores': stage_scores,
            'success': True
        }

    except Exception as e:
        print(f"[ERROR] ì˜ˆì¸¡ ì‹¤íŒ¨ {image_path}: {e}")
        return {
            'predicted_stage': 0,
            'confidence': 0.0,
            'similar_images': [],
            'stage_scores': {},
            'success': False,
            'error': str(e)
        }


def calculate_detailed_metrics(y_true: List[int], y_pred: List[int],
                             target_levels: List[int]) -> Dict[str, Any]:
    """ìƒì„¸ ë©”íŠ¸ë¦­ ê³„ì‚°"""
    # ì „ì²´ ì •í™•ë„
    accuracy = accuracy_score(y_true, y_pred)

    # ë ˆë²¨ë³„ ë©”íŠ¸ë¦­
    precision, recall, f1, support = precision_recall_fscore_support(
        y_true, y_pred, labels=target_levels, average=None, zero_division=0
    )

    # ê°€ì¤‘ í‰ê·  ë©”íŠ¸ë¦­
    precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(
        y_true, y_pred, labels=target_levels, average='weighted', zero_division=0
    )

    # í˜¼ë™ í–‰ë ¬
    cm = confusion_matrix(y_true, y_pred, labels=target_levels)

    # ë ˆë²¨ë³„ ìƒì„¸ ê²°ê³¼
    level_metrics = {}
    for i, level in enumerate(target_levels):
        level_metrics[level] = {
            'precision': precision[i],
            'recall': recall[i],
            'f1': f1[i],
            'support': support[i]
        }

    # ë¶„ë¥˜ ë¦¬í¬íŠ¸
    cls_report = classification_report(
        y_true, y_pred, labels=target_levels, zero_division=0, output_dict=True
    )

    return {
        'accuracy': accuracy,
        'precision_weighted': precision_weighted,
        'recall_weighted': recall_weighted,
        'f1_weighted': f1_weighted,
        'confusion_matrix': cm,
        'level_metrics': level_metrics,
        'classification_report': cls_report
    }


def analyze_misclassifications(results: List[Dict]) -> Dict[str, Any]:
    """ì˜¤ë¶„ë¥˜ ë¶„ì„"""
    misclassified = []
    level_1_as_2 = 0  # ë ˆë²¨ 1ì„ ë ˆë²¨ 2ë¡œ ì˜ëª» ì˜ˆì¸¡
    level_2_as_1 = 0  # ë ˆë²¨ 2ë¥¼ ë ˆë²¨ 1ë¡œ ì˜ëª» ì˜ˆì¸¡

    for result in results:
        true_level = result['true_stage']
        pred_level = result['pred_stage']

        if true_level != pred_level:
            misclassified.append({
                'filename': result['filename'],
                'true_level': true_level,
                'pred_level': pred_level,
                'confidence': result['confidence'],
                'stage_scores': result.get('stage_scores', {})
            })

            if true_level == 1 and pred_level == 2:
                level_1_as_2 += 1
            elif true_level == 2 and pred_level == 1:
                level_2_as_1 += 1

    return {
        'misclassified_cases': misclassified,
        'total_misclassified': len(misclassified),
        'level_1_as_2': level_1_as_2,
        'level_2_as_1': level_2_as_1
    }


def next_test_number(base: Path, prefix: str) -> int:
    """ë‹¤ìŒ í…ŒìŠ¤íŠ¸ ë²ˆí˜¸ ê³„ì‚°"""
    if not base.exists():
        return 1

    nums = []
    for d in base.iterdir():
        if d.is_dir() and d.name.startswith(prefix):
            s = d.name.replace(prefix, "")
            try:
                nums.append(int(s))
            except:
                pass

    return max(nums) + 1 if nums else 1


def save_confusion_matrix(cm: np.ndarray, labels: List[str],
                         title: str, save_path: Path):
    """í˜¼ë™ í–‰ë ¬ ì‹œê°í™” ë° ì €ì¥"""
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=labels, yticklabels=labels)
    plt.title(title)
    plt.ylabel('True Level')
    plt.xlabel('Predicted Level')
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()


def save_performance_chart(metrics: Dict, title: str, save_path: Path):
    """ì„±ëŠ¥ ì°¨íŠ¸ ì €ì¥"""
    plt.figure(figsize=(10, 6))
    names = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
    vals = [
        metrics['accuracy'],
        metrics['precision_weighted'],
        metrics['recall_weighted'],
        metrics['f1_weighted']
    ]

    bars = plt.bar(names, vals, color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728'])
    plt.ylim(0, 1)

    for b, v in zip(bars, vals):
        plt.text(b.get_x() + b.get_width()/2, v + 0.01,
                f"{v:.3f}", ha='center', va='bottom')

    plt.title(title)
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("="*80)
    print("FAISS ê¸°ë°˜ RAG ëª¨ë¸ ë ˆë²¨ 1-2 êµ¬ë¶„ í…ŒìŠ¤íŠ¸")
    print("="*80)

    # ë¡œê·¸ ë””ë ‰í† ë¦¬ êµ¬ì„±
    prefix = "faiss_level1-2_test"
    test_no = next_test_number(LOG_BASE_PATH, prefix)
    folder_name = f"{prefix}{test_no}"
    log_dir = LOG_BASE_PATH / folder_name
    ensure_dir(log_dir)

    print(f"í…ŒìŠ¤íŠ¸ ë²ˆí˜¸: {test_no}")
    print(f"ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {log_dir}")

    # FAISS ë§¤ë‹ˆì € ë° ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
    try:
        faiss_manager = ImprovedFAISSManager()
        image_processor = ImageProcessor()
        print("FAISS ë§¤ë‹ˆì € ë° ì´ë¯¸ì§€ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì™„ë£Œ")
    except Exception as e:
        print(f"[ERROR] ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return

    # í…ŒìŠ¤íŠ¸ì…‹ ìˆ˜ì§‘
    test_items = collect_test_set(TEST_ROOT, TARGET_LEVELS)
    if not test_items:
        print(f"[ERROR] í…ŒìŠ¤íŠ¸ì…‹ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤: {TEST_ROOT}")
        return

    print(f"ì´ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {len(test_items)}ê°œ")

    # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥ìš©
    all_results = {}

    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ë¶€í„° ì‹œì‘ (ì²˜ìŒ 5ê°œ ì´ë¯¸ì§€ë§Œ)
    print("\n" + "="*50)
    print("1. ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ (ì²˜ìŒ 5ê°œ ì´ë¯¸ì§€)")
    print("="*50)

    simple_test_items = test_items[:5]
    print(f"ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {len(simple_test_items)}ê°œ")

    for top_k in [10]:  # í•˜ë‚˜ì˜ k ê°’ìœ¼ë¡œë§Œ í…ŒìŠ¤íŠ¸
        print(f"\n--- TOP_K = {top_k} ---")
        results = []
        y_true = []
        y_pred = []

        start_time = time.time()
        print(f"TOP_K {top_k} í…ŒìŠ¤íŠ¸ ì‹œì‘...")

        for i, (fp, true_level) in enumerate(simple_test_items):
            prediction = analyze_faiss_prediction(
                faiss_manager, image_processor, fp, top_k=top_k
            )

            if prediction['success']:
                pred_level = prediction['predicted_stage']
                confidence = prediction['confidence']

                # ìœ íš¨í•œ ì˜ˆì¸¡ê°’ë§Œ ì‚¬ìš© (1 ë˜ëŠ” 2)
                if pred_level in TARGET_LEVELS:
                    results.append({
                        'filename': fp.name,
                        'true_stage': true_level,
                        'pred_stage': pred_level,
                        'confidence': confidence,
                        'stage_scores': prediction['stage_scores']
                    })

                    y_true.append(true_level)
                    y_pred.append(pred_level)
                else:
                    print(f"  ìœ íš¨í•˜ì§€ ì•Šì€ ì˜ˆì¸¡: {fp.name} -> {pred_level}")

                if (i + 1) % 5 == 0:
                    print(f"  ì²˜ë¦¬ ì™„ë£Œ: {i + 1}/{len(simple_test_items)}")
            else:
                print(f"  ì‹¤íŒ¨: {fp.name} - {prediction.get('error', 'Unknown error')}")

        elapsed_time = time.time() - start_time

        print(f"ì‹¤ì œ ë ˆë²¨: {y_true}")
        print(f"ì˜ˆì¸¡ ë ˆë²¨: {y_pred}")
        print(f"ì˜ˆì¸¡ ë‹¤ì–‘ì„±: {set(y_pred) if y_pred else 'None'}")

        if y_true and len(set(y_pred)) > 1:  # ì˜ˆì¸¡ê°’ì´ ë‹¤ì–‘í•´ì•¼ ë©”íŠ¸ë¦­ ê³„ì‚° ê°€ëŠ¥
            metrics = calculate_detailed_metrics(y_true, y_pred, TARGET_LEVELS)
            misclass_analysis = analyze_misclassifications(results)

            all_results[f'basic_top_k_{top_k}'] = {
                'metrics': metrics,
                'misclassification': misclass_analysis,
                'results': results,
                'elapsed_time': elapsed_time,
                'total_images': len(y_true)
            }

            print(f"ì •í™•ë„: {metrics['accuracy']:.3f}")
            print(f"F1-Score: {metrics['f1_weighted']:.3f}")
            print(f"ë ˆë²¨ 1â†’2 ì˜¤ë¶„ë¥˜: {misclass_analysis['level_1_as_2']}ê°œ")
            print(f"ë ˆë²¨ 2â†’1 ì˜¤ë¶„ë¥˜: {misclass_analysis['level_2_as_1']}ê°œ")
        else:
            print(f"ë©”íŠ¸ë¦­ ê³„ì‚° ë¶ˆê°€ - ì„±ê³µí•œ ì˜ˆì¸¡: {len(y_true)}ê°œ, ì˜ˆì¸¡ ë‹¤ì–‘ì„±: {len(set(y_pred)) if y_pred else 0}")
            if y_pred:
                print(f"ì˜ˆì¸¡ ê²°ê³¼: {set(y_pred)}")

    # ì„±ê³µí•œ ì˜ˆì¸¡ì´ ìˆìœ¼ë©´ ê³„ì† ì§„í–‰, ì—†ìœ¼ë©´ ì¢…ë£Œ
    if not y_true:
        print("ëª¨ë“  ì˜ˆì¸¡ì´ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # 2. ì „ì²´ í…ŒìŠ¤íŠ¸ (ì„±ê³µí•œ ê²½ìš°ì—ë§Œ)
    print("\n" + "="*50)
    print("2. ì „ì²´ í…ŒìŠ¤íŠ¸ (ëª¨ë“  ì´ë¯¸ì§€)")
    print("="*50)

    for top_k in TOP_K_VALUES:
        print(f"\n--- TOP_K = {top_k} ---")
        results = []
        y_true_full = []
        y_pred_full = []

        start_time = time.time()
        print(f"TOP_K {top_k} ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹œì‘...")

        for i, (fp, true_level) in enumerate(test_items):
            prediction = analyze_faiss_prediction(
                faiss_manager, image_processor, fp, top_k=top_k
            )

            if prediction['success']:
                pred_level = prediction['predicted_stage']
                confidence = prediction['confidence']

                results.append({
                    'filename': fp.name,
                    'true_stage': true_level,
                    'pred_stage': pred_level,
                    'confidence': confidence,
                    'stage_scores': prediction['stage_scores']
                })

                y_true_full.append(true_level)
                y_pred_full.append(pred_level)

                if (i + 1) % 10 == 0:
                    print(f"  ì²˜ë¦¬ ì™„ë£Œ: {i + 1}/{len(test_items)}")

        elapsed_time = time.time() - start_time

        if y_true_full and len(set(y_pred_full)) > 1:
            metrics = calculate_detailed_metrics(y_true_full, y_pred_full, TARGET_LEVELS)
            misclass_analysis = analyze_misclassifications(results)

            all_results[f'full_top_k_{top_k}'] = {
                'metrics': metrics,
                'misclassification': misclass_analysis,
                'results': results,
                'elapsed_time': elapsed_time,
                'total_images': len(y_true_full)
            }

            print(f"ì •í™•ë„: {metrics['accuracy']:.3f}")
            print(f"F1-Score: {metrics['f1_weighted']:.3f}")
            print(f"ë ˆë²¨ 1â†’2 ì˜¤ë¶„ë¥˜: {misclass_analysis['level_1_as_2']}ê°œ")
            print(f"ë ˆë²¨ 2â†’1 ì˜¤ë¶„ë¥˜: {misclass_analysis['level_2_as_1']}ê°œ")
        else:
            print(f"ë©”íŠ¸ë¦­ ê³„ì‚° ë¶ˆê°€ - ì„±ê³µí•œ ì˜ˆì¸¡: {len(y_true_full)}ê°œ, ì˜ˆì¸¡ ë‹¤ì–‘ì„±: {len(set(y_pred_full)) if y_pred_full else 0}")

    # 3. ë ˆë²¨ 1 ì œì™¸ í…ŒìŠ¤íŠ¸
    if EXCLUDE_LEVEL_1_TEST:
        print("\n" + "="*50)
        print("2. ë ˆë²¨ 1 ì œì™¸ í…ŒìŠ¤íŠ¸")
        print("="*50)

        for top_k in TOP_K_VALUES:
            print(f"\n--- TOP_K = {top_k} (ë ˆë²¨ 1 ì œì™¸) ---")
            results = []
            y_true = []
            y_pred = []

            start_time = time.time()

            for fp, true_level in test_items:
                prediction = analyze_faiss_prediction(
                    faiss_manager, image_processor, fp,
                    top_k=top_k, exclude_levels=[1]
                )

                if prediction['success']:
                    pred_level = prediction['predicted_stage']
                    confidence = prediction['confidence']

                    results.append({
                        'filename': fp.name,
                        'true_stage': true_level,
                        'pred_stage': pred_level,
                        'confidence': confidence,
                        'stage_scores': prediction['stage_scores']
                    })

                    y_true.append(true_level)
                    y_pred.append(pred_level)

            elapsed_time = time.time() - start_time

            if y_true and len(set(y_pred)) > 1:  # ì˜ˆì¸¡ê°’ì´ ë‹¤ì–‘í•´ì•¼ ë©”íŠ¸ë¦­ ê³„ì‚° ê°€ëŠ¥
                metrics = calculate_detailed_metrics(y_true, y_pred, TARGET_LEVELS)
                misclass_analysis = analyze_misclassifications(results)

                all_results[f'exclude_lv1_top_k_{top_k}'] = {
                    'metrics': metrics,
                    'misclassification': misclass_analysis,
                    'results': results,
                    'elapsed_time': elapsed_time,
                    'total_images': len(y_true)
                }

                print(f"ì •í™•ë„: {metrics['accuracy']:.3f}")
                print(f"F1-Score: {metrics['f1_weighted']:.3f}")
                print(f"ë ˆë²¨ 1â†’2 ì˜¤ë¶„ë¥˜: {misclass_analysis['level_1_as_2']}ê°œ")
                print(f"ë ˆë²¨ 2â†’1 ì˜¤ë¶„ë¥˜: {misclass_analysis['level_2_as_1']}ê°œ")
            else:
                print(f"ë©”íŠ¸ë¦­ ê³„ì‚° ë¶ˆê°€ - ì„±ê³µí•œ ì˜ˆì¸¡: {len(y_true)}ê°œ, ì˜ˆì¸¡ ë‹¤ì–‘ì„±: {len(set(y_pred)) if y_pred else 0}")
                if y_pred:
                    print(f"ì˜ˆì¸¡ ê²°ê³¼: {set(y_pred)}")

    # ê²°ê³¼ ì €ì¥
    print("\n" + "="*50)
    print("ê²°ê³¼ ì €ì¥ ì¤‘...")
    print("="*50)

    # ìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥
    with open(log_dir / "report.txt", "w", encoding="utf-8") as f:
        f.write("="*80 + "\n")
        f.write(f"FAISS ê¸°ë°˜ RAG ëª¨ë¸ ë ˆë²¨ 1-2 êµ¬ë¶„ í…ŒìŠ¤íŠ¸ - Test #{test_no}\n")
        f.write("="*80 + "\n")
        f.write(f"í…ŒìŠ¤íŠ¸ ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {TEST_ROOT}\n")
        f.write(f"ëŒ€ìƒ ë ˆë²¨: Level 1-2\n")
        f.write(f"FAISS ì¸ë±ìŠ¤: hair_loss_rag_analyzer_v0\n")
        f.write(f"ëª¨ë¸: ConvNext + CLIP + FAISS\n\n")

        f.write("ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ì •ë³´\n")
        f.write("-"*40 + "\n")
        level_counts = {}
        for _, level in test_items:
            level_counts[level] = level_counts.get(level, 0) + 1
        for level in sorted(level_counts.keys()):
            f.write(f"ë ˆë²¨ {level}: {level_counts[level]}ê°œ ì´ë¯¸ì§€\n")
        f.write(f"ì´ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {len(test_items)}ê°œ\n\n")

        # ê° ì„¤ì •ë³„ ê²°ê³¼ ìƒì„¸ ê¸°ë¡
        for test_name, test_data in all_results.items():
            f.write(f"ğŸ¯ {test_name} ê²°ê³¼\n")
            f.write("-"*40 + "\n")

            metrics = test_data['metrics']
            misclass = test_data['misclassification']

            f.write(f"ì²˜ë¦¬ ì‹œê°„: {test_data['elapsed_time']:.2f}ì´ˆ\n")
            f.write(f"ì •í™•ë„: {metrics['accuracy']:.3f}\n")
            f.write(f"ì •ë°€ë„: {metrics['precision_weighted']:.3f}\n")
            f.write(f"ì¬í˜„ìœ¨: {metrics['recall_weighted']:.3f}\n")
            f.write(f"F1-Score: {metrics['f1_weighted']:.3f}\n\n")

            f.write("ë ˆë²¨ë³„ ì„±ëŠ¥:\n")
            for level, level_metrics in metrics['level_metrics'].items():
                f.write(f"  ë ˆë²¨ {level}: ì •ë°€ë„={level_metrics['precision']:.3f}, "
                       f"ì¬í˜„ìœ¨={level_metrics['recall']:.3f}, F1={level_metrics['f1']:.3f}\n")

            f.write(f"\nì˜¤ë¶„ë¥˜ ë¶„ì„:\n")
            f.write(f"  ì´ ì˜¤ë¶„ë¥˜: {misclass['total_misclassified']}ê°œ\n")
            f.write(f"  ë ˆë²¨ 1â†’2 ì˜¤ë¶„ë¥˜: {misclass['level_1_as_2']}ê°œ\n")
            f.write(f"  ë ˆë²¨ 2â†’1 ì˜¤ë¶„ë¥˜: {misclass['level_2_as_1']}ê°œ\n\n")

    # ìµœì  ê²°ê³¼ ì°¾ê¸° ë° ì‹œê°í™”
    best_result = None
    best_accuracy = 0
    best_test_name = ""

    for test_name, test_data in all_results.items():
        if test_data['metrics']['accuracy'] > best_accuracy:
            best_accuracy = test_data['metrics']['accuracy']
            best_result = test_data
            best_test_name = test_name

    if best_result:
        print(f"ìµœê³  ì„±ëŠ¥: {best_test_name} (ì •í™•ë„: {best_accuracy:.3f})")

        # ìµœê³  ì„±ëŠ¥ ê²°ê³¼ ì‹œê°í™”
        cm = best_result['metrics']['confusion_matrix']
        labels = [f"Level {level}" for level in TARGET_LEVELS]

        save_confusion_matrix(
            cm, labels,
            f"FAISS RAG Level 1-2 Confusion Matrix\n{best_test_name} (Test #{test_no})",
            log_dir / "confusion_matrix_best.png"
        )

        save_performance_chart(
            best_result['metrics'],
            f"FAISS RAG Level 1-2 Performance\n{best_test_name} (Test #{test_no})",
            log_dir / "performance_best.png"
        )

    # ì „ì²´ ê²°ê³¼ JSON ì €ì¥
    results_json = {}
    for test_name, test_data in all_results.items():
        results_json[test_name] = {
            'metrics': {
                'accuracy': test_data['metrics']['accuracy'],
                'precision': test_data['metrics']['precision_weighted'],
                'recall': test_data['metrics']['recall_weighted'],
                'f1': test_data['metrics']['f1_weighted']
            },
            'misclassification': test_data['misclassification'],
            'elapsed_time': test_data['elapsed_time'],
            'total_images': test_data['total_images']
        }

    with open(log_dir / "results.json", "w", encoding="utf-8") as f:
        json.dump(results_json, f, ensure_ascii=False, indent=2)

    # CSV ì €ì¥ (ìµœê³  ì„±ëŠ¥ ê²°ê³¼)
    if best_result:
        df = pd.DataFrame(best_result['results'])
        df.to_csv(log_dir / "best_results.csv", index=False, encoding="utf-8-sig")

    print(f"\n{'='*80}")
    print(f"FAISS ê¸°ë°˜ RAG ëª¨ë¸ ë ˆë²¨ 1-2 êµ¬ë¶„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ! - Test #{test_no}")
    print(f"{'='*80}")
    print(f"ìµœê³  ì„±ëŠ¥: {best_test_name}")
    print(f"ìµœê³  ì •í™•ë„: {best_accuracy:.3f}")
    print(f"ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {log_dir}")
    print(f"{'='*80}")


if __name__ == "__main__":
    main()