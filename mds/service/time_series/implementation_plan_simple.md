# Time-Series ë…ë¦½ ëª¨ë“ˆ êµ¬í˜„ ê³„íš (ë‹¨ìˆœí™”)

> **ì‘ì„±ì¼**: 2025-10-07
> **ì›ì¹™**: ê¸°ì¡´ Swin ì½”ë“œì™€ ì™„ì „ ë¶„ë¦¬, ìµœì†Œí•œì˜ ì˜ì¡´ì„±

---

## ğŸ“ í´ë” êµ¬ì¡°

```
main_project/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ python/
â”‚   â”‚   â””â”€â”€ services/
â”‚   â”‚       â”œâ”€â”€ swin_hair_classification/    # ê¸°ì¡´ ì½”ë“œ (ìˆ˜ì • ì•ˆ í•¨)
â”‚   â”‚       â”‚   â”œâ”€â”€ models/
â”‚   â”‚       â”‚   â”œâ”€â”€ hair_swin_check.py
â”‚   â”‚       â”‚   â””â”€â”€ ...
â”‚   â”‚       â”‚
â”‚   â”‚       â””â”€â”€ time_series/                 # âœ¨ ì‹ ê·œ í´ë” (ì™„ì „ ë…ë¦½)
â”‚   â”‚           â”œâ”€â”€ __init__.py
â”‚   â”‚           â”œâ”€â”€ density_analyzer.py      # BiSeNet ë°€ë„ ì¸¡ì •
â”‚   â”‚           â”œâ”€â”€ feature_extractor.py     # Swin feature ì¶”ì¶œ
â”‚   â”‚           â”œâ”€â”€ timeseries_comparator.py # ì‹œê³„ì—´ ë¹„êµ
â”‚   â”‚           â””â”€â”€ api.py                   # FastAPI ì—”ë“œí¬ì¸íŠ¸
â”‚   â”‚
â”‚   â””â”€â”€ springboot/
â”‚       â””â”€â”€ src/main/java/.../controller/
â”‚           â””â”€â”€ TimeSeriesController.java    # âœ¨ ì‹ ê·œ ì»¨íŠ¸ë¡¤ëŸ¬
â”‚
â””â”€â”€ frontend/
    â””â”€â”€ src/
        â”œâ”€â”€ pages/hair_dailycare/
        â”‚   â””â”€â”€ DailyCare.tsx                # ê¸°ì¡´ íŒŒì¼ (ìµœì†Œ ìˆ˜ì •)
        â”‚
        â””â”€â”€ components/timeseries/           # âœ¨ ì‹ ê·œ ì»´í¬ë„ŒíŠ¸ í´ë”
            â”œâ”€â”€ TimeSeriesChart.tsx
            â”œâ”€â”€ DensityHeatmap.tsx
            â””â”€â”€ TrendSummary.tsx
```

---

## ğŸ”„ ë°ì´í„° íë¦„ (ë‹¨ìˆœí™”)

### Step 1: ë¶„ì„ ì‹œì ì— ë°ì´í„° ì €ì¥ (ê¸°ì¡´ íë¦„ í™œìš©)

```
ì‚¬ìš©ìê°€ DailyCareì—ì„œ ì‚¬ì§„ ì—…ë¡œë“œ
  â†“
ê¸°ì¡´ Swin API í˜¸ì¶œ (/ai/hair-loss-daily/analyze)
  â†“
ë¶„ì„ ê²°ê³¼ + ì´ë¯¸ì§€ URL â†’ DB ì €ì¥
  âœ… ê¸°ì¡´ ì½”ë“œ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ìˆ˜ì • ì—†ìŒ)
```

### Step 2: ì‹œê³„ì—´ ë¶„ì„ ìš”ì²­ (ì‹ ê·œ)

```
ì‚¬ìš©ìê°€ "ë³€í™” ì¶”ì´ ë³´ê¸°" ë²„íŠ¼ í´ë¦­
  â†“
Frontend â†’ Spring Boot (/api/timeseries/analyze)
  â†“
Spring Boot â†’ DBì—ì„œ ê³¼ê±° ë¶„ì„ ê²°ê³¼ ì¡°íšŒ (ì´ë¯¸ì§€ URL í¬í•¨)
  â†“
Spring Boot â†’ Python Time-Series API í˜¸ì¶œ
  â†“
Python:
  1. ì´ë¯¸ì§€ URLë¡œ S3ì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
  2. BiSeNetìœ¼ë¡œ ë°€ë„ ì¸¡ì •
  3. Swinìœ¼ë¡œ feature ì¶”ì¶œ
  4. ì‹œê³„ì—´ ë¹„êµ ë¶„ì„
  â†“
ê²°ê³¼ ë°˜í™˜ â†’ Frontend ì‹œê°í™”
```

---

## ğŸ¯ í•µì‹¬ ì›ì¹™

### 1. ê¸°ì¡´ Swin ì½”ë“œ ìˆ˜ì • âŒ
- `swin_hair_classification/` í´ë”ëŠ” **ì ˆëŒ€ ìˆ˜ì • ì•ˆ í•¨**
- ëŒ€ì‹  **ëª¨ë¸ë§Œ import**í•´ì„œ ì‚¬ìš©

### 2. DB ìŠ¤í‚¤ë§ˆ ìµœì†Œ ë³€ê²½
- ê¸°ì¡´ `analysis_result` í…Œì´ë¸” í™œìš©
- ì´ë¯¸ ì €ì¥ëœ `imageUrl`, `grade`, `inspectionDate` ì‚¬ìš©
- ì¶”ê°€ í•„ë“œëŠ” **ì„ íƒì ** (ì—†ì–´ë„ ë™ì‘)

### 3. ë…ë¦½ì  ì‹¤í–‰ ê°€ëŠ¥
- time_series ëª¨ë“ˆë§Œìœ¼ë¡œ ë¶„ì„ ê°€ëŠ¥
- ê¸°ì¡´ API ì˜í–¥ ì—†ìŒ

---

## ğŸ“¦ Backend - Python êµ¬í˜„

### í´ë”: `backend/python/services/time_series/`

#### íŒŒì¼ 1: `density_analyzer.py`

```python
"""
BiSeNetì„ í™œìš©í•œ í—¤ì–´ ë°€ë„ ì¸¡ì •
ê¸°ì¡´ ëª¨ë¸ë§Œ import, ì½”ë“œ ìˆ˜ì • ì—†ìŒ
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from swin_hair_classification.models.face_parsing.model import BiSeNet
import torch
import cv2
import numpy as np
from PIL import Image
import io

class DensityAnalyzer:
    def __init__(self, device='cpu'):
        self.device = torch.device(device)

        # ê¸°ì¡´ BiSeNet ëª¨ë¸ ë¡œë“œ (ê¸°ì¡´ ì½”ë“œ ì¬ì‚¬ìš©)
        self.model = BiSeNet(n_classes=19)
        model_path = '../swin_hair_classification/models/face_parsing/res/cp/79999_iter.pth'
        self.model.load_state_dict(torch.load(model_path, map_location=self.device))
        self.model.to(self.device)
        self.model.eval()

    def calculate_density(self, image_bytes: bytes) -> dict:
        """
        ì´ë¯¸ì§€ë¡œë¶€í„° í—¤ì–´ ë°€ë„ ì¸¡ì •

        Returns:
            {
                'hair_density_percentage': float,
                'total_hair_pixels': int,
                'distribution_map': list  # 8x8 ê·¸ë¦¬ë“œ
            }
        """
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
        image_np = np.array(image)
        image_resized = cv2.resize(image_np, (512, 512))

        # í…ì„œ ë³€í™˜
        from torchvision import transforms
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
        ])
        input_tensor = transform(image_resized).unsqueeze(0).to(self.device)

        # BiSeNetìœ¼ë¡œ ë§ˆìŠ¤í¬ ìƒì„±
        with torch.no_grad():
            output = self.model(input_tensor)[0]
            mask = torch.argmax(output, dim=1).squeeze().cpu().numpy()

        # í—¤ì–´ ë§ˆìŠ¤í¬ (í´ë˜ìŠ¤ 17)
        hair_mask = (mask == 17).astype(np.uint8) * 255

        # ë°€ë„ ê³„ì‚°
        total_hair_pixels = int(np.sum(hair_mask > 0))
        total_pixels = hair_mask.shape[0] * hair_mask.shape[1]
        density_percentage = (total_hair_pixels / total_pixels) * 100

        # 8x8 ê·¸ë¦¬ë“œ ë¶„í¬
        grid_size = 8
        cell_h = 512 // grid_size
        cell_w = 512 // grid_size
        distribution_map = []

        for i in range(grid_size):
            row = []
            for j in range(grid_size):
                cell = hair_mask[i*cell_h:(i+1)*cell_h, j*cell_w:(j+1)*cell_w]
                cell_density = np.sum(cell > 0) / (cell_h * cell_w) * 100
                row.append(round(cell_density, 2))
            distribution_map.append(row)

        return {
            'hair_density_percentage': round(density_percentage, 2),
            'total_hair_pixels': total_hair_pixels,
            'distribution_map': distribution_map
        }
```

---

#### íŒŒì¼ 2: `feature_extractor.py`

```python
"""
SwinTransformer feature vector ì¶”ì¶œ
ê¸°ì¡´ ëª¨ë¸ë§Œ import
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from swin_hair_classification.models.swin_hair_classifier import SwinHairClassifier
from swin_hair_classification.models.face_parsing.model import BiSeNet
import torch
import numpy as np
from PIL import Image
import io
import cv2

class FeatureExtractor:
    def __init__(self, device='cpu'):
        self.device = torch.device(device)

        # BiSeNet ë¡œë“œ (ë§ˆìŠ¤í‚¹ìš©)
        self.face_parser = BiSeNet(n_classes=19)
        face_model_path = '../swin_hair_classification/models/face_parsing/res/cp/79999_iter.pth'
        self.face_parser.load_state_dict(torch.load(face_model_path, map_location=self.device))
        self.face_parser.to(self.device)
        self.face_parser.eval()

        # Swin ëª¨ë¸ ë¡œë“œ
        self.swin_model = SwinHairClassifier(num_classes=4)
        swin_model_path = '../swin_hair_classification/models/best_swin_hair_classifier_top.pth'
        checkpoint = torch.load(swin_model_path, map_location=self.device)
        if 'model_state_dict' in checkpoint:
            self.swin_model.load_state_dict(checkpoint['model_state_dict'])
        else:
            self.swin_model.load_state_dict(checkpoint)
        self.swin_model.to(self.device)
        self.swin_model.eval()

    def extract_features(self, image_bytes: bytes) -> dict:
        """
        768ì°¨ì› feature vector ì¶”ì¶œ

        Returns:
            {
                'feature_vector': list,  # 768ì°¨ì›
                'feature_norm': float
            }
        """
        # 1. ë§ˆìŠ¤í¬ ìƒì„±
        image = Image.open(io.BytesIO(image_bytes)).convert('RGB')
        image_np = np.array(image)
        image_resized = cv2.resize(image_np, (512, 512))

        from torchvision import transforms
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))
        ])
        input_tensor = transform(image_resized).unsqueeze(0).to(self.device)

        with torch.no_grad():
            output = self.face_parser(input_tensor)[0]
            mask = torch.argmax(output, dim=1).squeeze().cpu().numpy()

        hair_mask = (mask == 17).astype(np.uint8) * 255

        # 2. ì´ë¯¸ì§€ + ë§ˆìŠ¤í¬ ê²°í•© (6ì±„ë„)
        image_224 = cv2.resize(image_np, (224, 224))
        mask_224 = cv2.resize(hair_mask, (224, 224)) / 255.0

        img_transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

        image_tensor = img_transform(Image.fromarray(image_224))  # [3, 224, 224]
        mask_tensor = torch.from_numpy(mask_224.astype(np.float32)).unsqueeze(0).repeat(3, 1, 1)  # [3, 224, 224]

        combined = torch.cat([image_tensor, mask_tensor], dim=0).unsqueeze(0).to(self.device)  # [1, 6, 224, 224]

        # 3. Feature ì¶”ì¶œ
        with torch.no_grad():
            features = self.swin_model.forward_features(combined)  # [1, 768]
            features_np = features.cpu().numpy()[0]

        return {
            'feature_vector': features_np.tolist(),
            'feature_norm': float(np.linalg.norm(features_np))
        }
```

---

#### íŒŒì¼ 3: `timeseries_comparator.py`

```python
"""
ì‹œê³„ì—´ ë¹„êµ ë¶„ì„
"""

import numpy as np
from scipy.spatial.distance import cosine

class TimeSeriesComparator:

    def compare_density(self, current: dict, past_list: list) -> dict:
        """
        ë°€ë„ ë³€í™” ë¶„ì„

        Args:
            current: {'hair_density_percentage': 48.5, ...}
            past_list: [{'hair_density_percentage': 50.2, ...}, ...]

        Returns:
            {
                'trend': 'improving' | 'stable' | 'declining',
                'change_percentage': -3.4,
                'weekly_change': -1.7,
                'monthly_change': -3.4
            }
        """
        if not past_list:
            return {'trend': 'insufficient_data'}

        current_density = current['hair_density_percentage']

        # ì£¼ê°„ ë³€í™” (ê°€ì¥ ìµœê·¼ê³¼ ë¹„êµ)
        weekly_change = current_density - past_list[-1]['hair_density_percentage']

        # ì›”ê°„ ë³€í™” (4ì£¼ ì „ê³¼ ë¹„êµ)
        monthly_change = current_density - past_list[-4]['hair_density_percentage'] if len(past_list) >= 4 else weekly_change

        # íŠ¸ë Œë“œ (ì„ í˜• íšŒê·€)
        densities = [p['hair_density_percentage'] for p in past_list] + [current_density]
        x = np.arange(len(densities))
        slope = np.polyfit(x, densities, 1)[0]

        trend = 'improving' if slope > 0.5 else ('declining' if slope < -0.5 else 'stable')

        return {
            'trend': trend,
            'change_percentage': round(weekly_change, 2),
            'weekly_change': round(weekly_change, 2),
            'monthly_change': round(monthly_change, 2)
        }

    def compare_distribution(self, current_map: list, past_maps: list) -> dict:
        """
        ë¶„í¬ ë³€í™” ë¶„ì„ (8x8 íˆíŠ¸ë§µ)
        """
        if not past_maps:
            return {'similarity': 1.0}

        current_flat = np.array(current_map).flatten()
        past_flat = np.array(past_maps[-1]).flatten()

        similarity = 1 - cosine(current_flat, past_flat)

        return {
            'similarity': round(similarity, 3),
            'change_detected': similarity < 0.9
        }

    def compare_features(self, current_feature: list, past_features: list) -> dict:
        """
        Feature vector ìœ ì‚¬ë„
        """
        if not past_features:
            return {'similarity': 1.0}

        current_np = np.array(current_feature)
        past_np = np.array(past_features[-1])

        similarity = 1 - cosine(current_np, past_np)
        distance = np.linalg.norm(current_np - past_np)

        return {
            'similarity': round(similarity, 3),
            'distance': round(distance, 2),
            'change_score': min(round(distance * 10, 1), 100)  # 0-100 ì ìˆ˜
        }
```

---

#### íŒŒì¼ 4: `api.py`

```python
"""
FastAPI ì—”ë“œí¬ì¸íŠ¸ (ë…ë¦½ ì‹¤í–‰ ê°€ëŠ¥)
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Optional
import requests

from .density_analyzer import DensityAnalyzer
from .feature_extractor import FeatureExtractor
from .timeseries_comparator import TimeSeriesComparator

app = FastAPI()

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
density_analyzer = DensityAnalyzer()
feature_extractor = FeatureExtractor()
comparator = TimeSeriesComparator()


class ImageAnalysisRequest(BaseModel):
    image_url: str  # S3 URL


class TimeSeriesRequest(BaseModel):
    current_image_url: str
    past_image_urls: List[str]


@app.post("/timeseries/analyze-single")
async def analyze_single_image(request: ImageAnalysisRequest):
    """
    ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„ (ë°€ë„ + feature)
    """
    try:
        # S3ì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        response = requests.get(request.image_url)
        image_bytes = response.content

        # ë°€ë„ ì¸¡ì •
        density_result = density_analyzer.calculate_density(image_bytes)

        # Feature ì¶”ì¶œ
        feature_result = feature_extractor.extract_features(image_bytes)

        return {
            "success": True,
            "density": density_result,
            "features": feature_result
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/timeseries/compare")
async def compare_timeseries(request: TimeSeriesRequest):
    """
    ì‹œê³„ì—´ ë¹„êµ ë¶„ì„
    """
    try:
        # í˜„ì¬ ì´ë¯¸ì§€ ë¶„ì„
        current_response = requests.get(request.current_image_url)
        current_bytes = current_response.content

        current_density = density_analyzer.calculate_density(current_bytes)
        current_features = feature_extractor.extract_features(current_bytes)

        # ê³¼ê±° ì´ë¯¸ì§€ë“¤ ë¶„ì„
        past_densities = []
        past_features = []
        past_maps = []

        for url in request.past_image_urls:
            past_response = requests.get(url)
            past_bytes = past_response.content

            past_density = density_analyzer.calculate_density(past_bytes)
            past_feature = feature_extractor.extract_features(past_bytes)

            past_densities.append(past_density)
            past_features.append(past_feature['feature_vector'])
            past_maps.append(past_density['distribution_map'])

        # ì‹œê³„ì—´ ë¹„êµ
        density_comparison = comparator.compare_density(current_density, past_densities)
        distribution_comparison = comparator.compare_distribution(
            current_density['distribution_map'],
            past_maps
        )
        feature_comparison = comparator.compare_features(
            current_features['feature_vector'],
            past_features
        )

        return {
            "success": True,
            "current": {
                "density": current_density,
                "features": current_features
            },
            "comparison": {
                "density": density_comparison,
                "distribution": distribution_comparison,
                "features": feature_comparison
            }
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

---

## ğŸ“¦ Backend - Spring Boot êµ¬í˜„

### íŒŒì¼: `TimeSeriesController.java`

```java
package com.example.springboot.controller;

import com.example.springboot.data.dao.AnalysisResultDAO;
import com.example.springboot.data.entity.AnalysisResultEntity;
import lombok.RequiredArgsConstructor;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.*;
import org.springframework.web.client.RestTemplate;

import java.time.LocalDate;
import java.util.List;
import java.util.Map;
import java.util.stream.Collectors;

@RestController
@RequestMapping("/api/timeseries")
@RequiredArgsConstructor
public class TimeSeriesController {

    private final AnalysisResultDAO analysisResultDAO;
    private final RestTemplate restTemplate = new RestTemplate();

    private static final String PYTHON_TIMESERIES_API = "http://localhost:8000/timeseries";

    /**
     * ì‹œê³„ì—´ ë¶„ì„ ì‹¤í–‰
     */
    @GetMapping("/analyze/{userId}")
    public ResponseEntity<Map<String, Object>> analyzeTimeSeries(@PathVariable Integer userId) {

        // 1. DBì—ì„œ ìµœê·¼ 3ê°œì›” ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
        LocalDate endDate = LocalDate.now();
        LocalDate startDate = endDate.minusMonths(3);

        List<AnalysisResultEntity> results = analysisResultDAO.findByUserIdAndAnalysisTypeAndDateRange(
                userId, "swin_dual_model_llm_enhanced", startDate, endDate);

        if (results.size() < 2) {
            return ResponseEntity.ok(Map.of(
                    "success", false,
                    "message", "ë¹„êµí•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ìµœì†Œ 2ê°œ ì´ìƒì˜ ë¶„ì„ ê²°ê³¼ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            ));
        }

        // 2. ì´ë¯¸ì§€ URL ì¶”ì¶œ
        String currentImageUrl = results.get(0).getImageUrl();
        List<String> pastImageUrls = results.stream()
                .skip(1)
                .map(AnalysisResultEntity::getImageUrl)
                .collect(Collectors.toList());

        // 3. Python API í˜¸ì¶œ
        Map<String, Object> requestBody = Map.of(
                "current_image_url", currentImageUrl,
                "past_image_urls", pastImageUrls
        );

        try {
            Map<String, Object> pythonResponse = restTemplate.postForObject(
                    PYTHON_TIMESERIES_API + "/compare",
                    requestBody,
                    Map.class
            );

            return ResponseEntity.ok(pythonResponse);
        } catch (Exception e) {
            return ResponseEntity.ok(Map.of(
                    "success", false,
                    "error", e.getMessage()
            ));
        }
    }

    /**
     * ì‹œê³„ì—´ ë°ì´í„° ì¡°íšŒ (ì‹œê°í™”ìš©)
     */
    @GetMapping("/data/{userId}")
    public ResponseEntity<Map<String, Object>> getTimeSeriesData(@PathVariable Integer userId) {

        LocalDate endDate = LocalDate.now();
        LocalDate startDate = endDate.minusMonths(3);

        List<AnalysisResultEntity> results = analysisResultDAO.findByUserIdAndAnalysisTypeAndDateRange(
                userId, "swin_dual_model_llm_enhanced", startDate, endDate);

        List<Map<String, Object>> data = results.stream()
                .map(r -> Map.of(
                        "date", r.getInspectionDate().toString(),
                        "grade", r.getGrade() != null ? r.getGrade() : 0,
                        "imageUrl", r.getImageUrl() != null ? r.getImageUrl() : ""
                ))
                .collect(Collectors.toList());

        return ResponseEntity.ok(Map.of(
                "success", true,
                "data", data
        ));
    }
}
```

---

## ğŸ¨ Frontend êµ¬í˜„

### í´ë”: `frontend/src/components/timeseries/`

#### íŒŒì¼ 1: `TimeSeriesChart.tsx`

```typescript
import React from 'react';
import { LineChart, Line, XAxis, YAxis, CartesianGrid, Tooltip, ResponsiveContainer } from 'recharts';

interface TimeSeriesChartProps {
  data: Array<{ date: string; grade: number }>;
}

export const TimeSeriesChart: React.FC<TimeSeriesChartProps> = ({ data }) => {
  return (
    <ResponsiveContainer width="100%" height={200}>
      <LineChart data={data}>
        <CartesianGrid strokeDasharray="3 3" />
        <XAxis dataKey="date" />
        <YAxis />
        <Tooltip />
        <Line type="monotone" dataKey="grade" stroke="#1f0101" strokeWidth={2} />
      </LineChart>
    </ResponsiveContainer>
  );
};
```

---

#### íŒŒì¼ 2: `DensityHeatmap.tsx`

```typescript
import React from 'react';

interface DensityHeatmapProps {
  distributionMap: number[][];  // 8x8 ê·¸ë¦¬ë“œ
}

export const DensityHeatmap: React.FC<DensityHeatmapProps> = ({ distributionMap }) => {
  return (
    <div className="grid grid-cols-8 gap-1">
      {distributionMap.map((row, i) =>
        row.map((cell, j) => (
          <div
            key={`${i}-${j}`}
            className="aspect-square rounded"
            style={{
              backgroundColor: `rgba(31, 1, 1, ${cell / 100})`,
            }}
            title={`ë°€ë„: ${cell.toFixed(1)}%`}
          />
        ))
      )}
    </div>
  );
};
```

---

#### íŒŒì¼ 3: `TrendSummary.tsx`

```typescript
import React from 'react';
import { Card, CardContent } from '../../components/ui/card';

interface TrendSummaryProps {
  trend: 'improving' | 'stable' | 'declining';
  weeklyChange: number;
  monthlyChange: number;
}

export const TrendSummary: React.FC<TrendSummaryProps> = ({ trend, weeklyChange, monthlyChange }) => {
  const getTrendEmoji = () => {
    if (trend === 'improving') return 'ğŸŸ¢';
    if (trend === 'declining') return 'ğŸ”´';
    return 'ğŸŸ¡';
  };

  return (
    <div className="grid grid-cols-3 gap-2">
      <Card>
        <CardContent className="p-3 text-center">
          <p className="text-xs text-gray-600">ì£¼ê°„ ë³€í™”</p>
          <p className={`text-lg font-bold ${weeklyChange > 0 ? 'text-green-600' : 'text-red-600'}`}>
            {weeklyChange > 0 ? '+' : ''}{weeklyChange.toFixed(1)}%
          </p>
        </CardContent>
      </Card>

      <Card>
        <CardContent className="p-3 text-center">
          <p className="text-xs text-gray-600">ì›”ê°„ ë³€í™”</p>
          <p className={`text-lg font-bold ${monthlyChange > 0 ? 'text-green-600' : 'text-red-600'}`}>
            {monthlyChange > 0 ? '+' : ''}{monthlyChange.toFixed(1)}%
          </p>
        </CardContent>
      </Card>

      <Card>
        <CardContent className="p-3 text-center">
          <p className="text-xs text-gray-600">íŠ¸ë Œë“œ</p>
          <p className="text-lg font-bold">
            {getTrendEmoji()} {trend === 'improving' ? 'ê°œì„ ' : trend === 'declining' ? 'ì•…í™”' : 'ìœ ì§€'}
          </p>
        </CardContent>
      </Card>
    </div>
  );
};
```

---

### DailyCare.tsxì— í†µí•©

```typescript
// DailyCare.tsx ìµœì†Œ ìˆ˜ì •

import { TimeSeriesChart } from '../../components/timeseries/TimeSeriesChart';
import { DensityHeatmap } from '../../components/timeseries/DensityHeatmap';
import { TrendSummary } from '../../components/timeseries/TrendSummary';

// ì¶”ê°€ state
const [timeSeriesData, setTimeSeriesData] = useState(null);
const [showTimeSeries, setShowTimeSeries] = useState(false);

// ì‹œê³„ì—´ ë¶„ì„ í˜¸ì¶œ
const handleTimeSeriesAnalysis = async () => {
  if (!userId) return;

  try {
    const response = await apiClient.get(`/api/timeseries/analyze/${userId}`);
    setTimeSeriesData(response.data);
    setShowTimeSeries(true);
  } catch (error) {
    console.error('ì‹œê³„ì—´ ë¶„ì„ ì‹¤íŒ¨:', error);
  }
};

// UIì— ë²„íŠ¼ ì¶”ê°€
<Button onClick={handleTimeSeriesAnalysis} className="w-full mt-4">
  ë³€í™” ì¶”ì´ ë³´ê¸°
</Button>

{/* ì‹œê³„ì—´ ë¶„ì„ ê²°ê³¼ */}
{showTimeSeries && timeSeriesData && (
  <Card className="mx-4 mt-4">
    <CardHeader>
      <CardTitle>ğŸ“Š ë¨¸ë¦¬ ë°€ë„ ë³€í™” ì¶”ì´</CardTitle>
    </CardHeader>
    <CardContent>
      {/* íŠ¸ë Œë“œ ìš”ì•½ */}
      <TrendSummary
        trend={timeSeriesData.comparison.density.trend}
        weeklyChange={timeSeriesData.comparison.density.weekly_change}
        monthlyChange={timeSeriesData.comparison.density.monthly_change}
      />

      {/* íˆíŠ¸ë§µ */}
      <div className="mt-4">
        <DensityHeatmap distributionMap={timeSeriesData.current.density.distribution_map} />
      </div>
    </CardContent>
  </Card>
)}
```

---

## ğŸ“ êµ¬í˜„ ìˆœì„œ

### Week 1: Python ë…ë¦½ ëª¨ë“ˆ (5ì¼)
1. `time_series/` í´ë” ìƒì„±
2. `density_analyzer.py` êµ¬í˜„ (2ì¼)
3. `feature_extractor.py` êµ¬í˜„ (2ì¼)
4. `timeseries_comparator.py` + `api.py` (1ì¼)

### Week 2: Backend ì—°ë™ (3ì¼)
5. `TimeSeriesController.java` êµ¬í˜„ (2ì¼)
6. Python API ì—°ë™ í…ŒìŠ¤íŠ¸ (1ì¼)

### Week 3: Frontend ì‹œê°í™” (4ì¼)
7. `TimeSeriesChart.tsx` (1ì¼)
8. `DensityHeatmap.tsx` (1ì¼)
9. `TrendSummary.tsx` (1ì¼)
10. DailyCare í†µí•© (1ì¼)

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ê¸°ì¡´ Swin ì½”ë“œ ìˆ˜ì • ì—†ìŒ
- [ ] DB ìŠ¤í‚¤ë§ˆ ë³€ê²½ ìµœì†Œí™” (ê¸°ì¡´ í…Œì´ë¸” í™œìš©)
- [ ] ë…ë¦½ ì‹¤í–‰ ê°€ëŠ¥ (time_series ëª¨ë“ˆë§Œìœ¼ë¡œ)
- [ ] API ì‘ë‹µ ì‹œê°„ < 3ì´ˆ
- [ ] ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ì¡´ ì‹œìŠ¤í…œ ì˜í–¥ ì—†ìŒ

---

**ì›ì¹™ ìš”ì•½**:
- âœ… ì™„ì „ ë…ë¦½ ëª¨ë“ˆ
- âœ… ê¸°ì¡´ ì½”ë“œ ìˆ˜ì • ì—†ìŒ
- âœ… ìµœì†Œí•œì˜ ì˜ì¡´ì„±
- âœ… ì ì§„ì  ì¶”ê°€ ê°€ëŠ¥

