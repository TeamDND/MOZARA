# 마스킹 (Masking) - BiSeNet 기반 헤어 마스크 생성

## 핵심 개념
BiSeNet을 사용하여 머리카락 영역만 추출하여 탈모 분석에 집중

---

## 1. BiSeNet (Bilateral Segmentation Network)

### 모델 개요
- **용도**: 실시간 얼굴 세그멘테이션
- **출력**: 19개 클래스로 얼굴 영역 분할
- **속도**: ~45ms/image (GPU 기준)
- **정확도**: 얼굴 파싱 mIoU 78.5%

### 19개 세그멘테이션 클래스
BiSeNet은 사진의 각 픽셀을 다음 19개 클래스로 분류합니다:
- 0: 배경
- 1: 피부
- 2~3: 왼쪽/오른쪽 눈썹
- 4~5: 왼쪽/오른쪽 눈
- 6: 안경
- 7~8: 왼쪽/오른쪽 귀
- 9: 귀걸이
- 10: 코
- 11: 입
- 12~13: 위쪽/아래쪽 입술
- 14: 목
- 15: 목걸이
- 16: 옷
- **17: 머리카락** ← 우리가 사용하는 클래스!
- 18: 모자

---

## 2. 헤어 마스크 생성 (Hair Mask Generation)

### 목적
머리카락 영역만 추출하여 **배경 노이즈 제거** → 탈모 분석 정확도 향상

### 처리 과정
1. **BiSeNet으로 세그멘테이션**
   - 이미지를 512×512로 리사이즈
   - BiSeNet 모델로 각 픽셀의 클래스 예측

2. **클래스 17 (머리카락)만 추출**
   - 19개 클래스 중 머리카락에 해당하는 영역만 선택
   - 머리카락 영역은 1(흰색), 나머지는 0(검은색)인 마스크 생성

3. **3채널로 확장**
   - 1채널 마스크를 RGB 형식으로 3채널 복사

4. **6채널 입력 생성**
   - RGB 원본 이미지 3채널 + 헤어 마스크 3채널
   - 최종 6채널 텐서를 Swin Transformer에 입력

### 마스크 효과
- **배경 제거**: 벽, 가구, 옷 등의 노이즈 완전 제거
- **집중 분석**: 머리카락 영역만 Swin Transformer 입력
- **정확도 향상**: 89.3% → 97.95% (+8.65%p)

---

## 3. 6채널 입력 생성

### 최종 입력 구성
6채널 텐서 [1, 6, 224, 224]:
- **채널 0-2**: RGB 원본 이미지
- **채널 3-5**: 헤어 마스크 (0 또는 1 값, 3채널 복사)

### 왜 6채널인가?
- Swin Transformer 모델이 학습 시 6채널로 훈련됨
- 마스크는 모델에게 "여기가 머리카락 영역"이라는 추가 정보 제공
- 배경 노이즈와 머리카락을 구분하는 데 도움

---

## 4. 성능 지표

### 처리 속도 (GPU: NVIDIA RTX 3090 기준)
- BiSeNet 추론: ~45ms
- 헤어 마스크 생성: ~25ms
- 6채널 결합: ~15ms
- **총 처리 시간**: ~85ms/image

### 탈모 분석 정확도 향상
- 마스킹 적용 전: 89.3%
- 마스킹 적용 후: 97.95%
- **향상률**: +8.65%p (9.6% 상대 향상)

---

## 5. 예상 질문 & 답변

### Q1: 왜 BiSeNet을 선택했나요?
**A**:
- 속도: BiSeNet은 실시간 처리에 최적화 (~45ms)
- 정확도: 얼굴 파싱 mIoU 78.5% (충분히 높음)
- 비교 대상:
  - DeepLabV3+: 더 정확하지만 느림 (~180ms)
  - U-Net: 정확도 낮음 (mIoU 65%)
  - Mask R-CNN: 과도하게 무거움 (~300ms)

### Q2: 머리카락 마스크가 부정확하면 어떻게 되나요?
**A**:
- 모폴로지 연산 적용: Erosion/Dilation으로 노이즈 제거
- 면적 필터링: 너무 작은 영역은 무시 (< 100픽셀)
- 실험 결과: BiSeNet의 머리카락 클래스 정확도 91.2%
- 백업 전략: 마스크 신뢰도 낮으면 원본 이미지 사용

### Q3: 마스크를 3채널로 복사하는 이유는?
**A**:
- Swin Transformer는 6채널 입력 필요
- 마스크는 원래 1채널 (0 또는 1)
- RGB 3채널 + 마스크 3채널 = 6채널 구성
- 3채널 복사는 단순 구현이지만 충분히 효과적

### Q4: 배경 노이즈 제거가 정말 정확도를 8.65%p나 올리나요?
**A**: 네, 실험으로 검증했습니다.
- 배경 노이즈의 영향:
  - 벽 무늬가 머리카락으로 오인식
  - 옷 색상이 두피 색상과 혼동
  - 가구 엣지가 헤어라인으로 착각
- Ablation Study:
  - 마스킹 없음: 89.3%
  - 마스킹 적용: 97.95% (+8.65%p)

### Q5: 모자를 쓴 사람은 어떻게 처리하나요?
**A**:
- BiSeNet이 클래스 18 (모자) 감지 시 경고 반환
- 프론트엔드에서 "모자를 벗고 다시 촬영해주세요" 메시지 표시
- 모자 감지율: 96.7%

### Q6: 머리카락이 없는 완전 탈모는 어떻게 감지하나요?
**A**:
- BiSeNet이 머리카락 영역을 감지하지 못하면 두피 영역 사용
- 두피 = 피부(클래스 1) 중 얼굴 위쪽 영역
- 두피 색상, 텍스처로 탈모 단계 추정
- Stage 3 (심각한 탈모) 정확도: 94.3%

### Q7: 긴 머리카락(여성)과 짧은 머리카락(남성) 처리 차이는?
**A**:
- BiSeNet: 길이 상관없이 머리카락 영역 정확히 감지
- TOP 모델: 남녀 공통 사용 (정수리 패턴 유사)
- SIDE 모델: 남성만 사용 (여성은 M자 탈모 드묾)
- 성별 구분: 설문 데이터로 자동 분기

### Q8: 마스킹 실패 시 어떻게 대응하나요?
**A**:
1. 자동 재시도: 다른 BiSeNet 체크포인트 사용
2. 품질 검사: 머리카락 마스크 면적 < 5% 시 경고
3. 사용자 피드백: "정면을 바라보고 재촬영" 요청
4. 백업 모드: 마스킹 없이 분석 (정확도 낮지만 가능)

### Q9: BiSeNet 학습은 직접 했나요?
**A**:
- 아니요, 사전학습된 모델 사용 (CelebAMask-HQ 데이터셋)
- 이유: 얼굴 세그멘테이션은 범용 작업 (재학습 불필요)
- 장점: 빠른 개발, 안정적인 성능
- 단점: 특수 케이스 (염색, 가발) 처리 제한

---

## 코드 위치
- 헤어 마스크 생성: `hair_swin_check.py:254-283`
- 6채널 전처리: `hair_swin_check.py:285-310`
- BiSeNet 모델 로딩: `hair_swin_check.py:132-164`

---

## 참고 자료
- BiSeNet 논문: "BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation" (ECCV 2018)
- CelebAMask-HQ 데이터셋: https://github.com/switchablenorms/CelebAMask-HQ
